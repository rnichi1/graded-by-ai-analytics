{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluate the data with the backend\n",
    "We are evaluating the gpt integration by simulating student responses from previous real data and comparing the feedback and results with real human grading."
   ],
   "id": "cceee7792bad98c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and Prepare Data",
   "id": "9954a037639ed9b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T11:53:26.841712Z",
     "start_time": "2025-01-05T11:53:26.839416Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:53:27.482581Z",
     "start_time": "2025-01-05T11:53:27.186787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tasks_df = pd.read_csv('data/tasks_df.csv')\n",
    "submissions_df = pd.read_csv('data/submissions_df.csv')\n",
    "users_df = pd.read_csv('data/users_df.csv')\n",
    "\n",
    "print(\"---Tasks---\")\n",
    "print(tasks_df.head())\n",
    "print(\"---Submissions---\")\n",
    "print(submissions_df.head())\n",
    "print(\"---Users---\")\n",
    "print(users_df.head())"
   ],
   "id": "3a521bf7aaa78864",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tasks---\n",
      "    id            slug  assignment_id  max_points  solution_file_id  \\\n",
      "0  402  1_week1_sta120            302         1.0               606   \n",
      "1  403  2_week1_sta120            302         1.0               611   \n",
      "2  753  2_week8_sta120            652         1.0              1261   \n",
      "3  709  3_week6_sta120            603         1.0              1146   \n",
      "4  404  3_week1_sta120            302         1.0               617   \n",
      "\n",
      "  solution_file_name solution_file_mime_type  \\\n",
      "0           script.R              text/plain   \n",
      "1           script.R              text/plain   \n",
      "2           script.R              text/plain   \n",
      "3           script.R              text/plain   \n",
      "4           script.R              text/plain   \n",
      "\n",
      "                                            solution  instruction_file_id  \\\n",
      "0  png(file = \"solution.png\")\\nrequire(fields) # ...                  602   \n",
      "1                                 demo(persp) \\n\\n\\n                  607   \n",
      "2   png(file=\"solution.png\")\\nmu <- c(1, 2)\\n sig...                 1257   \n",
      "3  n <- 95\\nx <- 8\\nex_CI <- binom.test(x, n)$con...                 1142   \n",
      "4  png(file=\"solution.png\")\\ndat <- read.csv(\"res...                  612   \n",
      "\n",
      "  instruction_file_name instruction_file_mime_type  \\\n",
      "0       instructions.md                 text/plain   \n",
      "1       instructions.md                 text/plain   \n",
      "2       instructions.md                 text/plain   \n",
      "3       instructions.md                 text/plain   \n",
      "4       instructions.md                 text/plain   \n",
      "\n",
      "                                         instruction  course_slug  \n",
      "0  Require the package fields. Display the volcan...  fs24-sta120  \n",
      "1  Use the the R help function to find out the pu...  fs24-sta120  \n",
      "2  Plot the density of $X$ (as defined in the pre...  fs24-sta120  \n",
      "3  Suppose that among $n=95$ Swiss males, eight a...  fs24-sta120  \n",
      "4  On www.isleroyalewolf.org/data/data/home.html ...  fs24-sta120  \n",
      "---Submissions---\n",
      "       id  points  valid  evaluation_id                      user_id  \\\n",
      "0  357735     1.0   True          49202  julianpatrick.stoerr@uzh.ch   \n",
      "1  357739     0.0   True          49204            floxmas@gmail.com   \n",
      "2  357741     1.0   True          49203  julianpatrick.stoerr@uzh.ch   \n",
      "3  350328     0.0   True          47315  anjana.thatheeskumar@uzh.ch   \n",
      "4  350330     1.0   True          47315  anjana.thatheeskumar@uzh.ch   \n",
      "\n",
      "   best_score                                            content  task_id  \n",
      "0         1.0  png(file = \"solution.png\")\\n\\n## Uniforme Vert...      761  \n",
      "1         1.0  png(file = \"solution.png\")\\n\\n## Normalverteil...      762  \n",
      "2         1.0  png(file = \"solution.png\")\\n\\n## Normalverteil...      762  \n",
      "3         1.0  png(file = \"solution.png\")\\n\\n## Normalverteil...      762  \n",
      "4         1.0  png(file = \"solution.png\")\\n\\n## Normalverteil...      762  \n",
      "---Users---\n",
      "                                user_id                 email  \\\n",
      "0  d95603c0-5a0f-4c9a-85f2-f2036892966d        student@uzh.ch   \n",
      "1  a08fc0d2-854a-4860-9f12-6c06b17df93e     supervisor@uzh.ch   \n",
      "2  c3b197c2-6295-4b30-a764-d06d6935f9d5  shubhi.pareek@uzh.ch   \n",
      "3  b2e59824-54a6-4dd2-aff5-b1c87c04b2f9                   NaN   \n",
      "4  7a5d43de-f501-4a44-9edb-6fa564804984                   NaN   \n",
      "\n",
      "                           username  \n",
      "0                    student@uzh.ch  \n",
      "1                 supervisor@uzh.ch  \n",
      "2              shubhi.pareek@uzh.ch  \n",
      "3  service-account-realm-management  \n",
      "4                             admin  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Stratified Sampling",
   "id": "fcdb31bae89f51b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:56:16.932410Z",
     "start_time": "2025-01-05T11:56:16.324454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from helpers.stratified_sample import stratified_random_sample\n",
    "\n",
    "# Combine submissions and tasks into one dataset\n",
    "combined_data = submissions_df.merge(tasks_df, left_on=\"task_id\", right_on=\"id\")\n",
    "\n",
    "# Rename columns for consistent field names\n",
    "combined_data.rename(columns={\"max_points\": \"maxPoints\"}, inplace=True)\n",
    "\n",
    "# Convert to a list of dictionaries for stratified sampling\n",
    "combined_data_dict = combined_data.to_dict(orient=\"records\")\n",
    "\n",
    "# Apply stratified sampling\n",
    "sampled_data_by_course = stratified_random_sample(\n",
    "    combined_data_dict,\n",
    "    sample_size=400,  # Adjust as needed\n",
    "    num_groups=6,\n",
    "    exercise_sample_size=10  # Ensure diversity in exercises\n",
    ")\n",
    "\n",
    "# Separate sampled data into stat and mat\n",
    "evaluation_data_stat_stratified = sampled_data_by_course.get(\"fs24-sta120\", [])\n",
    "evaluation_data_mat_stratified = sampled_data_by_course.get(\"fs24-mat183\", [])\n",
    "\n",
    "# Check stratified sampling results\n",
    "def count_submissions_by_exercise(data):\n",
    "    counts = {}\n",
    "    for entry in data:\n",
    "        task_id = entry[\"task_id\"]\n",
    "        counts[task_id] = counts.get(task_id, 0) + 1\n",
    "    return counts\n",
    "\n",
    "# Count submissions per exercise for each course\n",
    "counts_stat = count_submissions_by_exercise(evaluation_data_stat_stratified)\n",
    "counts_mat = count_submissions_by_exercise(evaluation_data_mat_stratified)\n",
    "\n",
    "# Count unique exercises\n",
    "unique_exercises_stat = len(counts_stat)\n",
    "unique_exercises_mat = len(counts_mat)\n",
    "\n",
    "print(f\"Total sampled submissions (Stat): {len(evaluation_data_stat_stratified)}\")\n",
    "print(f\"Total unique exercises (Stat): {unique_exercises_stat}\")\n",
    "print(f\"Total sampled submissions (Mat): {len(evaluation_data_mat_stratified)}\")\n",
    "print(f\"Total unique exercises (Mat): {unique_exercises_mat}\")\n",
    "\n",
    "# Convert counts to DataFrames for visualization\n",
    "counts_stat_df = pd.DataFrame(list(counts_stat.items()), columns=[\"Exercise\", \"Submissions\"])\n",
    "counts_mat_df = pd.DataFrame(list(counts_mat.items()), columns=[\"Exercise\", \"Submissions\"])\n",
    "\n",
    "# Plot the distribution of submissions per exercise for each course\n",
    "def plot_submissions_distribution(df, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df[\"Exercise\"].astype(str), df[\"Submissions\"])\n",
    "    plt.xlabel(\"Exercise ID\")\n",
    "    plt.ylabel(\"Number of Submissions\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_submissions_distribution(counts_stat_df, \"Distribution of Submissions per Exercise (Stat Data)\")\n",
    "plot_submissions_distribution(counts_mat_df, \"Distribution of Submissions per Exercise (Mat Data)\")\n",
    "\n",
    "# Summary statistics for submissions per exercise\n",
    "summary_stats_stat = counts_stat_df[\"Submissions\"].describe()\n",
    "summary_stats_mat = counts_mat_df[\"Submissions\"].describe()\n",
    "\n",
    "print(\"\\nSummary statistics for submissions per exercise (Stat):\")\n",
    "print(summary_stats_stat)\n",
    "\n",
    "print(\"\\nSummary statistics for submissions per exercise (Mat):\")\n",
    "print(summary_stats_mat)\n",
    "\n",
    "# Final integrity checks\n",
    "print(f\"Unique exercises in Stat set: {len(set(d['task_id'] for d in evaluation_data_stat_stratified))}\")\n",
    "print(f\"Unique exercises in Mat set: {len(set(d['task_id'] for d in evaluation_data_mat_stratified))}\")\n"
   ],
   "id": "fc9f8c7252b4c8fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sampled submissions (Stat): 200\n",
      "Total unique exercises (Stat): 10\n",
      "Total sampled submissions (Mat): 200\n",
      "Total unique exercises (Mat): 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSEElEQVR4nO3dB5hU5f0/7IeOWFBUBBRBxQr2KLFjRI0latRYorFGUmxoEoVfYi+giSUaY4yxRGOJ3aAJKsYuamyxG1ERjL0BQsTC/K/v816z7+6yiyzMYbbc93WNzJyZPfPMmTPH8zlPa1cqlUoJAAAAqLj2lV8lAAAAEIRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG6gzTnxxBNTu3btFsh7DRkyJN/K7r333vzeN9xwwwJ5/wMOOCD1798/NWeffvpp+uEPf5h69eqVt83w4cMX6PvHex522GGFv8/EiRPze11++eUVX3esN/ZrWo/ysSL+XdDOPPPMtNpqq6VZs2Yt8PduDV544YXUsWPH9Nxzz1W7KEAzIXQDLVoEmDgxLd+6du2a+vTpk7bddtt03nnnpWnTplXkfd56660cap5++unU3DTnss2N008/PX+PP/nJT9KVV16ZfvCDHzT62s8//zz99re/Teuuu25abLHF0uKLL54GDhyYhg0bll566aUFWm5ajrjwVPs4Ufv27W9/u9rFa1amTp2azjjjjHTsscem9u3//9PE8vaKC2QN+eUvf1nzmg8++KDJ7/v3v/+9SReO4mJm+f2inHE8WHXVVfPx46677krz4/e///18XRxbY4010g477JCOP/74+SoH0Hq0K5VKpWoXAmBexYnRgQcemE4++eS0wgorpC+++CK98847uXYoTryWX3759Le//S2ttdZaNX/z5Zdf5lsE9Ln1+OOPpw022CBddtllufZ4bkVIDJ07d87/Rrm23HLLdP3116fdd9+9SZ91XsoW2yNqq7p06ZKaq29+85u5VujBBx/82td+5zvfSf/4xz/S3nvvnTbaaKP8+SJs33bbbemUU05p0ndTFifthx56aPrd736XihT/u505c2bq1KlT6tChQ0XX/dlnn+VtGDcaDt1LLLFE+tnPfjbbc3GR7lvf+lZqbuJ3G8ePOHbUDr9FO/fcc9MJJ5yQ3n333TrHyPJFzbjFc+VjWtmKK66Y3n777bwvvv/++2mppZZq0vtGa5MLLrgg/07mNnS/+uqradSoUfnx9OnT04QJE9JNN92UXnvttbTHHnukv/zlL/n31lSDBg3K5Z+fVgZxnNp+++1zmVZaaaV5Xg/QOvi/M9AqbLfddukb3/hGzeORI0emf/7zn2nHHXdMO+20U3rxxRfTQgstlJ9bEOFkxowZqVu3brOdmC5o83LCuaC99957uWbo6/zrX//K4fq0005L//d//1fnuQjMn3zySWrOyqGlCEWtt6WIi2gRUuf0e1t22WXTvvvum5pDkJ6b7yuCdjW+17h4F8fMht47WgXERcwIlDvvvHPN8ocffji9/vrrabfddks33njjAitr9+7dZ/tOR48enY444ohcWx0XW6LWvhqGDh2aL/T8+c9/zheFgbZN83Kg1Yraq+OOOy698cYbucZjTn26o1Z80003zc2VF1lkkdxMsRzsorYjapJD1KqXmzSWmx9GjUvUjDzxxBNp8803z2G7/Lf1+3SXffXVV/k10Y954YUXzie5kydPrvOaOGFsqOa29jq/rmwN9emOGqGo8evbt2+uAY/P+pvf/Ga2GqZyX+dbbrklf754bTTlHjt27FyH6YMPPjgts8wy+QR+7bXXzieg9fusxsn67bffXlP26PvckKjVCptssslsz0XN8ZJLLvm1fdnn1J//qquuytsiyrr++uun+++/v8G//c9//pNP9OOEf+mll877WGy7+P4iiEQz1/hezzrrrK/t0x2tMuJ7W2655fL27d27d15H7W0QLRmiu0TUvMWFo2jRcdBBB31tn+6nnnoqX4yK8sQ+vdVWW6VHHnmkwe4ZDz30UDr66KPz54n98bvf/W6uraxtbsrRkPge4uLXnXfemdZZZ528feMiS9RI1hcXTqJPf3nfHDBgQA5NtfsWl7dj7LNRKxu1iPHa6Ec7P2J/jc8fv63av4WoqYxtsueee9YsixYLURsc5Yv3jvIec8wxeXlDv6HYt+K3E68t/37++9//5t9H1LTH8tie0cWi3DqmoT7dr7zySg62sX/Fdoz9Zq+99kpTpkyp875xvIt9OL6nHj165NfUP740JH6LzzzzTA6MjV24iGPc1VdfXWd5fL4111wzHyfqe+CBB9L3vve93OqovK2OOuqo9L///a/O7zVqucvbrHybF3EsiK5FsY/Fxbja2yYuKMT/F3r27JnLEq+58MILZ9tfn3/++XTffffVlKN8vP3oo4/Sz3/+8/xZ4zcVv634jf373/9u8IJn/N2tt946T58DaF3UdAOtWvTvi3AbJ/yHHHJIg6+JE6wIBdEEPWok4mQsTrQjiITVV189L4/+edF3eLPNNsvLN95445p1fPjhh/nkK05uI5BF0JyTqK2Nk7noNxkn+xEe4kQ3+mWXa+TnxtyUrbYIExHw77nnnnzCHyHojjvuSL/4xS9yCDjnnHPqvD6afEc4+ulPf5oWXXTRfDIbJ/2TJk2qE3LrixPqOOGM7RihIwJFNKmPk+sIVkceeWQue/ThjhPwCA/lpr8RfBrSr1+/mhP8CN6VbK0QJ9h//etfcw1ZfP9RSxa1eo899thsQSLCV5Q9atTiYsGpp56ag81FF12UT+gjJEYZ4+Q8LohESGlMbMvY/w4//PB8sh/7QlwAiu1bfrzNNtvkbTJixIh8UShCZ0OBtbZYZ+wLEQoiDEYAiPLFdxKfdfDgwXVeH+8ftXIRJGP9sT/G9xbbJMxrOWqHxdhuP/7xj9P++++fw08EsQigW2+9dU3rkC222CLvhz/60Y9ySIsa1Gi1Es2Wo0y1xTqiKXPs9/GdxXcwJ9EVoaG+xhGo4zcXQSwCWJTr/PPPz/tChP3YZ2Pfj30ixLL4DcVvI9479oVnn302/3bigkxcpKotWtxcd911eXvGBYv4XmMchg033DD/FmIdMWhZfO4YYDG2Q0M19hHG46JHBPv4viJ4x99E649YT1wEKh9b4kJQNK+O/tdx8SQ+T+yHcSEmvrvGxPYO6623XqOv+f73v59/vzEAYgTPaGUQv+24aBPfR33xXHymuKAQx4z4TUV53nzzzfxciO87tkns+3FMmF8RvKMLSmyH+J6if3WI7zcufsT3F8ePMWPG5GNbfKfRxSTEfhbbNz5b9FMP5eN5NFuP7zf2kTimRTP7+F3FfhsXfeICSm1x4SNCd/STj98i0IZFn26Aluqyyy6LKqnSv/71r0Zf071799K6665b8/iEE07If1N2zjnn5Mfvv/9+o+uI9cdr4v3q22KLLfJzf/jDHxp8Lm5l99xzT37tsssuW5o6dWrN8uuuuy4v/+1vf1uzrF+/fqX999//a9c5p7LF38d6ym655Zb82lNPPbXO63bfffdSu3btShMmTKhZFq/r3LlznWX//ve/8/Lzzz+/NCfnnntuft1f/vKXmmWff/55aaONNiotssgidT57lG+HHXYofZ1Zs2bVbOtlllmmtPfee5cuuOCC0htvvPG1n7ux7778OeP2+OOP1yyLdXbt2rX03e9+d7a/HTZsWM2yL7/8srTccsvlbTd69Oia5R9//HFpoYUWqvP9vf7663W+p3hNPP71r3/d6Ge++eabv3b/Ln+GKF/ZLrvskr+7V199tWbZW2+9VVp00UVLm2+++Wy/n6FDh+btW3bUUUeVOnToUPrkk0+aVI6GxPcQf3vjjTfWLJsyZUqpd+/edX6Xp5xySmnhhRcu/ec//6nz9yNGjMhlmTRpUp3tuNhii5Xee++9JpWhoduoUaPqvDb2q27duuVyxHcTr4nfTdmVV15Zat++femBBx6o83fx+4/XPvTQQzXL4nG89vnnn6/z2v322y8vb2h7lr+H8rEi/g1PPfVUfnz99dc3+jknTpyYt9Vpp51WZ/mzzz5b6tix42zL6/vVr36V32PatGmzPRfLDz300NJHH32U963YDuH222/P+3+8d/k3UvtYOmPGjNnWFds8/qb2bzfW3ZTT0jgWDBw4sNHny/ts7WNqQ2XZdtttSyuuuGKdZbHe2sfYss8++6z01Vdf1VkW+2OXLl1KJ5988myvv/rqq3MZHn300bn+XEDrpHk50OpFjcWcRjEv1/xEjcS8TpETNW3RTHhu7bfffrn2rCwGVYumxTGCb5Fi/VELFLV4tUUtc5xXR1/N2qL2vfYgQNEaIGpsosbn694nauKitqksalvjfaOGLGpbmypaBkStfNQsR63sNddck2unogY8alHnp093DMoWtVJlUcsazbzj/aIrQG21R2+ObRljCcS2i5YDtfepaKo+p+0UtatRoxnNhz/++OM57ptRmxk1tXMjyhstO3bZZZc8uFVZ7F9RSxk1f1HzVlvUttZuzhu15LGe6Joxr+WoLWoAo8l6WexD8RuImtdoYh+i1jPeN77bqJEu32IfjLLUb+4frQQaaxXRkKjdj5rU+rfa+2iIJslRaxy/yagpjdYytfsvRzmjdjtqp2uXszwYW7QiqS1qQWuPWRDHmKgtjUEBa49DUdZYs+pyTXbsk1Fz3JBoeRDrj1ru2mWL3+LKK688W9nqixY7UQMcx8zGxPcTrUDi9xeiqXm0rCm3RKmvdsud6NoS5YnXx28mvv+ilD9D7WN/7bJEs/MoS3w/8Tut30S/seN8eVC72Cdje5W7Iz355JMNbqswL6O5A62L0A20ehHyagfc+iKwRXPlCFPRjDCaiEdz0KYE8Ojr2JRB0+IEuP6JdvQPbaw/c6VEiIoAVH97RIgoP19bhM+GTiQbC4m13yc+Y/1Rlxt7n7kVJ73R5DMGxovmqHHiH6Ofl5vvzqv630dYZZVVcrip37e5/jaJMBT9a+uP1hzL57Sd4rNEU/S40BH7XTT/jfmRyyE0RCCIcHnSSSfl9Uf4i2bV9fsO1xbljXJHEKgvtn/s1/X799b/TOWwUC7/vJSjtti364fJ2L6hvM9HE/Robh5Buvat3L84mrjXFs17myLKHeuqf6sfFqOZenSjiL7N8R3G/dqinNF8v345y5/n68oZ309c9Gio//OcxHqiCfef/vSn/FmiqXn0g64dFqNsEWZjf65fvvjN1C/bvIqLN+VuEHEBIR43Jl4TTfRju0ZAjbLE/hTmJujOz3E/1D7WRZeh+M6jS0FcSIqylMffmJuyxG8nuhHE9o3fb3wPsY7YVxr6+/LYAPPaPx1oPfTpBlq16DcYJ0Nx0t+YqP2IWrSoBYo+unHiH31Zo+YqagznZnqnpvTDnluNnahFDUulp5xqTGPv0xxmm4ya27hAEmEw+mlG8I6BwaKmbk7brohtMq/bKQYNixrPCC5Rgxk1qzEFUvQDjrnI43NEP98YAC36n8ZrYvCyGKQtls2pRnJ+P1Pt8i+IckSgif7d0Qe9IeVQW+Rvriw+X/miQxxDaveDjnLGQFpnn312g38bA4UVVc7Y3hFgo1VOHJui5UjsL/EdxLgIUbb4ruJCTkPf6dd9T9HnOvpoR+3wnC5URp/oCJ3RPz8uvETNemO/t/hOYwCyGL8iWgdE4I2+6PE55rVl0dx47rnn8r/lY38MxBiDCUYZ4ruL7ykulEarnAjSc1OW008/Pf9GY9+PKQrjQkJcWIzfcUN/X75o1dTp04DWR+gGWrXyoDxRKzQnceIUJ2RxixOyOLmKGtUI4lEzUumaiqiRqh9uYtCx2vOJR21jQ02mo5a4drPhppQtavXGjRs320l1zHVdfr4SYj1R+xMnorVruyv9PuVm67HdYpuWm9LOadvNzfcRYlCsGIm+KU2Y50U034/m/XGLcsTgdhGuao+4H7X5cYtBsqI57z777JOuvfbaOk3dy6K8Ue6XX355tudi+8f3UT8Yzq2mlKO22LdjH6+9r8b2DeVR5mM7RO1kYyNnLyhx0S1qkyP8x4B4ESwfffTRmoH7opwxWnUcK+bluBDfTzSvL4fCporAH7df/epXeeCzaKXzhz/8IXe7iLLFdo5a8foXKeZGBNLyKOa1j0X1xYWE6L4Q+2gMINlYqIwB5uJ7jlkLojtBWdSS11fJY2yE/dg/43cQs1KEuFgUFwhiyrPaLTsaanLfWFniwtOWW26ZLrnkkjrL41jT0DaI7Ri/t3n5LoDWRfNyoNWK2sKojYgT0AgHjYlamPoi+IRy89monQmVmgv6iiuuqNPXME7mYoTmOIEtixPoqMEqTyFU7lNbv2lwU8q2/fbb5xPS6LdaW9T0xIlm7fefH/E+0Uy6PPp1iBq0GLU4atvKzUubIgJpNFWtLz73+PHjc9AuB+TYdtHCIYJ/WWzfm2++ucF1x9/X7pMZ2zhqE2PE7qJaFUQT8PqjPUe542JIeb+LmrL6teX19836orxR7ih/7e4KMdJyBJEIIU0dSXleylFbdAWove2jeXX8BmIdcZEkRG1pfA/lWub633HsP0WL94kLCDGyeFx4i/Ad+0XcL4tyRk3txRdf3OCo/dFveU4ihEVgjRAY07DNbeuI2Gb1t0GE71hf+TvYdddd8/cf3QDqryceRx/krxvbIDRUrvpidP4Y7T5qfhtT/u3ULkvc/+1vfzvbayt1jI3jW7QAiOb08W95X2+oLHGMiG4SDZWloXLEOupv1+jjH/tDQ2IayWiFU+6PD7RdarqBViGaU0YtXpyURriIwB21KVGjGjUb0ee2MTHlVjQvj2ll4vXR7zGmB4rmmuVakghD0cQ0apQiFMVJWQzM1NR+pWXRLDHWHYOvRXljmppoBll7WrM4+Y8wHoMWxYl+NI+MmqXaA5s1tWzRlDlqaqIWPwJZzJ0dzVQjoEUTyfrrnlcxMFdMpRNNSOPEM2oz47NEn8r4rHNqutqYqF2MvqNxYSAG3IptGCe7UYsWoS7WWz6xjmbn0Zw1Bu+KE+8IuDFdUNQ4NTTgUfSvjdYQtacMCxFeihI1gFFbGt9tDLQVNakRTGN/iPKH+GxRlvgc8d3EhZoIexEk4sJGY6LWszz3fEyJFOuO7yPCWfQbb6p5LUdZbPcYaO5f//pX7r9+6aWX5s9ZO/DEtHXxW43p+2K/iYHtIsBGbWnsO7G/zk8z3dhXarceKIuLQBGCQ0yFFcE0WoPEvhS/vfgdxvaMfuzxe4mB1aIrQ0x/FrWkUdMcQS+OP7E8Lho0NEBabRHi43cXF5/K047FRaEIcDHQXUPTesUxLcYtiOmqYnvGsS5a8kQ5o4tFiO8myhrTrMX2is8Vv7WocY19K94rwnJjogVN/Bbi83/dHOyxLeL2dTXnUaZ4z9j+sb/ceOONDY51UB7IMH6D8VuMz1X+HTQmQnP5O43feLSoiMHk4lgZfxsXXcviQlQ0J49jYExRFq0qYh+OqeJi29cvSxwvYlvGcTleE92NYt+M/1/EcTsGg4t9M1pD1G55VBYDDsaAkfH7AzBlGNCilac8Kt9iKptevXqVtt566zxVTO2pqRqbNuruu+8u7bzzzqU+ffrkv49/Y9qg+lMX3XrrraU11lgjT71Te+qnOU1d09iUYddcc01p5MiRpZ49e+appWLKrIamvjrrrLPy9GIxJc0mm2ySp7Wqv845la2hqbNiOqCYEio+Z6dOnUorr7xynhqp9pRRtacIqq+xqczqe/fdd0sHHnhgaamllsrbdc0112xwWrO5nTIs1hfTcsVnj+mm4rMuscQSpW9961ulG264YbbX33nnnaVBgwbl91511VXz9GWNTRkWnzOej20R2zqmsipP1VTW0HRIIbZFTHVVX/39ov6UYR988EF+39VWWy3/fUxtN3jw4Dx9XNmTTz6Z98Xll18+lyv2lx133LHO9GYNTRlW/tuYDimmaIspsLbccsvSww8/PFdT7tWfrmpuy9GQ8vd7xx13lNZaa6389/GZG5r6KvbN+F0MGDAgf2+x72y88cal3/zmN3nKudrbcU5TrTVlyrDy7yN+Q/E4fnO1xTEkXrP22mvXlCH+PeOMM/L3G58n9sP111+/dNJJJ+Xp0L7uNxTi9x5Thy299NJ5HTFtVbx25syZDX4Hr732Wumggw4qrbTSSnk6ux49euTvdNy4cbOtO6Zn23TTTfN+FbfY3rHul19++Wu31dlnn533mfrTa83ps8zpN/LCCy/kKelinfF9HnLIITVTD9Y+HsT0e4cffnjeHjGd2NedopanDyzfYv3x+913333zb78hf/vb3/I+GNuvf//++Tu89NJL89/HflX2zjvv5H02ptiL58rH25gy7Gc/+1k+/sRxO47J48ePb/CY/I9//CP/7SuvvDLHzwG0De3iP9UO/gBA6xStHKL2NLpG0PxF7XHU3EaLiNrT4NE00coguuw01qUFaFv06QYAIIv+xzGI3K9//etCRxdvzaI/eVxkqt28HWjb1HQDAIVR0w1AW6emGwAAAAqiphsAAAAKoqYbAAAACiJ0AwAAQEE6plYuRt5866230qKLLpqnbgAAAID5FT21p02blvr06ZPat2/fdkN3BO6+fftWuxgAAAC0QpMnT07LLbdc2w3dUcMdYkMstthi1S4OAAAArcDUqVNzBW85c7bZ0F1uUh6BW+gGAACgkr6uG7OB1AAAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAK0rGoFQMArVP/EbdXuwjNzsTRO1S7CAA0U2q6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAF6VjUigEAmHv9R9xe7SI0KxNH71DtIgBUhJpuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoDWG7lGjRqUNNtggLbrooqlnz55pl112SS+//HKd1wwZMiS1a9euzu3HP/5x1coMAAAALSJ033fffenQQw9NjzzySLrrrrvSF198kbbZZps0ffr0Oq875JBD0ttvv11zO/PMM6tWZgAAAJhbHVMVjR07ts7jyy+/PNd4P/HEE2nzzTevWd6tW7fUq1evKpQQAAAAWkmf7ilTpuR/e/ToUWf5VVddlZZaaqk0aNCgNHLkyDRjxowqlRAAAABaSE13bbNmzUrDhw9Pm2yySQ7XZd///vdTv379Up8+fdIzzzyTjj322Nzv+6abbmpwPTNnzsy3sqlTpy6Q8gMAAECzDd3Rt/u5555LDz74YJ3lw4YNq7m/5pprpt69e6etttoqvfrqq2mllVZqcHC2k046aYGUGYDmrf+I26tdhGZn4ugdql0EAGhTmkXz8sMOOyzddttt6Z577knLLbfcHF87ePDg/O+ECRMafD6an0cz9fJt8uTJhZQZAAAAmnVNd6lUSocffni6+eab07333ptWWGGFr/2bp59+Ov8bNd4N6dKlS74BAABAmw7d0aT86quvTrfeemueq/udd97Jy7t3754WWmih3IQ8nt9+++3Tkksumft0H3XUUXlk87XWWquaRQcAAIDmHbovvPDC/O+QIUPqLL/sssvSAQcckDp37pzGjRuXzj333Dx3d9++fdNuu+2WfvWrX1WpxAAAANCCmpfPSYTs++67b4GVBwAAAFrdQGoAAADQGgndAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACtKxqBXTdP1H3F7tIjQrE0fvUO0iAAAtmHOr2Tm/ggVPTTcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUpGNRKwZar/4jbq92EZqdiaN3mO912K6V36YAANWmphsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAABojaF71KhRaYMNNkiLLrpo6tmzZ9pll13Syy+/XOc1n332WTr00EPTkksumRZZZJG02267pXfffbdqZQYAAIAWEbrvu+++HKgfeeSRdNddd6UvvvgibbPNNmn69Ok1rznqqKPSmDFj0vXXX59f/9Zbb6Vdd921msUGAACAudIxVdHYsWPrPL788stzjfcTTzyRNt988zRlypR0ySWXpKuvvjp961vfyq+57LLL0uqrr56D+je/+c0qlRwAAABaWJ/uCNmhR48e+d8I31H7PXTo0JrXrLbaamn55ZdP48ePr1o5AQAAoNnXdNc2a9asNHz48LTJJpukQYMG5WXvvPNO6ty5c1p88cXrvHaZZZbJzzVk5syZ+VY2derUgksOAAAAzbymO/p2P/fcc+naa6+d78HZunfvXnPr27dvxcoIAAAALS50H3bYYem2225L99xzT1puueVqlvfq1St9/vnn6ZNPPqnz+hi9PJ5ryMiRI3Mz9fJt8uTJhZcfAAAAml3oLpVKOXDffPPN6Z///GdaYYUV6jy//vrrp06dOqW77767ZllMKTZp0qS00UYbNbjOLl26pMUWW6zODQAAANpcn+5oUh4jk9966615ru5yP+1oFr7QQgvlfw8++OB09NFH58HVIkAffvjhOXAbuRwAAIDmrqqh+8ILL8z/DhkypM7ymBbsgAMOyPfPOeec1L59+7TbbrvlAdK23Xbb9Pvf/74q5QUAAIAWE7qjefnX6dq1a7rgggvyDQAAAFqSZjGQGgAAALRGTQ7dMRr4m2++WfP4sccey/Nr//GPf6x02QAAAKBthe7vf//7eWqvEAOfbb311jl4//KXv0wnn3xyEWUEAACAthG6n3vuubThhhvm+9ddd10aNGhQevjhh9NVV12VLr/88iLKCAAAAG0jdH/xxRd5Luwwbty4tNNOO+X7q622Wnr77bcrX0IAAABoK6F74MCB6Q9/+EN64IEH0l133ZW+/e1v5+VvvfVWWnLJJYsoIwAAALSN0H3GGWekiy66KM+tvffee6e11147L//b3/5W0+wcAAAAmId5uiNsf/DBB2nq1KlpiSWWqFk+bNiw1K1bt0qXDwAAANpO6A4dOnSoE7hD//79K1UmAAAAaJvNy9999930gx/8IPXp0yd17NgxB/DaNwAAAGAea7oPOOCANGnSpHTcccel3r17p3bt2jV1FQAAANAmNDl0P/jgg3nk8nXWWaeYEgEAAEBbbV7et2/fVCqViikNAAAAtOXQfe6556YRI0akiRMnFlMiAAAAaKvNy/fcc880Y8aMtNJKK+Upwjp16lTn+Y8++qiS5QMAAIC2E7qjphsAAAAoIHTvv//+Tf0TAAAAaJOaHLrDV199lW655Zb04osv5scDBw5MO+20k3m6AQAAYH5C94QJE9L222+f/vvf/6ZVV101Lxs1alQe1fz222/Pfb0BAACAeRi9/IgjjsjBevLkyenJJ5/Mt0mTJqUVVlghPwcAAADMY033fffdlx555JHUo0ePmmVLLrlkGj16dNpkk02aujoAAABotZpc092lS5c0bdq02ZZ/+umnqXPnzpUqFwAAALS90L3jjjumYcOGpUcffTSVSqV8i5rvH//4x3kwNQAAAGAeQ/d5552X+3RvtNFGqWvXrvkWzcoHDBiQfvvb3zZ1dQAAANBqNblP9+KLL55uvfXW9Morr6SXXnopL1t99dVz6AYAAADmc57usPLKK+cbAAAAMB+h++ijj06nnHJKWnjhhfP9OTn77LPnZpUAAADQ6s1V6H7qqafSF198UXO/Me3atatcyQAAAKAthO577rmnwfsAAABABUcvr2/q1KnplltuqRlUDQAAAJjH0L3HHnuk3/3ud/n+//73v/SNb3wjL1tzzTXTjTfe2NTVAQAAQKvV5NB9//33p8022yzfv/nmm1OpVEqffPJJnr/71FNPLaKMAAAA0DZC95QpU1KPHj3y/bFjx6bddtstdevWLe2www557m4AAABgHkN337590/jx49P06dNz6N5mm23y8o8//jh17dq1qasDAACAtj16eW3Dhw9P++yzT1pkkUVSv3790pAhQ2qanUe/bgAAAGAeQ/dPf/rTtOGGG6bJkyenrbfeOrVv//9Vlq+44or6dAMAAMD8hO4QI5bHLXz11Vfp2WefTRtvvHFaYokl5mV1AAAA0Cq1n5fm5ZdccklN4N5iiy3Seuutl/t633vvvUWUEQAAANpG6L7hhhvS2muvne+PGTMmvf766+mll15KRx11VPrlL39ZRBkBAACgbYTuDz74IPXq1Svf//vf/56+973vpVVWWSUddNBBuZk5AAAAMI+he5lllkkvvPBCbloeU4bFYGphxowZqUOHDk1dHQAAALRaTR5I7cADD0x77LFH6t27d2rXrl0aOnRoXv7oo4+m1VZbrYgyAgAAQNsI3SeeeGIaNGhQnjIsmpZ36dIlL49a7hEjRhRRRgAAAGg7U4btvvvusy3bf//9K1EeAAAAaFuh+7zzzkvDhg1LXbt2zffn5IgjjqhU2QAAgGam/4jbq12EZmXi6B2qXQRaQ+g+55xz0j777JNDd9xvTPTxFroBAACgCaE75uJu6D4AAABQwSnDAAAAgIIGUiuVSumGG25I99xzT3rvvffSrFmz6jx/0003NXWVAAAA0Co1OXQPHz48XXTRRWnLLbdMyyyzTO7HDQAAAFQgdF955ZW5Nnv77bdv6p8CAABAm9LkPt3du3dPK664YjGlAQAAgLYcuk888cR00kknpf/973/FlAgAAADaavPyPfbYI11zzTWpZ8+eqX///qlTp051nn/yyScrWT4AAABoO6F7//33T0888UTad999DaQGAAAAlQzdt99+e7rjjjvSpptu2tQ/BQAAgDalyX26+/btmxZbbLFiSgMAAABtOXSfddZZ6ZhjjkkTJ04spkQAAADQVpuXR1/uGTNmpJVWWil169ZttoHUPvroo0qWDwAAANpO6D733HOLKQkAAAC0MvM0ejkAAABQQOgOX331Vbr55pvTiy++mB+vscYaaeedd04dO87T6gAAAKBVanJKfv7559NOO+2U3nnnnbTqqqvmZWeccUZaeuml05gxY9KgQYOKKCcAAAC0/tHLf/jDH6aBAwemN998Mz355JP5Nnny5LTWWmulYcOGFVNKAAAAaAs13U8//XR6/PHH0xJLLFGzLO6fdtppaYMNNqh0+QAAAKDt1HSvssoq6d13351t+XvvvZcGDBhQqXIBAABA2wjdU6dOrbmNGjUqHXHEEemGG27ITczjFveHDx+e+3YDAAAATWhevvjii6d27drVPC6VSmmPPfaoWRaPw3e+8508sjkAAAAwl6H7nnvuKb4kAAAA0BZD9xZbbFF8SQAAAKCtj15+//33z/H5zTfffH7KAwAAAG03dA8ZMmS2ZbX7e+vTDQAAAPM4ZdjHH39c5xZThY0dOzbP0X3nnXc2dXUAAADQajU5dHfv3r3Obamllkpbb711ni7smGOOaXJT9RjxvE+fPrm2/JZbbqnz/AEHHJCX1759+9vfbmqRAQAAoGWE7sYss8wy6eWXX27S30yfPj2tvfba6YILLmj0NRGy33777ZrbNddcU4HSAgAAQDPs0/3MM8/UeRxzdEcYHj16dFpnnXWatK7tttsu3+akS5cuqVevXk0tJgAAALS80B3BOpp5R9iu7Zvf/Ga69NJLU6Xde++9qWfPnmmJJZZI3/rWt9Kpp56allxyyUZfP3PmzHwrmzp1asXLBAAAAIWE7tdff73O4/bt26ell146de3aNVVaNC3fdddd0worrJBeffXV9H//93+5Znz8+PGpQ4cODf7NqFGj0kknnVTxsgAAAEDhobtfv35pQdlrr71q7q+55ppprbXWSiuttFKu/d5qq60a/JuRI0emo48+uk5Nd9++fRdIeQEAAGCeBlKL2uXbbrutzrIrrrgi10JH8+9hw4bVadZdhBVXXDGPlj5hwoQ59gFfbLHF6twAAACgWYfuk08+OT3//PM1j5999tl08MEHp6FDh6YRI0akMWPG5KbdRXrzzTfThx9+mHr37l3o+wAAAMACDd1PP/10nSbd1157bRo8eHC6+OKLc3Pu8847L1133XVNevNPP/00rzdu5f7icX/SpEn5uV/84hfpkUceSRMnTkx333132nnnndOAAQPStttu26T3AQAAgGbdp/vjjz/Oc3GX3XfffXWm+9pggw3S5MmTm/Tmjz/+eNpyyy1rHpf7Yu+///7pwgsvzNOT/fnPf06ffPJJ6tOnT9pmm23SKaeckpuQAwAAQKsJ3RG4oyY6BiX7/PPP05NPPllnlPBp06alTp06NenNhwwZMtvUY7XdcccdTVofAAAAtMjm5dtvv33uu/3AAw/kEcK7deuWNttss5rno1Y6RhYHAAAAmljTHc26Y87sLbbYIi2yyCK52Xfnzp1rnr/00ktz828AAACgiaE7puq6//7705QpU3Lo7tChQ53nr7/++rwcAAAAaGLoLuvevXuDy3v06NHUVQEAAECrNtd9ugEAAICmEboBAACgIEI3AAAAVDN0r7feeunjjz/O908++eQ0Y8aMosoDAAAAbSt0v/jii2n69On5/kknnZQ+/fTTossFAAAAbWP08nXWWScdeOCBadNNN02lUin95je/aXR6sOOPP77SZQQAAIDWG7ovv/zydMIJJ6TbbrsttWvXLv3jH/9IHTvO/qfxnNANAAAATQjdq666arr22mvz/fbt26e777479ezZc27+FAAAANqsuQrdtc2aNauYkgAAAEBbD93h1VdfTeeee24eYC2sscYa6cgjj0wrrbRSpcsHAAAAbWee7jvuuCOH7MceeyyttdZa+fboo4+mgQMHprvuuquYUgIAAEBbqOkeMWJEOuqoo9Lo0aNnW37sscemrbfeupLlAwAAgLZT0x1Nyg8++ODZlh900EHphRdeqFS5AAAAoO2F7qWXXjo9/fTTsy2PZUY0BwAAgPloXn7IIYekYcOGpddeey1tvPHGedlDDz2UzjjjjHT00Uc3dXUAAADQajU5dB933HFp0UUXTWeddVYaOXJkXtanT5904oknpiOOOKKIMgIAAEDbCN3t2rXLA6nFbdq0aXlZhHAAAACgAvN0lwnbAAAAUMGB1AAAAIC5I3QDAABAQYRuAAAAaA6h+4svvkhbbbVVeuWVV4oqDwAAALTN0N2pU6f0zDPPFFcaAAAAaMvNy/fdd990ySWXFFMaAAAAaMtThn355Zfp0ksvTePGjUvrr79+Wnjhhes8f/bZZ1eyfAAAANB2Qvdzzz2X1ltvvXz/P//5T53n2rVrV7mSAQAAQFsL3ffcc08xJQEAAIBWZp6nDJswYUK644470v/+97/8uFQqVbJcAAAA0PZC94cffpinDVtllVXS9ttvn95+++28/OCDD04/+9nPiigjAAAAtI3QfdRRR+WpwyZNmpS6detWs3zPPfdMY8eOrXT5AAAAoO306b7zzjtzs/LllluuzvKVV145vfHGG5UsGwAAALStmu7p06fXqeEu++ijj1KXLl0qVS4AAABoe6F7s802S1dccUWdacJmzZqVzjzzzLTllltWunwAAADQdpqXR7iOgdQef/zx9Pnnn6djjjkmPf/887mm+6GHHiqmlAAAANAWaroHDRqU/vOf/6RNN9007bzzzrm5+a677pqeeuqptNJKKxVTSgAAAGgLNd2he/fu6Ze//GXlSwMAAABtPXR//PHH6ZJLLkkvvvhifrzGGmukAw88MPXo0aPS5QMAAIC207z8/vvvT/3790/nnXdeDt9xi/srrLBCfg4AAACYx5ruQw89NO25557pwgsvTB06dMjLvvrqq/TTn/40P/fss882dZUAAADQKjU5dE+YMCHdcMMNNYE7xP2jjz66zlRi0Bz0H3F7tYvQ7EwcvUO1iwAAAG1Gk5uXr7feejV9uWuLZWuvvXalygUAAABto6b7mWeeqbl/xBFHpCOPPDLXeH/zm9/Myx555JF0wQUXpNGjRxdXUgAAAGiNoXudddZJ7dq1S6VSqWbZMcccM9vrvv/97+f+3gAAAMBchu7XX3+9+JIAAABAWwzd/fr1K74kAAAA0NZHLw9vvfVWevDBB9N7772XZs2aVee56PMNAAAAzEPovvzyy9OPfvSj1Llz57Tkkkvmvt5lcV/oBgAAgHkM3ccdd1w6/vjj08iRI1P79k2ecQwAAADajCan5hkzZqS99tpL4AYAAICv0eTkfPDBB6frr7++qX8GAAAAbU6Tm5ePGjUq7bjjjmns2LFpzTXXTJ06darz/Nlnn13J8gEAAEDbCt133HFHWnXVVfPj+gOpAQAAAPMYus8666x06aWXpgMOOKCpfwoAAABtSpP7dHfp0iVtsskmxZQGAAAA2nLoPvLII9P5559fTGkAAACgLTcvf+yxx9I///nPdNttt6WBAwfONpDaTTfdVMnyAQAAQNsJ3YsvvnjaddddiykNAAAAtOXQfdlllxVTEgAAAGjrfboBAACAgmq6V1hhhTnOx/3aa681dZUAAADQKjU5dA8fPrzO4y+++CI99dRTaezYsekXv/hFJcsGAAAAbSt0x5RhDbngggvS448/XokyAQAAQKtQsT7d2223XbrxxhsrtToAAABo8SoWum+44YbUo0ePSq0OAAAA2l7z8nXXXbfOQGqlUim988476f3330+///3vK10+AAAAaDuhe5dddqnzuH379mnppZdOQ4YMSauttlolywYAAABtK3SfcMIJxZQEAAAAWpmK9ekGAAAA5jF0RzPyDh06zPHWsWPTKs7vv//+9J3vfCf16dMn9xO/5ZZb6jwf/cWPP/741Lt377TQQguloUOHpldeeaVJ7wEAAADVMtcp+eabb270ufHjx6fzzjsvzZo1q0lvPn369LT22mungw46KO26666zPX/mmWfm9f75z39OK6ywQjruuOPStttum1544YXUtWvXJr0XAAAANNvQvfPOO8+27OWXX04jRoxIY8aMSfvss086+eSTmzy3d9waErXc5557bvrVr35V895XXHFFWmaZZXKN+F577dWk9wIAAIAW0af7rbfeSoccckhac80105dffpmefvrpXBvdr1+/ihXs9ddfz1ORRZPysu7du6fBgwfnmnUAAABo7prUCXvKlCnp9NNPT+eff35aZ5110t13350222yzQgoWgTtEzXZt8bj8XENmzpyZb2VTp04tpHwAAABQsZru6F+94oorpttuuy1dc8016eGHHy4scM+PUaNG5Rrx8q1v377VLhIAAABt1FzXdEff7RhBfMCAAbkpedwactNNN1WkYL169cr/vvvuu3n08rJ4HLXsjRk5cmQ6+uij69R0C94AAAA069C933775Wm9FpQYrTyCdzRhL4fsCNCPPvpo+slPftLo33Xp0iXfAAAAoMWE7ssvv7zib/7pp5+mCRMm1Bk8LQZl69GjR1p++eXT8OHD06mnnppWXnnlminDYk7vXXbZpeJlAQAAgKoOpFZpjz/+eNpyyy1rHpebhe+///455B9zzDF5Lu9hw4alTz75JG266aZp7Nix5ugGAACgRahq6B4yZEiej7sx0Zw95v5u6vzfAAAA0GLn6QYAAAC+ntANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAABoi6H7xBNPTO3atatzW2211apdLAAAAJgrHVMzN3DgwDRu3Liaxx07NvsiAwAAQNbsE2yE7F69elW7GAAAANC6mpeHV155JfXp0yetuOKKaZ999kmTJk2a4+tnzpyZpk6dWucGAAAA1dCsQ/fgwYPT5ZdfnsaOHZsuvPDC9Prrr6fNNtssTZs2rdG/GTVqVOrevXvNrW/fvgu0zAAAANAiQvd2222Xvve976W11lorbbvttunvf/97+uSTT9J1113X6N+MHDkyTZkypeY2efLkBVpmAAAAaDF9umtbfPHF0yqrrJImTJjQ6Gu6dOmSbwAAAFBtzbqmu75PP/00vfrqq6l3797VLgoAAAC07ND985//PN13331p4sSJ6eGHH07f/e53U4cOHdLee+9d7aIBAABAy25e/uabb+aA/eGHH6all146bbrppumRRx7J9wEAAKC5a9ah+9prr612EQAAAKB1Ni8HAACAlkzoBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACtKxqBUDAAAwd/qPuL3aRWhWJo7eIbUWaroBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAANCWQ/cFF1yQ+vfvn7p27ZoGDx6cHnvssWoXCQAAAFp+6P7rX/+ajj766HTCCSekJ598Mq299tpp2223Te+99161iwYAAAAtO3SfffbZ6ZBDDkkHHnhgWmONNdIf/vCH1K1bt3TppZdWu2gAAAAwRx1TM/b555+nJ554Io0cObJmWfv27dPQoUPT+PHjG/ybmTNn5lvZlClT8r9Tp05Nzd2smTOqXYRmpRLfmW06O9u1GLZr5dmmxbBdi2G7Vp5tWgzbtfIqlTNs17paQn4rl7FUKs3xde1KX/eKKnrrrbfSsssumx5++OG00UYb1Sw/5phj0n333ZceffTR2f7mxBNPTCeddNICLikAAABt0eTJk9Nyyy3XMmu650XUikcf8LJZs2aljz76KC255JKpXbt2VS1bSxBXa/r27Zt3nMUWW6zaxWk1bNfKs02LYbsWw3atPNu0GLZrMWzXyrNNi2G7Nk3UX0+bNi316dNnjq9r1qF7qaWWSh06dEjvvvtuneXxuFevXg3+TZcuXfKttsUXX7zQcrZG8SPzQ6s827XybNNi2K7FsF0rzzYthu1aDNu18mzTYtiuc6979+4teyC1zp07p/XXXz/dfffddWqu43Ht5uYAAADQHDXrmu4QTcX333//9I1vfCNtuOGG6dxzz03Tp0/Po5kDAABAc9bsQ/eee+6Z3n///XT88cend955J62zzjpp7NixaZlllql20VqlaJofc6LXb6LP/LFdK882LYbtWgzbtfJs02LYrsWwXSvPNi2G7VqMZj16OQAAALRkzbpPNwAAALRkQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidMMC8MUXX6RXXnklTZkypdpFAYA6vvrqqzqPH3300XT//ffn/3dReR9//HG64oorql0MaNDrr7+e7rrrrvTcc89VuyititBNmj59ev6f61//+td0/fXXpyeeeCKZSW7enXnmmel///tfzYnMz3/+87TIIouk1VZbLS211FLpoIMOciJTQbbl/G27Y445Jg0YMCBtuOGG6dJLL63z/Lvvvps6dOhQtfK1NvbVyjvppJPSBx98UO1itFhvv/122nTTTfN8vFtssUUOgzvuuGPaaKON0pAhQ9KgQYPya6isSZMmpQMPPLDaxYD005/+NH366af5fpy77r777vmcYNttt01rr712+ta3vlXzPPNH6G7DZs2alU+4e/bsmbbccsv0/e9/P+25555pgw02SCussEIaM2ZMtYvYIo0cOTJNmzYt3z/nnHNykPnDH/6Qnn322XT55Zen22+/PS+naa677rr0+eef1zz+3e9+l/r165e6du2aL2acfPLJVS1fS3Taaafl2pYf//jHaZtttklHH310+tGPflTnNS7ANZ19tfKmTp062y1aDsU+/Nprr9Uso2mOPfbY/Bu/+eabU+/evXPgju04efLkNHHixLT00kvnbcz876+1b+VzBJrm97//fRo6dGjaY4890t13313nubj4tuKKK1atbC3VRRddlGbMmJHvn3LKKbmVy7hx43LQjgq5uEDkGFAhJdqsY489trT66quXxowZU7rrrrtKm2++eemMM84ovfjii6Xjjjuu1KVLl9Idd9xR7WK2OO3atSu9++67+f66665buuiii+o8/5e//KU0cODAKpWu5Wrfvn3Ndr300ktLXbt2LR1//PGl22+/vXTqqaeWFl544dLFF19c7WK2KAMGDMi//7JXXnklLzvggANKs2bNKr3zzjt5u9M09tVitmlDtzje1v6Xpundu3dp/Pjx+f6HH36Yt+O4ceNqnr/77rtLK664YhVL2DKV98ev22+Ze7/97W9L3bp1Kx166KGlfffdt9S5c+fS6aefXvO8/1/N/znroEGDSldffXWd52+99dbSKqusUqXStS7t4j+VCvC0LH369MlNyjfbbLP8+L///W9uAh1XC6OpWVzx+sc//pEefvjhahe1RWnfvn1ulhs1BFGrde+99+YmerX7ysTjaNZP07brO++8k1tmDB48ODeB+sUvflHz/IUXXpguvvji9OSTT1a1nC1Jt27d0gsvvJD69+9fsyyOA9GcLFq8RFeJvn37ztbfkzmzr1becsstl9ZZZ530s5/9LG/fEKcvUev1pz/9KbfOCtFEmrm30EILpf/85z/5dx6iK9TTTz+dm5eGqOWK84JyTRhzp3v37umXv/xl/v03JMZ4iVZFjq1zb+DAgXmbRqvMEOemu+yyS26pFa2H4rwrzmtt03k/Z41bnLPGti5744030uqrr+4YUAEdK7ESWqZoOrLsssvWPI6mZZ999lnu09WrV6+02267pdGjR1e1jC1VnFDHyUvnzp3TRx99VOe5aFYWFzVounbt2uV/ozlpNIeuLR5HU0nmXvzOX3311TqhO44J99xzT+5ycsABB1S1fC2ZfbWynnnmmXTwwQfni8FXXnllzf+7YjvHeARrrLFGtYvYIsWFoeizXQ7dhx12WOrRo0fN83E+sPDCC1exhC3TeuutN8eLQIsvvriuO00UFRYbb7xxzeO4/89//jNfeIvxMoYPH17V8rVkxx13XL4IHwH8rbfeqhO6P/zwQ8eACtGnuw1bc8010zXXXFOnH2IExTgRL/f5Fg6bbvnll8+hO/ptx/arX5sVgWbVVVetWvlasrFjx6a//e1vuW9s/auuccGoHHSYO1GjffXVV8+2PGoL4mQmTnKYN/bVyoogGP2Ov/e97+WQXfv/Xcy7aD0wfvz4msdxob126H7wwQfTWmutVaXStVxRGxu//cbEedYJJ5ywQMvU0kXLwRhroLZoNRj/r7rsssvyGEU03eabb55efvnl9NRTT+WLl1GzXdvf//73OiGcead5eRsWg1DssMMOeXTC+J9DNNX59a9/XXO18De/+U1uXl5/sArmzyOPPJLD+LrrrlvtorQo5SalZVHjFU3Nyi655JJ0wQUXaLLbBPE/15deeimPUtqQuOId04bsv//+C7xsLZl9tVjRJSJCTZwgxowb//73v9V0F+Sxxx7LNWC1u0hBNcRvfplllmlwINrnn38+t86KWlnNyysrWmtFq83o4sP8EbrbuDhZiRrumTNn5hPvrbfeutpFgnly2223pU6dOjUaIKG5sK/OvxgdfsSIEbnl0E033VTTpxtovV1MYkrbxqZaizmlb7zxRi0IaLaEbijohPCWW27JzfZiQKVyc7Log7Tzzjvnq4bQHNhXoW1zDKi8N998s2aKwPDAAw/kqUNjYLqYPvDQQw/Nc6FDtdlXFxyhmzqiD+eECRPyoGqak82b2H5RgxVNc2Pk0mgOFWJ0yJj/MJroRLP98uiwNL25Y/2Tw/gfQvTzpGnsq8Wyry6YbRrhMEbbp+kcA4oR2zIGp4p5z2+99da066675vsxCnSMFh+tXaKFRiyjaRxXK8u+ugBVd8YyquknP/lJadq0afn+jBkzSrvttlud+SO33HLLmueZe0OHDi3tvPPOpSlTpsz2XCyL57bZZpuqlK0li3kkN91007x/9uvXr7ThhhvmW9yPZfFcea5J5o59tRj21cqzTYvhGFCMhRdeuPTaa6/l+4MHDy6NHj26zvPnn39+ad11161S6Vqm+H1vsskmjgEVZl9dcITuNiyCdfkANXLkyNJyyy1X+uc//1maPn166cEHHyyttNJKpREjRlS7mC3OQgstVHr22Wcbff6ZZ57Jr6Fp4qLQRhttVHrppZdmey6WbbzxxqXdd9+9KmVrqeyrxbCvVp5tWgzHgGJ079699O9//zvf79mzZ839sgkTJpS6detWpdK1TI4BxbCvLjimDGvDavcsGDNmTDrzzDPz6I8xUukmm2ySzj777NykhKaJ+TcnTpzY6PPxXLyGprnjjjvyiM8NTbcWy84777w8TRNzz75aDPtq5dmmxXAMKEbMz12e1i5mKrn33nvrPB8DAJbnmmfuOAYUw7664HRcgO9FM1SeKzb6xtSfizOmEqs/JyJf74c//GHab7/9ch+Zrbbaqk4fuZh+7dRTT02HH354tYvZ4sQ0a1OnTm30+WnTpplXvonsq8Wwr1aebVoMx4BixHznm222We4rv+mmm+YpA//1r3/lfrIxJ/Jf//rXPFgVc88xoBj21QVoAdaq08xEH5gf/ehHpaOOOio3KbnzzjvrPP/EE0+UllpqqaqVryWLPjG9e/eu6R9f7isfy84444xqF69F+ulPf5r7bt100011+h/G/VjWv3//0mGHHVbVMrZE9tXKs69Wnm1aHMeAYkSz3L322qu06KKL5u0Zt06dOuVm0DfffHO1i9fiOAYUx766YBi9vA0bMmRITU132GefffJV77K4wj1u3LjZmprQtNHga4+waS7ZeRdzyQ8fPjxdeuml6csvv6yZxiamu+nYsWM6+OCD0znnnONK9zyyr1aOfbXybNPiOQYUI06z33vvvTRr1qw8LVOnTp2qXaQWyTGgePbVYgndNOq1117LB7WYMgSai2he9vjjj+fmj+WTw/XXXz8ttthi1S4azLavPvHEE3WCjH11/tim0LY5B6ClErqpMX369HTdddfVzNO99957pyWXXLLaxWqRfve73+W5JLfffvu01157pSuvvDKNGjUqXz2MORBPPvnkfGWWuRf9CvfYY4/c94jKePLJJ9MSSyxRU6MV+2n03Zo0aVLq169fOuyww/L+S+WOrX369Mnb1LF1/timleEYUAzbtfKcAxTHOesCsoCasdMMrb766qUPP/ww3580aVLuKxNTB2ywwQalHj165H7e5bn7mHunnHJK7hcT01v06tUr95dbcsklS6eeemrp9NNPLy299NKl448/vtrFbHHK/Q1XXnnlvE3ffvvtahepxVtrrbVKd911V75/8cUX56mBjjjiiNKFF15YGj58eGmRRRYpXXLJJdUuZos/tkZfQ8fW+WObFsMxoBi2a+U5ByiGc9YFR+hu4wew8jzd++yzTx4w4ZNPPsmPp02bVho6dGhp7733rnIpW56Y3/zGG2/M959++ulShw4dSn/5y19qno8BPwYMGFDFErbc/XXcuHGlI488Mg/wF4N87LTTTqUxY8aUvvrqq2oXr0WKE8GJEyfm++uuu27pj3/8Y53nr7rqqtIaa6xRpdK1XI6tlWebFsMxoBi2a+U5ByiGc9YFxzzdZOPHj08nnnhi6t69e368yCKLpJNOOik9+OCD1S5aixPTLnzjG9+omXatffv2aZ111ql5fr311suvoenWXHPNdO655+bt95e//CUPrLLLLrukvn375mkuoqkpc69bt27pgw8+yPf/+9//pg033LDO84MHD86DKzHvHFsrzzatHMeAYtiuxXAOUHnOWRccobuNK49e/tlnn+V+3LUtu+yy6f33369SyVquGNTjhRdeyPdfeeWV9NVXX9U8Ds8//3zq2bNnFUvY8sWImtG3a+zYsXnAv0MOOSRdddVVadVVV6120VqU7bbbLl144YX5/hZbbJFuuOGGOs9Hn9kBAwZUqXQtm2Nr5dmmlecYUAzbtVjOASrHOeuCo1d8G7fVVlvlwRFiNMiXX345DRo0qOa5N954w8A08yCmXttvv/3SzjvvnO6+++50zDHHpJ///Ofpww8/zCeNp512Wtp9992rXcxWY/nll8+1XieccEKe4o65d8YZZ6RNNtkknxTGle6zzjorTxG4+uqr5+PBI488km6++eZqF7NFcmytPNu08hwDimG7LjjOAeaPc9YFR+huw+IAVVs00attzJgxRomcB9HMcaGFFspNIOPq64gRI3KTnTiQzZgxI33nO99Jp5xySrWL2eLEiK8dOnRo9Pn4n8PWW2+9QMvU0sWoz0899VQaPXp0/r3HOB8xgunkyZPzCeNDDz1U0+yMuefYWnm2aTEcA4phu1aec4BiOGddcEwZBgAAAAXRpxsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugGAOmIKnnXWWafaxQCAVkHoBoAqOeCAA/JUN/Vv3/72t6tarpinNeZsXVChPh6XP3vMxb3UUkulzTffPJ177rlp5syZhZUDABYE83QDQBVFwL7sssvqLOvSpUth7/f555+nzp07z/E1MQ92/bmwizZw4MA0bty4NGvWrPThhx+me++9N5166qnpyiuvzPcXXXTRBVoeAKgUNd0AUEURsHv16lXntsQSS+TnImxGQH7ggQdqXn/mmWemnj17pnfffTc/njx5ctpjjz3S4osvnnr06JF23nnnNHHixDq16bvssks67bTTUp8+fdKqq66al7/55ptp7733zn+z8MILp2984xvp0UcfbbAmOsqx4YYb5tfF+2yyySbpjTfeqHn+1ltvTeutt17q2rVrWnHFFdNJJ52UvvzyyyZth6jhjs8eZVxzzTXT4Ycfnu6777703HPPpTPOOGOety8AVJvQDQDN1JAhQ9Lw4cPTD37wgzRlypT01FNPpeOOOy796U9/Sssss0z64osv0rbbbptrgSOYP/TQQ7mGOmrPo0a7LJqKv/zyy+muu+5Kt912W/r000/TFltskf773/+mv/3tb+nf//53OuaYY3Itc30RniO0x+ufeeaZNH78+DRs2LDcFDzE++63337pyCOPTC+88EK66KKL0uWXX55D/vxabbXV0nbbbZduuumm+V4XAFSL5uUAUEURgus35f6///u/fAvRxDrCcgTdqPXdf//900477ZSf++tf/5qDcoTwcgiOpupRGx2109tss01eFjXU8Zpys/I//vGP6f3330//+te/ck13GDBgQIPlmzp1ag78O+64Y1pppZXystVXX73m+ajVHjFiRC5XiJruU045JYf4E044oSLB+84775zv9QBAtQjdAFBFW265ZbrwwgvrLCsH4RBB+aqrrkprrbVW6tevXzrnnHNqnosa6gkTJszW3/mzzz5Lr776as3jaK5dux/3008/ndZdd90679OYeE00UY8a9a233joNHTo0N2fv3bt3TRmihr12zfZXX32VyzBjxozUrVu3ND9KpVLNBQUAaImEbgCooqiFbqyWuezhhx/O/3700Uf5Fn8Topn4+uuvn0N5fUsvvXSd96htoYUWalIZo/b8iCOOSGPHjs2167/61a9y7fs3v/nNXIao7d51111n+7vo4z2/XnzxxbTCCivM93oAoFr06QaAZixqrI866qh08cUXp8GDB+dm3OW+1zF42SuvvJIHVovgXvvWvXv3RtcZteZR2x0Bfm5FzfjIkSPzBYBBgwalq6++uqYM0V+8/vvHrX37+TvNeOmll3LQ32233eZrPQBQTUI3AFRRzEP9zjvv1Ll98MEHNc20991339y0+8ADD8w1zjGY2VlnnZWf32efffKc1jFieQxo9vrrr+e+3FErHaOTNyZGLY+RwmOAtGga/tprr6Ubb7wxD5JWX6wzwnY8FyOWR//qCPrlft3HH398uuKKK3Jt9/PPP59rpq+99tpcG94UMWBbfPa33norPfvss+n888/Pg7fFKOq/+MUvmrhVAaD50LwcAKooanLL/aPLYlqvqOWNftIRdGOwtRCvi0HQIjTHIGlrr712uv/++9Oxxx6bm3dPmzYtLbvssmmrrbZKiy22WKPvGf27Izz/7Gc/S9tvv30OvGussUa64IILZntt9MmOsvz5z3/O82dHGQ499ND0ox/9KD8fFwSifCeffHKe2qtTp0558LMf/vCHTdoOEdhj3R06dMi19FGeCPs/+clPCp23HACK1q4UI5QAAAAAFad5OQAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAABSMf4f1AK5o8PazWUAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics for submissions per exercise (Stat):\n",
      "count    10.000000\n",
      "mean     20.000000\n",
      "std      12.866839\n",
      "min       9.000000\n",
      "25%       9.500000\n",
      "50%      16.500000\n",
      "75%      24.250000\n",
      "max      48.000000\n",
      "Name: Submissions, dtype: float64\n",
      "\n",
      "Summary statistics for submissions per exercise (Mat):\n",
      "count    10.000000\n",
      "mean     20.000000\n",
      "std       7.859884\n",
      "min       2.000000\n",
      "25%      18.000000\n",
      "50%      22.500000\n",
      "75%      24.750000\n",
      "max      28.000000\n",
      "Name: Submissions, dtype: float64\n",
      "Unique exercises in Stat set: 10\n",
      "Unique exercises in Mat set: 10\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check the data",
   "id": "c526f28915f19ef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:49:56.401642Z",
     "start_time": "2025-01-05T11:49:55.508991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Check number of unique exercises\n",
    "unique_exercises_stat = len(set(d[\"task_id\"] for d in evaluation_data_stat_stratified))\n",
    "unique_exercises_mat = len(set(d[\"task_id\"] for d in evaluation_data_mat_stratified))\n",
    "\n",
    "print(f\"Total exercises in Stat set: {unique_exercises_stat}\")\n",
    "print(f\"Total exercises in Mat set: {unique_exercises_mat}\")\n",
    "\n",
    "# Count submissions per exercise for each dataset\n",
    "def count_submissions_by_exercise(data):\n",
    "    counts = {}\n",
    "    for entry in data:\n",
    "        task_id = entry[\"task_id\"]\n",
    "        counts[task_id] = counts.get(task_id, 0) + 1\n",
    "    return counts\n",
    "\n",
    "counts_stat = count_submissions_by_exercise(evaluation_data_stat_stratified)\n",
    "counts_mat = count_submissions_by_exercise(evaluation_data_mat_stratified)\n",
    "\n",
    "# Convert counts to DataFrame for visualization\n",
    "df_stat = pd.DataFrame(list(counts_stat.items()), columns=[\"Exercise\", \"Submissions\"])\n",
    "df_mat = pd.DataFrame(list(counts_mat.items()), columns=[\"Exercise\", \"Submissions\"])\n",
    "\n",
    "# Plot distribution of submissions per exercise\n",
    "def plot_submissions_distribution(df, title):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(df[\"Exercise\"].astype(str), df[\"Submissions\"])\n",
    "    plt.xlabel(\"Exercise ID\")\n",
    "    plt.ylabel(\"Number of Submissions\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_submissions_distribution(df_stat, \"Distribution of Submissions per Exercise (Stat Set)\")\n",
    "plot_submissions_distribution(df_mat, \"Distribution of Submissions per Exercise (Mat Set)\")\n",
    "\n",
    "# Summary statistics for submissions per exercise\n",
    "stat_summary = df_stat[\"Submissions\"].describe()\n",
    "mat_summary = df_mat[\"Submissions\"].describe()\n",
    "\n",
    "print(\"Stat Submissions per Exercise Summary:\")\n",
    "print(stat_summary)\n",
    "\n",
    "print(\"\\nMat Submissions per Exercise Summary:\")\n",
    "print(mat_summary)\n"
   ],
   "id": "172566c4736b5274",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'task_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Check number of unique exercises\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m unique_exercises_stat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtask_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mevaluation_data_stat_stratified\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      6\u001B[0m unique_exercises_mat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(d[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_id\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m evaluation_data_mat_stratified))\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal exercises in Stat set: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munique_exercises_stat\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[17], line 5\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Check number of unique exercises\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m unique_exercises_stat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtask_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m evaluation_data_stat_stratified))\n\u001B[1;32m      6\u001B[0m unique_exercises_mat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(d[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_id\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m evaluation_data_mat_stratified))\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal exercises in Stat set: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munique_exercises_stat\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'task_id'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:34:25.101489Z",
     "start_time": "2025-01-05T10:34:06.015941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the evaluation data\n",
    "evaluation_data_stat = []\n",
    "evaluation_data_mat = []\n",
    "for _, submission in submissions_df.iterrows():\n",
    "    course = tasks_df.loc[tasks_df['id'] == submission['task_id'], 'course_slug'].values[0]\n",
    "    if course == \"fs24-sta120\":\n",
    "        evaluation_data_stat.append({\n",
    "            \"question\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'instruction'].values[0], # Get the question from the tasks_df using the task_id in the submissions_df\n",
    "            \"answer\":  submission['content'],\n",
    "            \"modelSolution\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'solution'].values[0],\n",
    "            \"maxPoints\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'max_points'].values[0],\n",
    "            \"minPoints\": 0,  # Default minPoints\n",
    "            \"pointStep\": 0.5,  # Default pointStep\n",
    "            \"human_points\": submission['points']\n",
    "        })\n",
    "    elif course == \"fs24-mat183\":\n",
    "        evaluation_data_mat.append({\n",
    "            \"question\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'instruction'].values[0], # Get the question from the tasks_df using the task_id in the submissions_df\n",
    "            \"answer\":  submission['content'],\n",
    "            \"modelSolution\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'solution'].values[0],\n",
    "            \"maxPoints\": tasks_df.loc[tasks_df['id'] == submission['task_id'], 'max_points'].values[0],\n",
    "            \"minPoints\": 0,  # Default minPoints\n",
    "            \"pointStep\": 0.5,  # Default pointStep\n",
    "            \"human_points\": submission['points']\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Unknown course_slug: {course}\")\n",
    "    "
   ],
   "id": "b49a87bde04791e5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T10:34:25.105412Z",
     "start_time": "2025-01-05T10:34:25.103112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(evaluation_data_stat[:5])\n",
    "print(evaluation_data_mat[:5])\n",
    "print(f\"Total submissions to evaluate: {len(evaluation_data_stat)}\")\n",
    "print(f\"Total submissions to evaluate: {len(evaluation_data_mat)}\")"
   ],
   "id": "3ddfeecf586bad0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': \"The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany.\\nSimulate a 95\\\\% confidence interval for the sample mean of the variable SRM based on the following bootstrap scheme (sampling with replacement):\\nRepeat $10'000$ times\\n    - Sample $544$ observations $Z_{i}$ with replacement\\\\\\n    - Calculate and store the mean of these sampled observations\\\\\\nConstruct the confidence interval by taking the 2.5\\\\% and the 97.5\\\\% quantiles of the stored means.\\n\", 'answer': 'require(spam)\\ndata(Oral)\\n\\nn <- 544\\nset.seed(3)\\n\\n# Room for creativity!\\nboot_means <- replicate(10000, {\\n  sampled_indices <- sample(1:n, replace = TRUE)\\n  mean(Oral$q[sampled_indices])\\n})\\n\\nsol <- quantile(boot_means, c(0.025, 0.975), na.rm = TRUE)\\n', 'modelSolution': 'require(spam) \\ndata(Oral) \\nn <- 544\\nmybootstrap <- function(n.replications){ \\n temporary <- array(0, dim = n.replications) # Preallocation is always advisable! \\n for(i in 1:n.replications){ \\n   temporary[i] = mean(sample(Oral$SMR, size = n, replace = T)) \\n } \\n return(as.numeric(temporary)) \\n} \\nset.seed(3) \\nsim.mean2 <- mybootstrap(10000) \\nsol <- quantile(sim.mean2, c(0.025, 0.975)) ', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 0.5}, {'question': 'For the case below, specify the null and alternative hypothesis. \\nThen use R to perform the $t$-tests.\\n$\\\\mu_{\\\\text{Hb S}\\\\beta} = \\\\mu_{\\\\text{Hb SS}}$ ($\\\\alpha = 1\\\\%$, two-sided).\\nAs the solution, return the p.value from the t.test, the alternative hypothesis of the test, and the confidence interval for the difference in the means between two groups. \\nMake sure you get those from the attributes of the t.test object and not manually (so that it can be automatically compared).\\n', 'answer': 'HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1,\\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt <- t.test(HbSS, HbSb, var.equal = TRUE, conf.level = 0.99)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci = ci, alt_hyp = alt_hyp)', 'modelSolution': 'HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1,\\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt <- t.test(HbSb, HbSS, var.equal = TRUE, conf = 0.99)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, alt_hyp = alt_hyp)', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 0.5}, {'question': 'What changes, if in a one-sided test is performed instead, compared to Exercise 1?\\n', 'answer': 'HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt_two_sided <- t.test( HbSb , mu = 10 ) # same call as in Task 01\\ntt_one_sided <- t.test( HbSb , mu = 10 , alternative = \"greater\" )\\n\\np_ratio <- tt_two_sided$p.value / tt_one_sided$p.value # What is the ratio of the two p values? Numerator the one like Task 01, Denominator the current one.\\n\\nsol <- list(ratio = p_ratio)', 'modelSolution': 'HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt_two_sided <- t.test( HbSb , mu = 10 ) # same call as in Task 01\\ntt_one_sided <- t.test(HbSb, mu = 10, alternative = \"greater\")\\n\\np_ratio <- tt_two_sided$p.value /  tt_one_sided$p.value # What is the ratio of the two p values? Numerator the one like Task 01, Denominator the current one.\\n\\nsol<- list(ratio = p_ratio)', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}, {'question': 'We now use all data jointly and use ```districtSize``` as a predictor as well. \\nHowever, ```districtSize``` is not numerical, rather categorical and thus we set ```mydata$districtSize <- as.factor(mydata$districtSize)```.   \\nFit a linear model using ```salary``` as the response variable and ```districtSize``` and ```experience``` as the predictors.  \\nIs there an effect of ```experience``` and/or ```districtSize```?   \\nHow can we interpret the parameter estimates?\\n', 'answer': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\nmydata$districtSize <- as.factor( mydata$districtSize )\\nstr( mydata )\\nlength(unique( mydata ))\\n#Note that the elements in the column District are all distinct, so they can be thought as \\'\\'labels\\'\\' for the observations. Therefore, we discard such columns when fitting the linear model.\\nfit <- lm(salary ~ districtSize + experience , data = mydata)\\nsummary(fit)\\npar(mfrow = c(2, 2))\\nplot(fit)\\ndev.off()', 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\nmydata$districtSize <- as.factor(mydata$districtSize)\\nstr(mydata)\\nlength(unique(mydata$District))\\n#Note that the elements in the column District are all distinct, so they can be thought as \\'\\'labels\\'\\' for the observations. Therefore, we discard such columns when fitting the linear model.\\nfit <- lm(salary ~ experience + districtSize, data = mydata)\\nsummary(fit)\\npar(mfrow = c(2, 2))\\nplot(fit)\\ndev.off()', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}, {'question': 'Require the package fields. Display the volcano data with the function image.plot(). What is the maximum height of the volcano?', 'answer': 'png(file = \"solution.png\")\\nrequire(fields) # Or library(fields) \\nimage.plot(volcano) # Check out the plot in your R-Studio\\n# function which.max() returns you the highest value of your dataset (there is also which.min())\\n\\nmax_height <- which.max(volcano)\\ndev.off()\\n\\n', 'modelSolution': 'png(file = \"solution.png\")\\nrequire(fields) # Or library(fields) \\nimage.plot(volcano) # Check out the plot in your R-Studio\\n# function which.max() returns you the heighest value of your dataset (there is also which.min())\\n\\nmax_height <- volcano[which.max(volcano)] \\ndev.off()\\n\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}]\n",
      "[{'question': 'And now plot the density function of this continuous distribution:\\n\\n* Uniform distribution, $X\\\\sim U[0, 3]$.\\n\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Uniforme Verteilung\\na <- 0\\nb <- 3\\nx <- seq(a, b, 0.1)\\ny = dunif(x,min = a, max = b)\\nplot(\\n\\tx, \\n\\ty , \\n\\ttype=\"s\", \\n\\tlwd=5, \\n\\txlab=\"x\", \\n\\tylab=\"f(x)\", \\n\\txaxt=\"n\",\\n\\txlim=c(a-1, b+1), \\n\\tmain=\"Uniform, X~U[0,3]\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=x, labels=x)\\nev <- (a + b) / 2\\nabline(h=0, lty=3)\\nabline(v=ev, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\n#abline(v=c(... - ..., ... + ... ), lty=2)\\n\\ndev.off()\\n', 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Uniforme Verteilung\\na <- 0\\nb <- 3\\nx <- seq(a, b, 0.1)\\nplot(x, dunif(x, min=a, max=b), type=\"s\", lwd=5, xlab=\"x\", ylab=\"f(x)\", xaxt=\"n\",\\n\\txlim=c(a-1, b+1), main=\"Uniform, X~U[0,3]\", col=\"blue\")\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=(a+b)/2, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c((a+b)/2-sqrt((b-a)^2/12), (a+b)/2+sqrt((b-a)^2/12)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}, {'question': 'Plot the density function of this continuous distribution:\\n    \\n* Normal distribution, $X\\\\sim N(0,3)$,\\n\\nEx.: the distribution of length variations in some machined parts, with standard deviation $\\\\sqrt{3}$.\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(\\n\\tx, \\n\\tdnorm(x, mean=0, sd=3, log=FALSE), \\n\\ttype=\"l\", \\n\\tlwd=5, \\n\\tylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=0, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(0 - sqrt(3), 0 + sqrt(3) ), lty=2)\\n\\ndev.off()\\n', 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(x, dnorm(x, mean=mu, sd=sqrt(sigma2)), type=\"l\", lwd=5, ylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", col=\"blue\")\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu-sqrt(sigma2), mu+sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 0.0}, {'question': 'Plot the density function of this continuous distribution:\\n    \\n* Normal distribution, $X\\\\sim N(0,3)$,\\n\\nEx.: the distribution of length variations in some machined parts, with standard deviation $\\\\sqrt{3}$.\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nsigma <- sqrt(sigma2)\\ny <- dnorm(x, mean = mu, sd = sigma, )\\nplot(\\n\\tx, \\n\\ty, \\n\\ttype=\"l\", \\n\\tlwd=5, \\n\\tylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu -sigma, mu + sigma ), lty=2)\\n\\ndev.off()\\n', 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(x, dnorm(x, mean=mu, sd=sqrt(sigma2)), type=\"l\", lwd=5, ylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", col=\"blue\")\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu-sqrt(sigma2), mu+sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}, {'question': 'Plot the density function of this continuous distribution:\\n    \\n* Normal distribution, $X\\\\sim N(0,3)$,\\n\\nEx.: the distribution of length variations in some machined parts, with standard deviation $\\\\sqrt{3}$.\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(\\n\\tx, \\n\\tdnorm(x,mean=0,sd=sqrt(3)), \\n\\ttype=\"l\", \\n\\tlwd=5, \\n\\tylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=0, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(0 - sqrt(3), 0 + sqrt(8) ), lty=2)\\n\\ndev.off()\\n', 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(x, dnorm(x, mean=mu, sd=sqrt(sigma2)), type=\"l\", lwd=5, ylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", col=\"blue\")\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu-sqrt(sigma2), mu+sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 0.0}, {'question': 'Plot the density function of this continuous distribution:\\n    \\n* Normal distribution, $X\\\\sim N(0,3)$,\\n\\nEx.: the distribution of length variations in some machined parts, with standard deviation $\\\\sqrt{3}$.\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(\\n\\tx, \\n\\tdnorm(x,mean=0,sd=sqrt(3)), \\n\\ttype=\"l\", \\n\\tlwd=5, \\n\\tylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=0, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(0 - sqrt(3), 0 + sqrt(3) ), lty=2)\\n\\ndev.off()\\n', 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(x, dnorm(x, mean=mu, sd=sqrt(sigma2)), type=\"l\", lwd=5, ylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", col=\"blue\")\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu-sqrt(sigma2), mu+sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': np.float64(1.0), 'minPoints': 0, 'pointStep': 0.5, 'human_points': 1.0}]\n",
      "Total submissions to evaluate: 18267\n",
      "Total submissions to evaluate: 37022\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n",
    "We use parallelism here to speed up the evaluation process. We evaluate the submissions using the LLM and compare the results with the human-assigned points."
   ],
   "id": "7ef5a6c17edd8bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:24:26.187184Z",
     "start_time": "2025-01-05T11:24:26.177223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Function to evaluate the submissions using the LLM\n",
    "def evaluate(to_evaluate, solution=False, cot=False, voting=1):\n",
    "    EVALUATION_URL = \"http://localhost:4000/evaluate\"\n",
    "    tracker = []\n",
    "    accuracy_tracker = []\n",
    "    logs = []\n",
    "\n",
    "    def calculate_accuracy(human_points, llm_points, max_points):\n",
    "        if max_points == 0:\n",
    "            return 1  # Avoid division by zero\n",
    "        diff = abs(human_points - llm_points)\n",
    "        return 1 - diff / max_points\n",
    "\n",
    "    for idx, submission in enumerate(tqdm(to_evaluate, desc=\"Evaluating submissions\"), start=1):\n",
    "        try:\n",
    "            # Prepare payload for the API\n",
    "            payload = prepare_payload(submission, solution=solution, cot=cot, voting=voting)\n",
    "            # Make API call for evaluation\n",
    "            response = requests.post(EVALUATION_URL, json=payload, headers={\"Content-Type\": \"application/json\"})\n",
    "            response.raise_for_status()\n",
    "            evaluation_result = response.json()\n",
    "\n",
    "            # Extract LLM-assigned points and rubric data\n",
    "            llm_points = evaluation_result.get(\"points\", 0)\n",
    "            max_points = payload[\"maxPoints\"]\n",
    "            human_points = submission.get(\"human_points\", 0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = calculate_accuracy(human_points, llm_points, max_points)\n",
    "\n",
    "            tracker.append({\n",
    "                \"human_points\": human_points,\n",
    "                \"gpt_points\": llm_points,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"evaluation_result\": evaluation_result,\n",
    "                \"submission\": submission,  # Store the original submission\n",
    "            })\n",
    "            accuracy_tracker.append(accuracy)\n",
    "\n",
    "            # Add logs\n",
    "            logs.append(f\"Submission {idx} Result: {evaluation_result}\")\n",
    "            logs.append(f\"Human Points: {human_points}, GPT Points: {llm_points}\")\n",
    "            logs.append(f\"Accuracy: {accuracy:.2%}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error evaluating submission {idx}: {e}\")\n",
    "            logs.append(f\"Error evaluating submission {idx}: {e}\")\n",
    "\n",
    "    average_accuracy = sum(accuracy_tracker) / len(accuracy_tracker) if accuracy_tracker else 0\n",
    "\n",
    "    return tracker, average_accuracy, logs\n",
    "\n",
    "\n",
    "def prepare_payload(submission, solution=False, cot=False, voting=1):\n",
    "    # Create a deep copy to avoid modifying the original\n",
    "    submission_copy = copy.deepcopy(submission)\n",
    "\n",
    "    # Ensure required fields exist with default values\n",
    "    submission_copy.setdefault(\"rubrics\", [])\n",
    "    submission_copy.setdefault(\"modelSolution\", \"\")\n",
    "    submission_copy.setdefault(\"temperature\", 0)\n",
    "    submission_copy.setdefault(\"llmType\", \"gpt\")\n",
    "\n",
    "    # Adjust optional fields\n",
    "    if not solution:\n",
    "        submission_copy.pop(\"modelSolution\", None)\n",
    "        submission_copy.pop(\"rubrics\", None)  # Remove rubrics if not using solution\n",
    "\n",
    "    # Add chain of thought and voting parameters\n",
    "    submission_copy[\"chainOfThought\"] = cot\n",
    "    submission_copy[\"votingCount\"] = voting\n",
    "\n",
    "    # Convert np.float64 to float for numeric fields\n",
    "    submission_copy[\"maxPoints\"] = float(submission_copy.get(\"maxPoints\", 0))\n",
    "    submission_copy[\"minPoints\"] = float(submission_copy.get(\"minPoints\", 0))\n",
    "    submission_copy[\"pointStep\"] = float(submission_copy.get(\"pointStep\", 0))\n",
    "\n",
    "    return {\n",
    "        \"question\": submission_copy[\"question\"],\n",
    "        \"answer\": submission_copy[\"answer\"],\n",
    "        \"rubrics\": submission_copy.get(\"rubrics\", []),\n",
    "        \"modelSolution\": submission_copy.get(\"modelSolution\", \"Undefined\"),\n",
    "        \"maxPoints\": submission_copy[\"maxPoints\"],\n",
    "        \"minPoints\": submission_copy[\"minPoints\"],\n",
    "        \"pointStep\": submission_copy[\"pointStep\"],\n",
    "        \"temperature\": 0,\n",
    "        \"llmType\": \"gpt\",\n",
    "        \"chainOfThought\": cot,\n",
    "        \"votingCount\": voting,\n",
    "    }\n"
   ],
   "id": "7407f570301313f1",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "55fe6bfa67f3757f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:02:18.188200Z",
     "start_time": "2025-01-05T11:02:18.184227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.parallel_evaluate import parallel_evaluate\n",
    "\n",
    "# Parallel evaluation setup\n",
    "num_threads = 4  # Adjust based on your CPU cores, keep it at max 4 due to rate limits.\n",
    "batch_size = 25\n",
    "\n",
    "# Sample size for evaluation in total\n",
    "sample_size = 100\n",
    "\n",
    "# Number of groups for stratified sampling, the more groups the more well distributed the sample. Generally this should increase with the sample size\n",
    "num_groups = 6"
   ],
   "id": "9600a39b2b165765",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stratified Sampling",
   "id": "6a7146fe43764f78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:02:18.538867Z",
     "start_time": "2025-01-05T11:02:18.522228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.stratified_sample import stratified_random_sample\n",
    "\n",
    "# Get well distributed sample (assuming maxPoints = roughly difficulty)\n",
    "evaluation_data_stat_rand = stratified_random_sample(evaluation_data_stat, sample_size=sample_size, num_groups=num_groups)\n",
    "\n",
    "# evaluate random stratified subset of mat\n",
    "evaluation_data_mat_rand = stratified_random_sample(evaluation_data_mat, sample_size=sample_size, num_groups=num_groups)\n"
   ],
   "id": "12b8260471c9ed37",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate each case\n",
    "We evaluate the submissions using different strategies to see how they affect the accuracy of the LLM."
   ],
   "id": "a56cb79f9581283c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Without Voting, CoT and Solutions\n",
    "This represents the most basic evaluation setup, accuracy should be lowest here.\n"
   ],
   "id": "43be5d33b1876c1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:03:12.246237Z",
     "start_time": "2025-01-05T11:02:19.733628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate random subset of stat without including solutions\n",
    "stat_tracker_no_solutions, stat_accuracy_no_solutions, stat_logs_no_solutions = parallel_evaluate(\n",
    "    evaluation_data_stat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"Satistics Set: Average Accuracy without any strategiesy-y: {stat_accuracy_no_solutions:.2%}\")\n"
   ],
   "id": "de4f0f8a3adfd160",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating batch...Evaluating batch...\n",
      "\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ae678ee7dc24c8daffb310fdf5f9eb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8437241d19974b7a9bc6d4be243600ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a5ae779aa53426aaa6412aafda8f5f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b47d109422f4041bad9039e19425dbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Satistics Set: Average Accuracy without any strategies: 70.00%\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:14:30.661566Z",
     "start_time": "2025-01-05T11:13:42.342919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mat_tracker_no_solutions, mat_accuracy_no_solutions, mat_logs_no_solutions = parallel_evaluate(evaluation_data_mat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size)\n",
    "print(f\"Maths Set: Average Accuracy without any strategies: {mat_accuracy_no_solutions:.2%}\")\n"
   ],
   "id": "109ede9a981f9c65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating batch...Evaluating batch...\n",
      "\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e3c4f36b79e4c2a97de90b973ded613"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ab8f611b7f544abbf0e87a11f3806a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a282b1bfff24dddbb92c2e7fcef06e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f74250d720e74cb78cf73fec11eb440b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maths Set: Average Accuracy without any strategies: 72.50%\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### With Solutions\n",
    "We add the solutions to the evaluation data to see how it affects the accuracy of the LLM."
   ],
   "id": "be5305dd7c43adab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:22:34.510600Z",
     "start_time": "2025-01-05T11:21:38.842318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "stat_tracker, stat_accuracy, stat_logs = parallel_evaluate(evaluation_data_stat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True)\n",
    "print(f\"Statistics Set: Average Accuracy with added solutions: {stat_accuracy:.2%}\")\n"
   ],
   "id": "cb6c2fe2b1c796a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating batch...Evaluating batch...\n",
      "\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "887977a80c4041a29937d1915fe87507"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9cecba483bc46d5a635109446b8acad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5c3f246592e422d90b16473931e0b31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b81ff620996b40e180c534341e9ac28e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"In a simple linear regression, the data are assumed to follow $Y_i = \\\\beta_0 + \\\\beta_1 x_i  + \\\\varepsilon_i$ with $\\\\varepsilon_i \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(0, \\\\sigma^2)$, $i = 1, \\\\dots, n$. \\nWe simulate $n = 15$ data points from that model with $\\\\beta_0 = 1$, $\\\\beta_1 = 2$, $\\\\sigma = 2$ and the following values for $x_i$.\\n\\nPlot the simulated data in a scatter plot in your Rstudio. Calculate the Pearson correlation coefficient and the Spearman's rank correlation coefficient. Why do they agree well? \\n\\nEstimate the linear regression coefficients $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ using the formulas from the script. \\n\\n*PS* -  The same code will repeat multiple time during this exercise. We recommend you to copy your final code and save it somewhere for the next exercise.\\n\", 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true*x \\n\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\n# Use formulas from the script\\nsx <- sqrt(sum((x - x.mean)^2))\\nsy <- sqrt(sum((y - y.mean)^2))\\nbeta1.hat <- pearson_cor*sy/sx\\nbeta0.hat <- y.mean - beta1.hat*x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor, \\n     Spearman_correlation_coefficients = spearman_cor,\\n\\t beta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'rubrics': [], 'modelSolution': 'set.seed(5)         \\nbeta0.true <- 1     \\nbeta1.true <- 2     \\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nplot(data)\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor,\\n            Spearman_correlation_coefficients = spearman_cor,\\n\\t\\t\\tbeta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We choose the following gamma prior density for the parameter $\\\\kappa$:\\n$$\\nf(\\\\kappa \\\\mid \\\\alpha,\\\\beta) =\\n    \\\\begin{cases}\\n        \\\\frac{\\\\beta^{\\\\alpha}}{\\\\Gamma(\\\\alpha)} \\\\kappa^{\\\\alpha-1} \\\\exp(-\\\\beta \\\\kappa), & \\\\text{if $\\\\kappa > 0$},\\\\\\\\\\n      0, & \\\\text{otherwise},\\n\\\\end{cases}\\n$$\\nfor fixed {hyper-parameters} $\\\\alpha > 0$, $\\\\beta > 0$, i.e. $\\\\kappa \\\\sim \\\\mathcal{G}am(\\\\alpha, \\\\beta)$. How does this distribution relate to the exponential distribution?\\n\\nPlot four densities for $(\\\\alpha, \\\\beta)$ = (1,1), (1,2), (2,1) and (2,2). How can a certain choice of $\\\\alpha, \\\\beta$ be interpreted with respect to our ''beliefs'' on $\\\\kappa$?\\n\", 'answer': 'png(file=\"solution.png\")\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1 , 1 , 2 , 2 )  # shape\\nbeta <- c( 1 , 2 , 1 , 2 )  # rate\\nplot ( grid , dgamma( grid , shape =  alpha[1] , rate = beta[1] ),\\n     type = \"l\", lwd = 2, col = 2,\\n     xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 2 : 4 ){\\n  lines ( grid , dgamma ( grid , shape = alpha[i] , rate =  beta[i] ),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1, 1, 2, 2)  # shape\\nbeta <- c(1, 2, 1, 2)  # rate\\nplot(grid, dgamma(grid, shape = alpha[1], rate = beta[1]),\\n     type = \"l\", lwd = 2, col = 2,\\n     xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 2:4){\\n  lines(grid, dgamma(grid, shape = alpha[i], rate = beta[i]),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin. The dataset anorexia in the package MASS gives the weight in pounds of 72 females before and after a treatment, consisting of control, cognitive behavioral treatment and family treatment. \\\\\\nIn this exercise we only want to compare the control treatment (Cont) with the family treatment (FT). \\\\\\nVisualize the weight difference before and after the control treatment and the family treatment in a boxplot.\\n\\n*Do not change the plot functions*\\n', 'answer': 'png(file=\"solution.png\")\\nrequire(MASS)\\n# Try to replace \"%%%\" with with proper operator, to get the right output.\\n# This might help: https://www.statmethods.net/management/operators.html\\nmyAnorexia <- anorexia[ anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ] # Make sure you choose proper groups.\\nmyAnorexia <- droplevels(myAnorexia)\\n# Calculate the difference between Postwt and Prewt: \\nanorexiaDiff <-  myAnorexia$Postwt - myAnorexia$Prewt\\nboxplot( anorexiaDiff ~ myAnorexia$Treat, \\n         xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nrequire(MASS)\\n myAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\n myAnorexia <- droplevels(myAnorexia)\\n anorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt\\n boxplot(anorexiaDiff ~ myAnorexia$Treat, \\n         xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Fit a one-way ANOVA with log(OC) as response variable and Behandlung as explanatory variable. \\nHint: Use ```lm()``` and perform an ```anova()``` on the output. \\nDo not forget to check the model assumptions.\\n', 'answer': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\n\\nfit1lm <- lm(logOC ~ Behandlung, data = chem)\\nfit1lm_anova <- anova(fit1lm)\\n\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot(fit1lm_anova)\\n\\nsol <- list(owANOVA = fit1lm_anova)', 'rubrics': [], 'modelSolution': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nfit1lm <- lm(logOC ~ Behandlung, data = chem)\\nfit1lm_anova <- anova(fit1lm)\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot(fit1lm)\\nsol <- list(owANOVA = fit1lm_anova)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Let $X_{1}, \\\\dots, X_{n}$ be independent and identically distributed (iid) exponential random variables with parameter $\\\\lambda > 0$, i.e. $X_{1}, \\\\dots, X_{n} \\\\underset{iid}{\\\\sim} Exp(\\\\lambda)$. Assume $\\\\lambda = 2$ for the following. \\\\\\nDraw a histogram of $500$ realizations from $\\\\min(X_{1}, \\\\dots, X_{100})$.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\n\\nset.seed(100)\\nn <- 100\\n\\n# What would be the best way to sample something once, but to have 500 samples?\\n# Generate a matrix with dimensions 500 rows by \\'n\\' columns, \\n# where each element is drawn from an exponential distribution with a rate parameter of 2.\\nartificial <- matrix (dexp (n,2) , 500, n)\\n\\n# Find the minimum of each sample. You can use the function apply().\\nrowmins <- apply(artificial,c(1,2),min)\\n\\npar(mfrow = c(1, 2))\\nhist(rowmins, prob = TRUE, xlab = \"Sample minima\", ylim = c(0, n*2),\\n   main = \"\", breaks = 30) # default value for breaks is a bit too small\\nrug(rowmins) # in case `breaks` are not optimal \\n\\n# Compare it  with theoretical density using curve() function\\ncurve( dexp(x,2*n) , col = \"red\", add = TRUE) # theoretical density like in the previous task\\n\\n### Additionaly plot the  QQ-plot against theoretical quantile fucntion.\\nqqplot( artificial , rowmins, xlab = \"Exp(2n)\")\\nqqline( artificial , distribution = function(p){qexp(p, rate = 2*n)} )\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(100)\\nn <- 100\\n\\nartificial <- matrix(rexp(n * 500, rate = 2), 500, n)\\n\\nrowmins <- apply(artificial, 1, min)\\n\\npar(mfrow = c(1, 2))\\nhist(rowmins, prob = TRUE, xlab = \"Sample minima\", ylim = c(0, n*2),\\n  main = \"\", breaks = 30) # default value for breaks is a bit too small\\nrug(rowmins) # in case `breaks` are not optimal \\n\\ncurve(dexp(x, rate = n * 2), col = \"red\", add = TRUE) # theoretical density from (b)\\n\\nqqplot(qexp(ppoints(100), rate = 2*n), rowmins, xlab = \"Exp(2n)\")\\nqqline(rowmins, distribution = function(p){qexp(p, rate = 2*n)} )\\n\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Suppose that among $n=95$ Swiss males, eight are red-green colour blind. We are interested in estimating the proportion $p$ of people suffering from such disease among the male population.  \\n\\nCompute a 95\\\\% Wilson confidence interval and compare it to the confidence intervals obtained in (d).  \\nHint: Use the formula for the CI given in equation 6.11 in the script and define your own R function for calculating the CI.\\n', 'answer': 'n <- 95\\nx <- 8\\n\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  \\n  phat <- x/n\\n  q <- qnorm(1-alpha/2)\\n  \\n  CI <- 1/(1+(q^2)/n) * (phat + (q^2)/(2*n) + c(-1, 1) * q * sqrt(phat * (1-phat)/n + (q^2)/4*n^2))\\n  \\n  \\n  return(CI)\\n}\\n\\nCI <- WilsonCI(x, n)\\n\\nsol <- list(CI = CI)', 'rubrics': [], 'modelSolution': 'n <- 95\\nx <- 8\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  p_hat <- x/n\\n  q <- qnorm(1-alpha/2)\\n  CI <- 1/(1 + (q^2)/n) * (p_hat + q^2/(2*n) + \\n                             c(-1, 1) * q * sqrt( p_hat*(1-p_hat)/n + q^2/(4*n^2) ))\\n  return(CI)\\n}\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For the mtcars dataset (available by default through the package datasets), use standard and robust estimates for location and scale for miles/gallon, number of cylinders and weight and compare the results.\\n', 'answer': 'require(datasets)\\ndata(mtcars)\\n# miles/gallon\\nlocation_mpg <-  c(mean(mtcars$mpg) , # Mean\\n                   mean(mtcars$mpg,trim=0.1) , # 10% Trimmed Mean\\n                   median(mtcars$miles) ) # Median\\nspread_mpg <- c(sd(mtcars$mpg) , # Standart deviation \\n                (sd(mtcars$mpg) /1.349), # IQR \\n                mad(mtcars$mpg) ) # MAD\\n\\n# number of cylinders\\nlocation_cyl <- c(mean(mtcars$cyl), # Mean\\n                  mean(mtcars$cyl,trim=0.1) , #10% Trimmed Mean\\n                  mad(mtcars$cyl)) # Median\\nspread_cyl <- c(sd(mtcars$cyl) , # Standart deviation \\n                (sd(mtcars$cyl)/1.349), # IQR \\n                mad(mtcars$cyl)) # MAD\\n\\n# weight\\nlocation_wt <- c(mean(mtcars$wt) , # Mean\\n                 mean(mtcars$wt,trim=0.1) , #10% Trimmed Mean\\n                 median(mtcars$wt)) # Median\\nspread_wt <- c(sd(mtcars$wt) , # Standart deviation \\n                (sd(mtcars$wt)/1.349), # IQR \\n               mad(mtcars$wt)) # MAD\\n\\nsol <- list(location_mpg = location_mpg, \\n     spread_mpg = spread_mpg, \\n     location_cyl = location_cyl, \\n     spread_cyl = spread_cyl, \\n     location_wt = location_wt, \\n     spread_wt = spread_wt)\\n', 'rubrics': [], 'modelSolution': 'require(datasets)\\n\\n# miles/gallon\\nlocation_mpg <-  c(mean(mtcars$mpg), \\n                   mean(mtcars$mpg, trim = 0.1), \\n                   median(mtcars$mpg))\\nspread_mpg <- c(sd(mtcars$mpg), \\n                IQR(mtcars$mpg)/1.349, \\n                mad(mtcars$mpg))\\n\\n# number of cylinders\\nlocation_cyl <- c(mean(mtcars$cyl), \\n                  mean(mtcars$cyl, trim = 0.1), \\n                  median(mtcars$cyl))\\nspread_cyl <- c(sd(mtcars$cyl), \\n                IQR(mtcars$cyl)/1.349, \\n                mad(mtcars$cyl))\\n\\n# weight\\nlocation_wt <- c(mean(mtcars$wt), \\n                 mean(mtcars$wt, trim = 0.1), \\n                 median(mtcars$wt))\\nspread_wt <- c(sd(mtcars$wt), \\n               IQR(mtcars$wt)/1.349, \\n               mad(mtcars$wt))\\n\\nsol <- list(location_mpg = location_mpg, \\n     spread_mpg = spread_mpg, \\n     location_cyl = location_cyl, \\n     spread_cyl = spread_cyl, \\n     location_wt = location_wt, \\n     spread_wt = spread_wt)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For the mtcars dataset (available by default through the package datasets), use standard and robust estimates for location and scale for miles/gallon, number of cylinders and weight and compare the results.\\n', 'answer': 'require(datasets)\\ndata = mtcars\\n# miles/gallon\\nlocation_mpg <-  c(mean(data$mpg), # Mean\\n                   mean(data$mpg,trim = 0.1), #10% Trimmed Mean\\n                   median(data$mpg)) # Median\\n\\nspread_mpg <- c(sd(data$mpg), # Standart deviation \\n                IQR(data$mpg)/1.349, # IQR \\n                mad(data$mpg)) # MAD\\n\\n# number of cylinders\\nlocation_cyl <- c(mean(data$cyl), # Mean\\n                   mean(data$cyl,trim = 0.1), #10% Trimmed Mean\\n                   median(data$cyl)) # Median\\nspread_cyl <- c(sd(data$cyl), # Standart deviation \\n                IQR(data$cyl)/1.349, # IQR \\n                mad(data$cyl)) # MAD\\n\\n# weight\\nlocation_wt <- c(mean(data$wt), # Mean\\n                 mean(data$wt,trim = 0.1), #10% Trimmed Mean\\n                 median(data$wt)) # Median\\nspread_wt <- c(sd(data$wt), # Standart deviation \\n               IQR(data$wt)/1.349, # IQR \\n               mad(data$wt)) # MAD\\n\\nsol <- list(location_mpg = location_mpg, \\n     spread_mpg = spread_mpg, \\n     location_cyl = location_cyl, \\n     spread_cyl = spread_cyl, \\n     location_wt = location_wt, \\n     spread_wt = spread_wt)\\nprint(sol)\\n', 'rubrics': [], 'modelSolution': 'require(datasets)\\n\\n# miles/gallon\\nlocation_mpg <-  c(mean(mtcars$mpg), \\n                   mean(mtcars$mpg, trim = 0.1), \\n                   median(mtcars$mpg))\\nspread_mpg <- c(sd(mtcars$mpg), \\n                IQR(mtcars$mpg)/1.349, \\n                mad(mtcars$mpg))\\n\\n# number of cylinders\\nlocation_cyl <- c(mean(mtcars$cyl), \\n                  mean(mtcars$cyl, trim = 0.1), \\n                  median(mtcars$cyl))\\nspread_cyl <- c(sd(mtcars$cyl), \\n                IQR(mtcars$cyl)/1.349, \\n                mad(mtcars$cyl))\\n\\n# weight\\nlocation_wt <- c(mean(mtcars$wt), \\n                 mean(mtcars$wt, trim = 0.1), \\n                 median(mtcars$wt))\\nspread_wt <- c(sd(mtcars$wt), \\n               IQR(mtcars$wt)/1.349, \\n               mad(mtcars$wt))\\n\\nsol <- list(location_mpg = location_mpg, \\n     spread_mpg = spread_mpg, \\n     location_cyl = location_cyl, \\n     spread_cyl = spread_cyl, \\n     location_wt = location_wt, \\n     spread_wt = spread_wt)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In a simple linear regression, the data are assumed to follow $Y_i = \\\\beta_0 + \\\\beta_1 x_i  + \\\\varepsilon_i$ with $\\\\varepsilon_i \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(0, \\\\sigma^2)$, $i = 1, \\\\dots, n$. \\nWe simulate $n = 15$ data points from that model with $\\\\beta_0 = 1$, $\\\\beta_1 = 2$, $\\\\sigma = 2$ and the following values for $x_i$.\\n\\nPlot the simulated data in a scatter plot in your Rstudio. Calculate the Pearson correlation coefficient and the Spearman's rank correlation coefficient. Why do they agree well? \\n\\nEstimate the linear regression coefficients $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ using the formulas from the script. \\n\\n*PS* -  The same code will repeat multiple time during this exercise. We recommend you to copy your final code and save it somewhere for the next exercise.\\n\", 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true*x + rnorm(n = 15, mean = 0, sd = 2)\\n\\n\\npearson_cor <- cor.test( x , y , method = \"pearson\")\\nspearman_cor <- cor.test ( x , y , method = \"spearman\")\\n# ?cor.test\\n# These two correlation coe\"cients are comparable because in the \\n# scatterplot there are no evident outliers.\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\n# Use formulas from the script\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\n\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor, \\n            Spearman_correlation_coefficients = spearman_cor,\\n            beta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'rubrics': [], 'modelSolution': 'set.seed(5)         \\nbeta0.true <- 1     \\nbeta1.true <- 2     \\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nplot(data)\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor,\\n            Spearman_correlation_coefficients = spearman_cor,\\n\\t\\t\\tbeta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany.\\nSimulate a 95\\\\% confidence interval for the sample mean of the variable SRM based on the following bootstrap scheme (sampling with replacement):\\nRepeat $10'000$ times\\n    - Sample $544$ observations $Z_{i}$ with replacement\\\\\\n    - Calculate and store the mean of these sampled observations\\\\\\nConstruct the confidence interval by taking the 2.5\\\\% and the 97.5\\\\% quantiles of the stored means.\\n\", 'answer': 'require(spam) \\ndata(Oral) \\n\\nn <- 544\\nset.seed(3) \\n\\n# Room for creativity!\\nsim <- function(n.replications) {\\n    temp <- array(0, dim = n.replications)\\n    for(i in 1:n.replications) {\\n        temp[i] = mean(sample(Oral$SMR, size = n, replace = T))\\n    }\\n    return(as.numeric(temp))\\n} \\n\\n\\nsol <- quantile( sim(10000) , c(0.025, 0.975)) \\n', 'rubrics': [], 'modelSolution': 'require(spam) \\ndata(Oral) \\nn <- 544\\nmybootstrap <- function(n.replications){ \\n temporary <- array(0, dim = n.replications) # Preallocation is always advisable! \\n for(i in 1:n.replications){ \\n   temporary[i] = mean(sample(Oral$SMR, size = n, replace = T)) \\n } \\n return(as.numeric(temporary)) \\n} \\nset.seed(3) \\nsim.mean2 <- mybootstrap(10000) \\nsol <- quantile(sim.mean2, c(0.025, 0.975)) ', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For the case below, specify the null and alternative hypothesis. \\nThen use R to perform the $t$-tests.\\n$\\\\mu_{\\\\text{Hb S}\\\\beta} = \\\\mu_{\\\\text{Hb SS}}$ ($\\\\alpha = 1\\\\%$, two-sided).\\nAs the solution, return the p.value from the t.test, the alternative hypothesis of the test, and the confidence interval for the difference in the means between two groups. \\nMake sure you get those from the attributes of the t.test object and not manually (so that it can be automatically compared).\\n', 'answer': 'HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1,\\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt <- t.test(HbSS, HbSb, var.equal = TRUE, conf = 0.99)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, alt_hyp = alt_hyp)', 'rubrics': [], 'modelSolution': 'HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1,\\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt <- t.test(HbSb, HbSS, var.equal = TRUE, conf = 0.99)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, alt_hyp = alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For the control treatment and the family treatment, perform an individual paired  Wilcoxon signed rank test to compare the weight before and after the treatment.\\n', 'answer': 'require(MASS)\\nmyAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\",] # Same split as in previous exercise.\\nmyAnorexia <- droplevels(myAnorexia)\\n\\naCont <- myAnorexia[ myAnorexia$Treat == \"Cont\", ] # Choose only Treat = \"Cont\"\\nwilcox_cont <-  wilcox.test (aCont$Prewt, aCont$Postwt, paired = TRUE, exact = FALSE) #Prewt VS Postwt\\n\\naFT <- myAnorexia[myAnorexia$Treat == \"FT\",] # Choose only Treat = \"FT\"\\nwilcox_FT <- wilcox.test(aFT$Prewt, aFT$Postwt, paired = TRUE, exact = FALSE) #Prewt VS Postwt\\n\\nsol <- list(wilcox_cont = wilcox_cont$p.value, wilcox_FT = wilcox_FT$p.value)', 'rubrics': [], 'modelSolution': 'require(MASS)\\nmyAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\nmyAnorexia <- droplevels(myAnorexia)\\n\\naCont <- myAnorexia[myAnorexia$Treat == \"Cont\",]\\nwilcox_cont <- wilcox.test(aCont$Prewt, aCont$Postwt, paired = TRUE, exact = FALSE)\\n\\naFT <- myAnorexia[myAnorexia$Treat == \"FT\",]\\nwilcox_FT <- wilcox.test(aFT$Prewt, aFT$Postwt, paired = TRUE, exact = FALSE)\\n\\nsol <- list(wilcox_cont = wilcox_cont$p.value, wilcox_FT = wilcox_FT$p.value)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'What changes, if in a one-sided test is performed instead, compared to Exercise 1?\\n', 'answer': 'HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt_two_sided <- t.test( HbSb , mu = 10 ) # same call as in Task 01\\ntt_one_sided <- t.test( HbSb , mu = 10 , alternative = \"greater\" )\\n\\np_ratio <- tt_two_sided$p.value/tt_one_sided$p.value # What is the ratio of the two p values? Numerator the one like Task 01, Denominator the current one.\\n\\nsol <- list(ratio = p_ratio)', 'rubrics': [], 'modelSolution': 'HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\ntt_two_sided <- t.test( HbSb , mu = 10 ) # same call as in Task 01\\ntt_one_sided <- t.test(HbSb, mu = 10, alternative = \"greater\")\\n\\np_ratio <- tt_two_sided$p.value /  tt_one_sided$p.value # What is the ratio of the two p values? Numerator the one like Task 01, Denominator the current one.\\n\\nsol<- list(ratio = p_ratio)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin.  \\nThe dataset anorexia in the package MASS gives the weight (in pounds) of 29 females before and after a cognitive behavioral treatment (CBT).  \\nTest whether the treatment was effective.\\nTo do this, return as a solution the p-value of the t.test, the 95 percent confidence interval of the difference between post and pre treatment, and the alternative hypothesis.\\nTo obtain the right difference (direction), make sure to use the pre-treatment weight first, and then the post-treatment weight.\\nYou can assume that the variances are equal, i.e. use the setting ``` var.equal=TRUE```.\\n', 'answer': 'require(MASS)\\ndata(anorexia)\\n\\n\\ntt <- t.test(anorexia[anorexia$Treat==\"CBT\",]$Prewt, \\n             anorexia[anorexia$Treat==\"CBT\",]$Postwt, paired = TRUE)\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'rubrics': [], 'modelSolution': 'require(MASS)\\ndata(anorexia)\\n\\nanorexiaCBT <- subset(anorexia, Treat == \"CBT\")\\ntt <- t.test(anorexiaCBT$Prewt, anorexiaCBT$Postwt, paired = TRUE)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We choose the following gamma prior density for the parameter $\\\\kappa$:\\n$$\\nf(\\\\kappa \\\\mid \\\\alpha,\\\\beta) =\\n    \\\\begin{cases}\\n        \\\\frac{\\\\beta^{\\\\alpha}}{\\\\Gamma(\\\\alpha)} \\\\kappa^{\\\\alpha-1} \\\\exp(-\\\\beta \\\\kappa), & \\\\text{if $\\\\kappa > 0$},\\\\\\\\\\n      0, & \\\\text{otherwise},\\n\\\\end{cases}\\n$$\\nfor fixed {hyper-parameters} $\\\\alpha > 0$, $\\\\beta > 0$, i.e. $\\\\kappa \\\\sim \\\\mathcal{G}am(\\\\alpha, \\\\beta)$. How does this distribution relate to the exponential distribution?\\n\\nPlot four densities for $(\\\\alpha, \\\\beta)$ = (1,1), (1,2), (2,1) and (2,2). How can a certain choice of $\\\\alpha, \\\\beta$ be interpreted with respect to our ''beliefs'' on $\\\\kappa$?\\n\", 'answer': 'png(file=\"solution.png\")\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1 , 1 , 2 , 2 )  # shape\\nbeta <- c( 1 , 2 , 1 , 2 )  # rate\\nplot (grid, dgamma( grid , shape =  alpha[1] , rate = beta[1] ),\\n     type = \"l\", lwd = 2, col = 2,\\n     xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 2 : 4 ){\\n  lines ( grid , dgamma ( grid , shape = alpha[i] , rate =  beta[i] ),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1, 1, 2, 2)  # shape\\nbeta <- c(1, 2, 1, 2)  # rate\\nplot(grid, dgamma(grid, shape = alpha[1], rate = beta[1]),\\n     type = \"l\", lwd = 2, col = 2,\\n     xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 2:4){\\n  lines(grid, dgamma(grid, shape = alpha[i], rate = beta[i]),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Under the null hypothesis, we are allowed to permute the observations (all $y$-values) while keeping the group assignments fix. Keeping this in mind, we will now manually construct a permutation test to detect a potential shift. Write an R function ```perm_test()``` that implements a two-sample permutation test and returns the $p$-value. Your function should execute the following steps.\\n\\n1. Compute the test statistic $t_\\\\text{obs} = \\\\displaystyle \\\\widetilde y_A - \\\\widetilde y_B$, where $\\\\,\\\\widetilde{\\\\cdot}\\\\,$ denotes the empirical median. For the grading, make sure your group $y_A$ contains the measurements taken at ```12-26 Weeks``` , and the group $y_B$ contains the measurements taken ```At term```.\\n2. Then repeat many times (e.g. $R = 1000$) \\n    - Randomly assign all the values of ```pd``` to two groups $x_A$ and $x_B$ of the same size as $y_A$ and $y_B$. \\n    - Store the test statistic $t_\\\\text{sim}  = \\\\widetilde x_A - \\\\widetilde x_B $. \\n3. Return the two-sided $p$-value, i.e. the number of permuted test statistics $t_\\\\text{sim}$ which are smaller or equal than $-\\\\vert t_\\\\text{obs} \\\\vert$ or larger or equal than $\\\\vert t_\\\\text{obs} \\\\vert$ divided by the total number of permutations (in our case $R = 1000$).\\n\\n**Important for the access grading**: The path bug has been fixed, if you want to run your script, the path can remain ```read.csv(\"resource/07water_transfer.txt\")```.\\nYou do not have to change the dots anymore for running and submission.\\n', 'answer': 'mydata <- read.csv(\"../resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y)\\n  # Store the data without the group labels ( try using c() )\\n  all.data <- c(x, y)           \\n  tsim <- array(0, R )           # Preallocation of R-amount of values\\n  for(i in length(tsim) ){\\n    index <- sample(x = 1:length(all.data), size = length(x), replace = FALSE) # random permutation\\n    medianxA <- median(all.data[index]) # Sample median of group A\\n    medianxB <- median(all.data[-index]) # Sample median of group B\\n    tsim[i] <- medianxA -medianxB  # Difference for the current iteration\\n  }\\n  # Sample p-value. Proportion of \"some\" values and amount of iterations  \\n  return( sum( abs( tsim ) >= abs( tobs ))/ R)  \\n}\\n\\n# We test our function:\\nyA <- mydata[ mydata$age == \"At term\", 1]  # Split the data such that you have one factor per group\\nyB <- mydata[ mydata$age == \"12-26 Weeks\",1 ] # Split the data such that you have one factor per group\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y) \\n  all.data <- c(x, y)           # Store the data without the group labels\\n  tsim <- array(0, R)           # Preallocation\\n  for(i in 1:R){\\n    index <- sample(1:length(all.data), length(x), replace = F) # random permutation\\n    medianxA <- median( all.data[ index]) # Sample mean of group A\\n    medianxB <- median( all.data[-index]) # Sample mean of group B\\n    tsim[i] <- medianxA - medianxB  # Difference for the current iteration\\n  }\\n  return(sum( abs(tsim) >= abs(tobs))/ R) # Sample p-value \\n}\\n\\n# We test our function:\\nyA <- mydata[mydata$age == \"12-26 Weeks\", 1]\\nyB <- mydata[mydata$age == \"At term\", 1]\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this problem we visualize and derive some properties of the Poisson random variable with parameter $\\\\lambda$. \\\\\\nVisualize the cdf and pmf of X $\\\\sim$ Pois($\\\\lambda$) for $\\\\lambda$ = 0.2 and $\\\\lambda$ = 2.\\nPlot the cdfs and pmfs in the same plot. Use col = \"blue\" for $\\\\lambda$ = 0.2 and col=\"red\" for $\\\\lambda$ = 2 and use `par(mfrow = c(1, 2))` to visualize the plots in one image.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\nlambda1 <- 0.2\\nlambda2 <- 2\\ngrid <- 0:8\\n\\npar(mfrow = c(1, 2))\\n\\n# PMFs\\nplot(grid, dpois(grid, lambda1), main = \"PMFs\", type = \"h\",\\n     xlab = expression(x), ylab = expression(f(x)), col = \"blue\")\\npoints(grid, dpois(grid, lambda1), col = \"blue\", pch = 20)\\npoints(grid + 0.1, dpois(grid, lambda2), type = \"h\", col = \"red\")\\npoints(grid + 0.1, dpois(grid, lambda2), col = \"red\", pch = 20)\\nlegend(\"topright\", pch = 20,\\n       legend = c(expression(lambda == 0.2), expression(lambda == 2)), \\n       col = c(\"blue\", \"red\"))\\n\\n# CDFs\\nprobs1 <- c(0, ppois(grid, lambda1))\\nprobs2 <- c(0, ppois(grid, lambda2))\\n\\nplot(stepfun(grid, probs1), verticals = TRUE, pch = 20, \\n     xlab = expression(x), ylab = expression(F(x)), \\n     main = \"CDFs\", col = \"blue\")\\nplot(stepfun(grid, probs2), verticals = TRUE, add = TRUE, pch = 20, col = \"red\")\\nlegend(\"bottomright\", pch = 20, \\n       legend = c(expression(lambda == 0.2), expression(lambda == 2)), col = c(\"blue\", \"red\"))\\n  \\ndev.off()\\n', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nlambda1 <- 0.2\\n lambda2 <- 2\\n\\n grid <- 0:8\\n \\n par(mfrow = c(1, 2))\\n plot(grid, dpois(grid, lambda1), main = \"PMFs\", type = \"h\",\\n      xlab = expression(x), ylab = expression(f(x)), col = \"blue\")\\n points(grid, dpois(grid, lambda1), col = \"blue\", pch = 20)\\n points((grid)+0.1, dpois(grid, lambda2), type = \"h\", col = \"red\")\\n points((grid)+0.1, dpois(grid, lambda2), col = \"red\", pch = 20)\\n legend(\"topright\", pch = 20,\\n        legend = c(expression(lambda == 0.2), expression(lambda == 2)),\\n        col = c(\"blue\", \"red\"))\\n\\n probs1 <- c(0, ppois(grid, lambda1))\\n probs2 <- c(0, ppois(grid, lambda2))\\n\\n plot(stepfun(grid, probs1), verticals = FALSE, pch = 20, \\n      xlab = expression(x), ylab = expression(F(x)), \\n      main = \"CDFs\", col = \"blue\")\\n plot(stepfun(grid, probs2), verticals = FALSE, add = TRUE, pch = 20, col = \"red\")\\nlegend(\"bottomright\", pch = 20, \\n       legend = c(expression(lambda == 0.2), expression(lambda == 2)),\\n       col = c(\"blue\", \"red\"))\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Consider the distribution from task 1 and its plot:\\n$$     \\n     \\\\quad \\\\mu = \\\\begin{pmatrix}\\\\,1\\\\,\\\\\\\\ 2\\\\end{pmatrix},\\n     \\\\quad \\\\Sigma = \\\\begin{pmatrix}1 & 1\\\\\\\\1 & 2\\\\end{pmatrix}.\\n$$\\n\\nMark the values that can be seen as a realization of $Y \\\\mid \\\\{Z \\\\in [3,4] \\\\}$ in red. \\nAdd also 100 points from the conditional distribution $Y \\\\mid \\\\{Z = 3.5 \\\\}$ to the plot. Are the realizations of $Y \\\\mid \\\\{Z \\\\in [3,4] \\\\}$ a good approximation of $Y \\\\mid \\\\{Z = 3.5 \\\\}$? \\\\\\nHint: Use the formula (8.28) to compute the distribution of $Y \\\\mid \\\\{Z = 3.5 \\\\}$.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  require(mvtnorm)\\n  set.seed(14)\\n  mu <- c(1,2)\\n  sigma <- array(c(1,1,1,2), c(2,2))\\n  res <- res[, 1]\\n  \\n  # from (b)\\n  par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n  plot(res, xlab = \"y\", ylab = \"z\", pch = 20,\\n       xlim = c(-3, 7), ylim = c(-3, 7))\\n  \\n  # exercise now\\n  # Make sure you choose a right operator instead of \"%%%\".\\n  points(res[res[,2 ]> 3 % res[, 2]< 4, ], col = \"red\", pch = 20)\\n  z <- 3.5\\n  mu.constr <- mu[1] + sigma[1,2]*(1/sigma[2,2])* (z-mu[2])# Use formula from the lecture.\\n  sigma.constr <- sigma[1,1] - sigma[1,2]*(1/sigma[2,2]) * sigma[2,1]# Use formula from the lecture.\\n  y.constr <- rnorm(100, mu.constr, sqrt(sigma.constr)) # Generating 100 points with new mu and sigma\\n  points(y.constr, rep(z, 100), col = \"blue\", pch = 20)\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nrequire(mvtnorm)\\n set.seed(14)\\n mu <- c(1, 2)\\n sigma <- matrix(c(1, 1, 1, 2), ncol = 2)\\n res <- rmvnorm(n = 500, mean = mu, sigma = sigma)\\n \\n #from (b)\\n par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n plot(res, xlab = \"y\", ylab = \"z\", pch = 20,\\n      xlim = c(-3, 7), ylim = c(-3, 7))\\n \\n #exercise now\\n points(res[res[,2] > 3 & res[,2] < 4,], col = \"red\", pch = 20)\\n z <- 3.5\\n mu.constr <- mu[1] + sigma[1,2] * (1 / sigma[2,2]) * (z - mu[2])\\n sigma.constr <- sigma[1,1] - sigma[1,2] *(1 / sigma[2,2]) * sigma[2,1]\\n y.constr <- rnorm(100, mu.constr, sqrt(sigma.constr))\\n points(y.constr, rep(z, 100), col = \"blue\", pch = 20)\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Fit a linear model without intercept (i.e. force $\\\\beta_0$ to be zero).\\nAdd the corresponding regression line to the scatterplot.\\nDiscuss if the model fits the data *better*.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  # use the following code as a base:\\n  set.seed(5)         ## for reproducible simulations \\n  beta0.true <- 1     ## true parameters, intercept\\n  beta1.true <- 2     ## and slope\\n  ## observed x values:\\n  x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n         8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n  ## simulation of y values:\\n  y <- beta0.true + beta1.true * x + rnorm(length(x), mean = 0, sd = 2)\\n  \\n  data <- data.frame(x = x, y = y)\\n  \\n  # start here to calculate your solution for the problem:\\n  mod <- lm(y ~ x, data = data) # Basic LM\\n  mod2 <- lm(y ~ 0 + x, data = data) # b_0 = 0 LM\\n  par(mfrow = c(1, 1))\\n  plot(data)\\n  abline(mod$coefficients, col = \"red\") # fit with intercept\\n  abline(mod2$coefficients, lty = 2) # fit without intercept\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(5)         ## for reproducible simulations \\n beta0.true <- 1     ## true parameters, intercept\\n beta1.true <- 2     ## and slope\\n ## observed x values:\\n x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n        8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n ## simulation of y values:\\n y <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n \\n data <- data.frame(x = x, y = y)   \\n \\n \\n # start here to calculate your solution for the problem:\\n mod <- lm(y ~ x, data = data)\\n mod2 <- lm(y ~ 0 + x, data = data)\\n par(mfrow = c(1, 1))\\n plot(data)\\n abline(a = coef(mod)[1], b = coef(mod)[2], col = \"red\") # fit with intercept\\n abline(a = 0, b = coef(mod2)[1], lty = 2) # fit without intercept\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We assume $X\\\\sim\\\\mathcal{U}(0,8)$. Simulate $n=10,50,10000$ random numbers and visualize the histogram as well as a QQ-plot thereof. Superimpose a smoothed density to the histograms (with lines(density(...)) ). \\\\\\nUse par(mfrow = c(3, 2)) to visualize the graphs in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': 'png(file=\"solution.png\")\\n  set.seed(1)\\n  # Define the sample sizes\\n  n_values <- c(10, 50, 10000)\\n  # Define the range of the uniform distribution\\n  range_min <- 0\\n  range_max <- 8\\n  # Create a layout for the plots\\n  par(mfrow = c(3, 2))\\n  # Loop through each sample size\\n  for (n in n_values) {\\n  # Simulate random numbers from a uniform distribution\\n  x <- runif(n, min = range_min, max = range_max)\\n  # Histogram with density overlay\\n  hist(x, main = paste(\"Histogram of X\"), prob = TRUE)\\n  lines(density(x), col = \"red\")\\n  qqplot(qunif(ppoints(500)), x)\\n}\\ndev.off()\\n', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nset.seed(1)\\n theta <- 8\\n n <- c(10, 50, 10000)\\n \\n par(mfrow = c(3, 2))\\n for (k in 1:length(n)) {\\n   x <- runif(n[k], 0, theta)\\n   hist(x, prob = TRUE)\\n   lines(density(x), col = \"red\")\\n   qqplot(qunif(ppoints(500)), x)\\n }\\n dev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this problem we investigate the effect of deviations of statistical assumptions on the $p$-value. For simplicity, we use the one-sample $t$-test.   \\nFor 10'000 times, sample $X_{1}, \\\\dots, X_{10} ~ \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$ with $\\\\mu = 0$ and $\\\\sigma^{2} = 1$.  \\nFor each sample perform a $t$-test for $H_{0}: \\\\mu = 0$ and store the $p$-value thereof. \\nPlot the 10'000 $p$-values in a histogram. What do you observe?    \\nFor $\\\\alpha = 0.05$, what is the observed Type I error of the sampled data in (a)?   \\nHint: The Type I error is the probability of rejecting the null hypothesis even though it is true (here, $\\\\alpha = 0.05$).    \\nIn this setting we know that the null hypothesis $H_{0}: \\\\mu = 0$ is true because we sample from a $\\\\mathcal{N}(0, 1)$ distribution.     \\nThe observed Type I error is then the proportion of the number of rejected null hypotheses.  \\n\", 'answer': 'set.seed(5)\\n# Number of iterations\\nR <- 10000\\nn <- 10\\n\\n# Generate samples from N(0,1)\\nsamples <- matrix(rnorm(n * R), R, n)\\n\\n# Function to calculate p-value for each sample\\ngetPvalue <- function(x) {\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\n\\n# Apply t-test to each row of \\'samples\\' and store p-values\\npvals <- apply(samples, 1, getPvalue)\\n\\n# Plot histogram of p-values\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\n\\n# Calculate observed Type I error for alpha = 0.05\\nalpha <- 0.05\\nerr <- mean(pvals < alpha)\\n\\n# Store the observed Type I error rate\\nsol <- list(type_I_error = err)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\nsamples <- matrix(rnorm(n*R), R, n) # R rows, n columns\\ngetPvalue <- function(x){\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\npvals <- apply(samples, 1, getPvalue) # apply one t-test for each row of \\'samples\\'\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\nerr <- 1/R * sum(pvals < 0.05)\\nsol <- list(type_I_error = err)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Require the package fields. Display the volcano data with the function image.plot(). What is the maximum height of the volcano?', 'answer': 'png(file = \"solution.png\")\\nrequire(fields) # Or library(fields) \\n#library(fields)\\nimage.plot(volcano) # Check out the plot in your R-Studio\\n# function which.max() returns you the heighest value of your dataset (there is also which.min())\\n\\nmax_height <- volcano[which.max(volcano)]\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nrequire(fields) # Or library(fields) \\nimage.plot(volcano) # Check out the plot in your R-Studio\\n# function which.max() returns you the heighest value of your dataset (there is also which.min())\\n\\nmax_height <- volcano[which.max(volcano)] \\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany. \\\\\\nLoad the data and take a look at its help page using ?Oral. Also have look at str() of the Oral data.  \\nCompute summary statistics for all variables in the dataset.  \\nWhich of the $544$ regions has the highest number of expected counts E?  \\nAssume that the standardized mortality ratio $Z_{i} = Y_{i} / E_{i}$ is normally distributed, i.e., $Z_{1}, \\\\dots, Z_{544} \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$. \\nEstimate $\\\\mu$ and give a 95\\\\% (exact) confidence interval (CI). \\n\\nSave all results in the given list. \\\\\\nHint: The standardized mortality ratio is stored in the column SMR of the dataset Oral.\\n\\n', 'answer': 'require( spam )\\ndata( Oral )\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- 1/(n-1) * sum((Oral$SMR-mean_SMR^2))\\nS <- sqrt(S2)\\n(ci <- mean(Oral$SMR) + c(-1, 1) * qt(0.975, n-1, lower = TRUE) * S/sqrt(n))\\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'rubrics': [], 'modelSolution': 'require(spam)\\ndata(Oral)\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- 1/(n-1) * sum((Oral$SMR - mean(Oral$SMR))^2)  \\nS <- sqrt(S2) \\nci <-  mean_SMR + c(-1, 1) * qt(0.975, n-1, lower = TRUE) * S/sqrt(n) \\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin. The dataset anorexia in the package MASS gives the weight in pounds of 72 females before and after a treatment, consisting of control, cognitive behavioral treatment and family treatment. \\\\\\nIn this exercise we only want to compare the control treatment (Cont) with the family treatment (FT). \\\\\\nVisualize the weight difference before and after the control treatment and the family treatment in a boxplot.\\n\\n*Do not change the plot functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  require(MASS)\\n  # Try to replace \"%%%\" with with proper operator, to get the right output.\\n  # This might help: https://www.statmethods.net/management/operators.html\\n  myAnorexia <- anorexia[ anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ] # Make sure you choose proper groups.\\n  myAnorexia <- droplevels(myAnorexia)\\n  # Calculate the difference between Postwt and Prewt: \\n  anorexiaDiff <- myAnorexia$Postwt-myAnorexia$Prewt \\n  boxplot(anorexiaDiff ~ myAnorexia$Treat, \\n          xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nrequire(MASS)\\n myAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\n myAnorexia <- droplevels(myAnorexia)\\n anorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt\\n boxplot(anorexiaDiff ~ myAnorexia$Treat, \\n         xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Fit a one-way ANOVA with log(OC) as response variable and Behandlung as explanatory variable. \\nHint: Use ```lm()``` and perform an ```anova()``` on the output. \\nDo not forget to check the model assumptions.\\n', 'answer': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\n\\nfit1lm <- lm( logOC ~ Behandlung , data = chem)\\nfit1lm_anova <- anova( fit1lm )\\n\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot( fit1lm )\\n\\nsol <- list(owANOVA = fit1lm_anova)', 'rubrics': [], 'modelSolution': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nfit1lm <- lm(logOC ~ Behandlung, data = chem)\\nfit1lm_anova <- anova(fit1lm)\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot(fit1lm)\\nsol <- list(owANOVA = fit1lm_anova)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Let $X_{1}, \\\\dots, X_{n}$ be independent and identically distributed (iid) exponential random variables with parameter $\\\\lambda > 0$, i.e. $X_{1}, \\\\dots, X_{n} \\\\underset{iid}{\\\\sim} Exp(\\\\lambda)$. Assume $\\\\lambda = 2$ for the following. \\\\\\nDraw a histogram of $500$ realizations from $\\\\min(X_{1}, \\\\dots, X_{100})$.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\n\\nset.seed(100)\\nn <- 500\\n\\n# What would be the best way to sample something once, but to have 500 samples?\\n# Generate a matrix with dimensions 500 rows by \\'n\\' columns, \\n# where each element is drawn from an exponential distribution with a rate parameter of 2.\\nartificial <- matrix ( rexp(100*500,2) , 500, n)\\n\\n# Find the minimum of each sample. You can use the function apply().\\nrowmins <- apply(artificial, 1, min)\\n#artificial is a matrix\\n#1 stands for the rows of the matrix ie 100 i think\\n#min is the function that we apply -> it takes the minimum \\npar(mfrow = c(1, 2))\\nhist(rowmins, prob = TRUE, xlab = \"Sample minima\", ylim = c(0, n*2),\\n   main = \"\", breaks = 30) # default value for breaks is a bit too small\\nrug(rowmins) # in case `breaks` are not optimal \\n\\n# Compare it  with theoretical density using curve() function\\ncurve( dexp(x, 100*2) , col = \"red\", add = TRUE) # theoretical density like in the previous task\\n\\n### Additionaly plot the  QQ-plot against theoretical quantile fucntion.\\nqqplot( qexp(ppoints(100), 2*n) , rowmins, xlab = \"Exp(2n)\")\\nqqline( rowmins , distribution = function(p){qexp(p, rate = 2*n)} )\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(100)\\nn <- 100\\n\\nartificial <- matrix(rexp(n * 500, rate = 2), 500, n)\\n\\nrowmins <- apply(artificial, 1, min)\\n\\npar(mfrow = c(1, 2))\\nhist(rowmins, prob = TRUE, xlab = \"Sample minima\", ylim = c(0, n*2),\\n  main = \"\", breaks = 30) # default value for breaks is a bit too small\\nrug(rowmins) # in case `breaks` are not optimal \\n\\ncurve(dexp(x, rate = n * 2), col = \"red\", add = TRUE) # theoretical density from (b)\\n\\nqqplot(qexp(ppoints(100), rate = 2*n), rowmins, xlab = \"Exp(2n)\")\\nqqline(rowmins, distribution = function(p){qexp(p, rate = 2*n)} )\\n\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The ```data 10stackloss.txt``` is available on the course page. \\nIt represents the production of nitric acid in the process of oxidizing ammonia. \\nThe response variable, stack loss, is the percentage of the ingoing ammonia that escapes unabsorbed. \\nKey process variables are the airflow, the cooling water temperature (in degrees C), and the acid concentration (in percent).\\n\\nConstruct a regression model that relates the three predictors to the \\nresponse, stack loss. Check the adequacy of the model.\\n\\nHints:  \\n- Look at the data outliers\\n- Try to find an *\"optimal\"* model. Exclude predictors that do not improve the model fit. \\n- Use model diagnostics, use $t$-, $F$-tests and (adjusted) $R^2$ values to compare different models.\\n- Which data points have a (too) strong influence on the model fit?  (```influence.measures()```)\\n- Are the predictors correlated? In case of a high correlation, what are possible implications?\\n', 'answer': 'mydata <- read.table(\"resource/stackloss.txt\", header = TRUE, sep = \",\")\\nstr( mydata )\\n\\npar(mfrow = c(1, 4))\\nboxplot(mydata$Air , xlab = \"Airflow\")\\nboxplot(mydata$Temp , xlab = \"Temp\")\\nboxplot(mydata$Acid. , xlab = \"Acid.\")\\nboxplot(mydata$Stkloss , xlab = \"Stackloss\")\\n\\n# Be aware that you don\\'t see how many outliers there are if they have the exact same value. \\n# Boxplots give you an idea about the value range of outliers. \\n# You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs(mydata, gap = 0, col = c(mydata$Air>70)+1)\\n\\nfit_full <- lm(Stkloss ~ ., data = mydata)\\nsummary(fit_full)\\npar(mfrow = c(2, 2))\\nplot(fit_full)\\n\\n### Multicollinearity\\nprint(cor(mydata[c(\"Air\", \"Temp\", \"Acid.\")]))\\n\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif(fit_full)\\n\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep(fit_full)\\n\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, \\n#i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures(fit_full)\\n\\n#Let us consider a smaller (nested) model, without the non-significant predictor:\\nfit_nested <- lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\n\\n#Below, fill out whether multicollinearity exists (Yes or No), which predictor can be removed (capital first letter), and the optimal model formula (lm(...))\\nsol <- list(Multicollinearity_exists = \" No \", predictor_that_can_be_removed = \" Acid \", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata))', 'rubrics': [], 'modelSolution': 'mydata <- read.table(\"resource/stackloss.txt\", header = TRUE, sep = \",\")\\nstr(mydata)\\npar(mfrow = c(1, 4))\\nboxplot(mydata$Air, xlab = \"Airflow\")\\nboxplot(mydata$Temp, xlab = \"Temp\")\\nboxplot(mydata$Acid., xlab = \"Acid.\")\\nboxplot(mydata$Stkloss, xlab = \"Stackloss\")\\n#Be aware that you don\\'t see how many outliers there are if they have the exact same value. Boxplots give you an idea about the value range of outliers. You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs(mydata, gap = 0, col = c(mydata$Air>70)+1)\\nfit_full <- lm(Stkloss ~ ., data = mydata)\\nsummary(fit_full)\\npar(mfrow = c(2, 2))\\nplot(fit_full)\\n### Multicollinearity\\nprint(cor(mydata[c(\"Air\", \"Temp\", \"Acid.\")]))\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif(fit_full)\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep(fit_full)\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures(fit_full)\\n#Let us consider a smaller (nested) model, without the non-significant predictor. We have:\\nfit_nested <- lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\nsol <- list(Multicollinearity_exists = \"No\", predictor_that_can_be_removed = \"Acid\", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata))\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true*x + rnorm(n=15, mean=0, sd=2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean)*(y-y.mean))/sum((x-x.mean)**2)\\nbeta0.hat <- y.mean-beta1.hat*x.mean\\ny.fitted <- beta0.hat + beta1.hat *x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS/(n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2/sum((x- x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1/sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt( 0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat+ c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\nt0 <- beta0.hat/beta0.se\\nt1 <- beta1.hat/beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt(abs(t0), df = n-2 , lower.tail = F) \\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail =F)\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Let $\\\\lambda$ = 5. Plot the pmf of $X \\\\sim Pois(\\\\lambda)$ and $Y \\\\sim Bin(n, \\\\frac{\\\\lambda}{n})$ for n = 10; 100; 1000.\\nPlot the pmf of Poisson and Binomial in one graph for each n, so that you have three graphs. Use col=1 for the Poisson distribution and col=2 for the Binomial distribution. Set type=h and use `par(mfrow = c(1, 3))` to visualize the plots in one image. \\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\n\\nlambda <- 5\\ngrid <- 0:12\\nn <- c(10, 100, 1000)\\n\\npar(mfrow = c(1, 3))\\n\\nfor (i in 1:length(n)) {\\n  plot(grid, dpois(grid, lambda) , main = paste(\"n =\", n[i]), type = \"h\", #plots the probability mass function PMF of poisson dist (histogram)\\n        ylim = c(0, 0.25), xlab = \"\", ylab = \"\", col = 1)\\n  points( grid , dpois(grid, lambda), col = 1, pch = 20) #ads the points of the poisson dist so its actually pottec\\n  \\n  points( (grid) +0.1, dbinom(x= grid, size= n[i], prob= lambda/n[i]) , type = \"h\", col = 2) #plots the PMF for binomial dist. on top of it (histogram)\\n  points((grid)+0.1, dbinom(x= grid, size= n[i], prob= lambda/n[i]) , col = 2, pch = 20) #ads the points of the binom so its actually plotted\\n  \\n  legend(\"topright\", pch = 20, legend = c(\"Pois\", \"Binom\"), col = c(1, 2))\\n}\\n\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nlambda <- 5\\n grid <- 0:12\\n n <- c(10, 100, 1000)\\n \\n par(mfrow = c(1, 3))\\n for (i in 1:length(n)) {\\n   plot(grid, dpois(grid, lambda), main = paste(\"n =\", n[i]), type = \"h\",\\n        ylim = c(0, 0.25), xlab = \"\", ylab = \"\", col = 1)\\n   points(grid, dpois(grid, lambda), col = 1, pch = 20)\\n   points((grid)+0.1, dbinom(grid, size = n[i], p = lambda/n[i]), type = \"h\", col = 2)\\n   points((grid)+0.1, dbinom(grid, size = n[i], p = lambda/n[i]), col = 2, pch = 20)\\n   legend(\"topright\", pch = 20, legend = c(\"Pois\", \"Binom\"), col = c(1, 2))\\n }\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Suppose that among $n=95$ Swiss males, eight are red-green colour blind.  \\nWe are interested in estimating the proportion $p$ of people suffering from such disease among the male population.\\nIs a binomial model suitable for this problem? Why?\\nCalculate the maximum likelihood estimate (MLE) $\\\\widehat{p}_{\\\\text{ML}}$ and the MLE of the odds $\\\\widehat{\\\\omega}_{\\\\text{ML}}$. \\nHint: For $X \\\\sim Bin(n,p)$ the MLE of $p$ is given by $X/n$ (see script Chapter~6.1), and the MLE of odds is given by $\\\\frac{p_{ML}}{(1-p_{ML})}$.\\n', 'answer': 'n <- 95\\nx <- 8\\np_ML <- x/n # ML estimate of p\\nomega_ML <- p_ML/(1-p_ML) # ML estimate of the odds ratio omega\\n\\nsol <- list(p_ML = p_ML, omega_ML = omega_ML )', 'rubrics': [], 'modelSolution': 'n <- 95\\nx <- 8\\np_ML <- x/n # ML estimate of p\\nomega_ML <- p_ML/(1-p_ML) # ML estimate of the odds ratio omega\\nsol <- list(p_ML = p_ML, omega_ML = omega_ML )', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': '(Extra Points)\\nWe would like to produce a sample from the laplace distribution again, as in the previous tasks.\\nPropose an intuitive alternative sampling approach based on ```rexp()```\\n(use $\\\\lambda = 2$)\\n', 'answer': 'set.seed(1)\\nn <- 1000\\n\\nlambda <- 2\\nalt <- rexp( 1000 , lambda ) * sample(c(-1,1), size = 1000)\\n\\nsol <- list(alternative = alt)', 'rubrics': [], 'modelSolution': 'set.seed(1)\\nlambda <- 2\\nalt <- rexp(1000, rate = lambda) * sample(c(-1,1), size = 1000, replace = TRUE)\\n\\nsol <- list(alternative = alt)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany.\\nSimulate a 95\\\\% confidence interval for the sample mean of the variable SRM based on the following bootstrap scheme (sampling with replacement):\\nRepeat $10'000$ times\\n    - Sample $544$ observations $Z_{i}$ with replacement\\\\\\n    - Calculate and store the mean of these sampled observations\\\\\\nConstruct the confidence interval by taking the 2.5\\\\% and the 97.5\\\\% quantiles of the stored means.\\n\", 'answer': 'require(spam) \\ndata(Oral) \\n\\nn <- 544\\nset.seed(3) \\n\\n # Room for creativity!\\nx<-array(0, dim=10000)\\nfor(i in 1:10000){\\n  x[i]=mean(sample(Oral$SMR, n, replace = TRUE))\\n}\\n \\nsol <- quantile( x , c(0.025, 0.975) ) ', 'rubrics': [], 'modelSolution': 'require(spam) \\ndata(Oral) \\nn <- 544\\nmybootstrap <- function(n.replications){ \\n temporary <- array(0, dim = n.replications) # Preallocation is always advisable! \\n for(i in 1:n.replications){ \\n   temporary[i] = mean(sample(Oral$SMR, size = n, replace = T)) \\n } \\n return(as.numeric(temporary)) \\n} \\nset.seed(3) \\nsim.mean2 <- mybootstrap(10000) \\nsol <- quantile(sim.mean2, c(0.025, 0.975)) ', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The following hemoglobin levels of blood samples from patients with Hb SS and Hb S$\\\\beta$ sickle cell disease are given:\\n```\\nHbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, 9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n```\\nVisualize the data with boxplots. Use a list of the data to create the boxplots, i.e. ```boxplot(list())```.\\n', 'answer': 'png(file=\"solution.png\")\\n  HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n            9.1, 9.1, 9.8, 10.1, 10.3)\\n  HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n  boxplot(list(HbSS = HbSS , HbSb = HbSb ), col = c(3, 4))\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nHbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n           9.1, 9.1, 9.8, 10.1, 10.3)\\n HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n boxplot(list(HbSS = HbSS, HbSb = HbSb), col = c(3, 4))\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Calculate the residuals ($y_i - \\\\widehat{y_i}$) for all $n$ points and the residual sum of squares $SS = \\\\sum_i (y_i - \\\\widehat{y_i})^2$. \\nAre the residuals normally distributed? \\nDo the residuals increase or decrease with the fitted values?\\n', 'answer': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true+beta1.true* x + rnorm(15, mean=0, sd=2)\\n\\ndt <- data.frame(x=x, y=y)\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean)*(y-y.mean)/sum((x-x.mean)^2))\\nbeta0.hat <-y.mean-beta1.hat*x.mean\\n\\ny.fitted <- beta0.hat+beta1.hat*x \\n\\nresiduals <- y-y.fitted\\n\\nSS <- sum(residuals^2)\\n\\nsol <- list(SS = SS)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\ny.fitted <- beta0.hat + beta1.hat * x\\n\\nresiduals <- y - y.fitted\\n\\nSS <- sum(residuals^2)\\n\\nsol <- list(SS = SS)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In the following settings, calculate the probabilities and quantiles $q_1$ and $q_2$.\\n\\n$$\\nX\\\\sim \\\\mathcal{N}(2,16): \\n$$\\n$$\\n\\\\qquad P_1 = P(X<4), P_2 = P(0\\\\leq X\\\\leq 4), P(X> Q_1)=0.95, P(X< -Q_2)=0.05.\\n$$\\nYou can use the following two R commands: pnorm(a) and qnorm(b) for specific values a and b.\\n**Do not change the solution list at the bottom**\\n', 'answer': 'mu = 2\\nsigma = 4\\n\\nP1 <- pnorm(4, mean = mu, sd = sigma)\\nP2 <- pnorm(4,mean=mu,sd = sigma) - pnorm(0,mean=mu,sd = sigma)\\nQ1 <- qnorm(0.05,mean=mu,sd = sigma)\\nQ2 <- qnorm(0.95,mean=mu,sd = sigma)\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))\\nprint(sol)', 'rubrics': [], 'modelSolution': 'P1 <- pnorm(4, 2, sqrt(16))\\nP2 <- pnorm(4, 2, sqrt(16)) - pnorm(0, 2, sqrt(16))\\nQ1 <- qnorm(0.95, 2, sqrt(16), lower.tail=FALSE)\\nQ2 <- -qnorm(0.05, 2, sqrt(16))\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The ```data 10stackloss.txt``` is available on the course page. \\nIt represents the production of nitric acid in the process of oxidizing ammonia. \\nThe response variable, stack loss, is the percentage of the ingoing ammonia that escapes unabsorbed. \\nKey process variables are the airflow, the cooling water temperature (in degrees C), and the acid concentration (in percent).\\n\\nConstruct a regression model that relates the three predictors to the \\nresponse, stack loss. Check the adequacy of the model.\\n\\nHints:  \\n- Look at the data outliers\\n- Try to find an *\"optimal\"* model. Exclude predictors that do not improve the model fit. \\n- Use model diagnostics, use $t$-, $F$-tests and (adjusted) $R^2$ values to compare different models.\\n- Which data points have a (too) strong influence on the model fit?  (```influence.measures()```)\\n- Are the predictors correlated? In case of a high correlation, what are possible implications?\\n', 'answer': 'mydata <- read.table(\"stackloss.txt\", header = TRUE, sep = \",\")\\nstr(mydata)\\n\\npar(mfrow = c(1, 4))\\nboxplot(mydata$Air, xlab = \"Airflow\")\\nboxplot(mydata$Temp, xlab = \"Temp\")\\nboxplot(mydata$Acid., xlab = \"Acid.\")\\nboxplot(mydata$Stkloss, xlab = \"Stackloss\")\\n\\n# Be aware that you don\\'t see how many outliers there are if they have the exact same value. \\n# Boxplots give you an idea about the value range of outliers. \\n# You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs(mydata, gap = 0, col = c(mydata$Air > 70) + 1)\\n\\nfit_full <- lm(Stkloss ~ ., data = mydata)\\nsummary(fit_full)\\npar(mfrow = c(2, 2))\\nplot(fit_full)\\n\\n### Multicollinearity\\nprint(cor((mydata[c(\"Air\", \"Temp\", \"Acid.\")])))\\n\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif( fit_full )\\n\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep( fit_full )\\n\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, \\n#i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures( fit_full )\\n\\n#Let us consider a smaller (nested) model, without the non-significant predictor:\\nfit_nested <- lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\n\\n#Below, fill out whether multicollinearity exists (Yes or No), which predictor can be removed (capital first letter), and the optimal model formula (lm(...))\\nsol <- list(Multicollinearity_exists = \"Yes\", predictor_that_can_be_removed = \"Air/Temp/Acid\", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata) )\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.table(\"resource/stackloss.txt\", header = TRUE, sep = \",\")\\nstr(mydata)\\npar(mfrow = c(1, 4))\\nboxplot(mydata$Air, xlab = \"Airflow\")\\nboxplot(mydata$Temp, xlab = \"Temp\")\\nboxplot(mydata$Acid., xlab = \"Acid.\")\\nboxplot(mydata$Stkloss, xlab = \"Stackloss\")\\n#Be aware that you don\\'t see how many outliers there are if they have the exact same value. Boxplots give you an idea about the value range of outliers. You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs(mydata, gap = 0, col = c(mydata$Air>70)+1)\\nfit_full <- lm(Stkloss ~ ., data = mydata)\\nsummary(fit_full)\\npar(mfrow = c(2, 2))\\nplot(fit_full)\\n### Multicollinearity\\nprint(cor(mydata[c(\"Air\", \"Temp\", \"Acid.\")]))\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif(fit_full)\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep(fit_full)\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures(fit_full)\\n#Let us consider a smaller (nested) model, without the non-significant predictor. We have:\\nfit_nested <- lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\nsol <- list(Multicollinearity_exists = \"No\", predictor_that_can_be_removed = \"Acid\", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata))\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this problem we visualize and derive some properties of the Poisson random variable with parameter $\\\\lambda$. \\\\\\nVisualize the cdf and pmf of X $\\\\sim$ Pois($\\\\lambda$) for $\\\\lambda$ = 0.2 and $\\\\lambda$ = 2.\\nPlot the cdfs and pmfs in the same plot. Use col = \"blue\" for $\\\\lambda$ = 0.2 and col=\"red\" for $\\\\lambda$ = 2 and use `par(mfrow = c(1, 2))` to visualize the plots in one image.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\n  lambda1 <- 0.2\\n  lambda2 <- 2\\n  grid <- 0:8\\n  \\n  par(mfrow = c(1, 2))\\n  plot(grid, dpois(grid, lambda1), main = \"PMFs\", type = \"h\",\\n       xlab = expression(x), ylab = expression(f(x)), col = \"blue\")\\n  points(grid, dpois(grid, lambda1), col = \"blue\", pch = 20)\\n  points(grid + 0.1, dpois(grid, lambda2) , type = \"h\", col = \"red\")\\n  points(grid + 0.1, dpois(grid, lambda2) , col = \"red\", pch = 20)\\n  legend(\"topright\", pch = 20,\\n         legend = c(expression(lambda == 0.2), expression(lambda == 2)), \\n         col = c(\"blue\", \"red\"))\\n  \\n  probs1 <- c(0, ppois(grid, lambda1)) # Use ppois() here, and make sure to include an additional point at 0\\n  probs2 <- c(0, ppois(grid, lambda2)) # Use ppois() here\\n  \\n  plot(stepfun(grid, probs1), verticals = TRUE, pch = 20, \\n       xlab = expression(x), ylab = expression(F(x)), \\n       main = \"CDFs\", col = \"blue\")\\n  plot(stepfun(grid, probs2), verticals = TRUE, add = TRUE, pch = 20, col = \"red\")\\n  legend(\"bottomright\", pch = 20, \\n         legend = c(expression(lambda == 0.2), expression(lambda == 2)),\\n         col = c(\"blue\", \"red\"))\\n  \\ndev.off()\\n', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nlambda1 <- 0.2\\n lambda2 <- 2\\n\\n grid <- 0:8\\n \\n par(mfrow = c(1, 2))\\n plot(grid, dpois(grid, lambda1), main = \"PMFs\", type = \"h\",\\n      xlab = expression(x), ylab = expression(f(x)), col = \"blue\")\\n points(grid, dpois(grid, lambda1), col = \"blue\", pch = 20)\\n points((grid)+0.1, dpois(grid, lambda2), type = \"h\", col = \"red\")\\n points((grid)+0.1, dpois(grid, lambda2), col = \"red\", pch = 20)\\n legend(\"topright\", pch = 20,\\n        legend = c(expression(lambda == 0.2), expression(lambda == 2)),\\n        col = c(\"blue\", \"red\"))\\n\\n probs1 <- c(0, ppois(grid, lambda1))\\n probs2 <- c(0, ppois(grid, lambda2))\\n\\n plot(stepfun(grid, probs1), verticals = FALSE, pch = 20, \\n      xlab = expression(x), ylab = expression(F(x)), \\n      main = \"CDFs\", col = \"blue\")\\n plot(stepfun(grid, probs2), verticals = FALSE, add = TRUE, pch = 20, col = \"red\")\\nlegend(\"bottomright\", pch = 20, \\n       legend = c(expression(lambda == 0.2), expression(lambda == 2)),\\n       col = c(\"blue\", \"red\"))\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin.  \\nThe dataset anorexia in the package MASS gives the weight (in pounds) of 29 females before and after a cognitive behavioral treatment (CBT).  \\nTest whether the treatment was effective.\\nTo do this, return as a solution the p-value of the t.test, the 95 percent confidence interval of the difference between post and pre treatment, and the alternative hypothesis.\\nTo obtain the right difference (direction), make sure to use the pre-treatment weight first, and then the post-treatment weight.\\nYou can assume that the variances are equal, i.e. use the setting ``` var.equal=TRUE```.\\n', 'answer': 'require(MASS)\\nlibrary(dplyr)\\ndata(anorexia)\\nanorexia\\n\\nCBTANA <- filter(anorexia, anorexia$Treat==\"CBT\")\\nCBTANA\\ntt <- t.test(CBTANA$Prewt, CBTANA$Postwt, var.equal = T, conf.level = 0.95, alternative=\"less\", paired=T)\\ntt #dont forget its paired!\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'rubrics': [], 'modelSolution': 'require(MASS)\\ndata(anorexia)\\n\\nanorexiaCBT <- subset(anorexia, Treat == \"CBT\")\\ntt <- t.test(anorexiaCBT$Prewt, anorexiaCBT$Postwt, paired = TRUE)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For $\\\\lambda$ = 0.2 and $\\\\lambda$ = 2, sample from X1,...,Xn $\\\\sim$ Pois($\\\\lambda$) with n = 200 and draw histograms. Use `par(mfrow = c(1, 2))` to visualize the plots in one image.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\n  set.seed(3)\\n  lambda1 <- 0.2\\n  lambda2 <- 2\\n  n <- 200\\n  \\n  data1 <- rpois(n,lambda1)\\n  data2 <- rpois(n,lambda2)\\n  \\n  # Pay attention to the binning to be used for count data!\\n  par(mfrow = c(1, 2))\\n  hist(data1, xlab = \"\", prob = TRUE,\\n       breaks = seq(min(data1)-0.5, max(data1)+0.5, by = 1),\\n       main = expression(lambda == 0.2))\\n  points( ... , ... (unique(data1), lambda1), pch = 19)\\n  hist(data2, xlab = \"\", prob = TRUE,\\n       breaks = seq(min(data2)-0.5, max(data2)+0.5, by = 1),\\n       main = expression(lambda == 2))\\n  points( ... , ... (unique(data2), lambda2), pch = 19)\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nset.seed(3)\\n lambda1 <- 0.2\\n lambda2 <- 2\\n n <- 200\\n \\n data1 <- rpois(n, lambda1)\\n data2 <- rpois(n, lambda2)\\n \\n # Pay attention to the binning to be used for count data!\\n par(mfrow = c(1, 2))\\n hist(data1, xlab = \"\", prob = TRUE,\\n      breaks = seq(min(data1)-0.5, max(data1)+0.5, by = 1),\\n      main = expression(lambda == 0.2))\\n points(unique(data1), dpois(unique(data1), lambda1), pch = 19)\\n hist(data2, xlab = \"\", prob = TRUE,\\n      breaks = seq(min(data2)-0.5, max(data2)+0.5, by = 1),\\n      main = expression(lambda == 2))\\n points(unique(data2), dpois(unique(data2), lambda2), pch = 19)\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(15, 0, 2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean)) / sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat*x \\nresiduals <- y - y.fitted\\nSS <- sum(residuals ** 2)\\n\\nn <- length(x)\\nsigma.e <- sqrt(SS / (n - 2))\\nbeta0.se <- sigma.e * sqrt((1/n) + (x.mean^2 / sum((x - x.mean)^2)))\\nbeta1.se <- sigma.e / sqrt(sum((x - x.mean)^2))\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n - 2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n - 2) * beta1.se\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt(abs(t0), df = n - 2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n - 2, lower.tail = FALSE)\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany. \\\\\\nLoad the data and take a look at its help page using ?Oral. Also have look at str() of the Oral data.  \\nCompute summary statistics for all variables in the dataset.  \\nWhich of the $544$ regions has the highest number of expected counts E?  \\nAssume that the standardized mortality ratio $Z_{i} = Y_{i} / E_{i}$ is normally distributed, i.e., $Z_{1}, \\\\dots, Z_{544} \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$. \\nEstimate $\\\\mu$ and give a 95\\\\% (exact) confidence interval (CI). \\n\\nSave all results in the given list. \\\\\\nHint: The standardized mortality ratio is stored in the column SMR of the dataset Oral.\\n\\n', 'answer': 'require(spam)\\ndata(Oral)\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- Oral[which.max(Oral$E), ]\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- var(Oral$SMR)\\nS <- sqrt(S2)\\nci <- mean_SMR + c(-1, 1) * qnorm(1 - 0.05/2) * (S/sqrt(n))\\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)\\nsol', 'rubrics': [], 'modelSolution': 'require(spam)\\ndata(Oral)\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- 1/(n-1) * sum((Oral$SMR - mean(Oral$SMR))^2)  \\nS <- sqrt(S2) \\nci <-  mean_SMR + c(-1, 1) * qt(0.975, n-1, lower = TRUE) * S/sqrt(n) \\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In the following settings, calculate the probabilities and quantiles $q_1$ and $q_2$.\\n\\n$$\\nX\\\\sim \\\\mathcal{N}(2,16): \\n$$\\n$$\\n\\\\qquad P_1 = P(X<4), P_2 = P(0\\\\leq X\\\\leq 4), P(X> Q_1)=0.95, P(X< -Q_2)=0.05.\\n$$\\nYou can use the following two R commands: pnorm(a) and qnorm(b) for specific values a and b.\\n**Do not change the solution list at the bottom**\\n', 'answer': 'png(file=\"solution.png\")\\nP1 <- pnorm(4,2,4)\\nP2 <- pnorm(4,2,4)-pnorm(0,2,4)\\nQ1 <- qnorm(0.95,2,4)\\nQ2 <- qnorm(0.05,2,4)\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'rubrics': [], 'modelSolution': 'P1 <- pnorm(4, 2, sqrt(16))\\nP2 <- pnorm(4, 2, sqrt(16)) - pnorm(0, 2, sqrt(16))\\nQ1 <- qnorm(0.95, 2, sqrt(16), lower.tail=FALSE)\\nQ2 <- -qnorm(0.05, 2, sqrt(16))\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The following hemoglobin levels of blood samples from patients with HbSS and HbSb sickle cell disease are given:\\nConstruct $90$\\\\%-confidence intervals for the means of HbSS and HbSb variants in R (assume that the variances are known and are given by $\\\\sigma_{\\\\text{SS}}^{2} = \\\\sigma_{\\\\text{Sb}}^{2} = 1$). Save the results in a list.\\n', 'answer': 'HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\nsigma_SS <- 1 \\nsigma_Sb <- 1 \\n# CI for HbSS\\nn_SS <- length(HbSS)\\nmean_HbSS <- mean(HbSS)\\nz <- qnorm(0.95) \\nCI_HbSS <- mean_HbSS + c(-1, 1) * z * (sigma_SS / sqrt(n_SS))\\n# CI for HbSb\\nn_Sb <- length(HbSb)\\nmean_HbSb <- mean(HbSb)\\nCI_HbSb <- mean_HbSb + c(-1, 1) * z * (sigma_Sb / sqrt(n_Sb))\\n\\nsol <- list(CI_HbSS, CI_HbSb)', 'rubrics': [], 'modelSolution': ' HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n          9.1, 9.1, 9.8, 10.1, 10.3)\\n HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\n# CI for HbSS\\n n_SS <- length(HbSS)\\n CI_HbSS <- mean(HbSS) + c(-1, 1) * qnorm(0.95) * 1/sqrt(n_SS)\\n\\n# CI for HbSb\\n n_Sb <- length(HbSb)\\n CI_HbSb <- mean(HbSb) + c(-1, 1) * qnorm(0.95) * 1/sqrt(n_Sb)\\n\\n sol <- list(CI_HbSS, CI_HbSb)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A clinical trial is performed to compare two treatments, A and B, that are intended to treat a skin disease named psoriasis. \\nThe outcome shown in the following table is whether the patient’s skin cleared within 16 weeks of the start of the treatment.        \\nCleared(Treatment A: 9, Treatment B: 5)      \\nNot Cleared(Treatment A: 18, Treatment B: 22)       \\nUse $\\\\alpha=0.05$ throughout this problem.\\nCompute confidence intervals for both relative risk (RR) and odds ratio (OR) and interpret them.  \\nHint: Create your own R functions for calculating the CIs. For the RR you may use the CI given in equation~(6.23) and for OR the CI in equation~(6.27).\\nHow would the point estimate of the odds ratio change if we considered the proportions of patients whose skin did not clear?', 'answer': 'ORCI <- function(x1, x2, n1, n2, alpha = 0.05) {\\n  # n1, n2 are always for factor/no factor -> here n1, n2 is for treat. A, treat. B!!!\\n  # ((h_{11}/n_1)/(1-h_{11}/n_1))/((h_{21}/n_2)/(1-h_{21}/n_2)), where x1 = h11, x2= h21\\n  # Calculate the estimate of the odds ratio\\n  EstOR <- (x1 * n2) / (x2 * n1) #if x1 = h11, n2 = 22, x2 = h12, n1 = h21 \\n  Z <- qnorm(1 - (alpha / 2))\\n  # write function with h11, h12, h21, h22 instead of x1, x2, n1, n2!!\\n  # Calculate the confidence interval\\n  CI <- exp(log(EstOR) + c(-1, 1) * Z * sqrt(1/x1 + 1/n1 + 1/x2 + 1/n2))\\n  return(round(CI, 4))\\n}\\n\\nRRCI <- function(x1, x2, n1, n2, alpha = 0.05) {\\n  \\n  # Calculate the estimate of the relative risk\\n  EstRR <- (x1 / (x1 + n1)) / (x2 / (x2 + n2))\\n  Z <- qnorm(1 - (alpha / 2))\\n  \\n  # Calculate the standard error\\n  SE <- sqrt(1/x1 - 1/(x1 + n1) + 1/x2 - 1/(x2 + n2))\\n  \\n  # Calculate the confidence interval\\n  CI <- exp(log(EstRR) + c(-1, 1) * Z * SE)\\n  return(round(CI, 4))\\n}\\n\\n# Number of patients whose skin cleared with each treatment\\nx1 <- 9 # Treatment A\\nx2 <- 5 # Treatment B\\n\\n# Number of patients whose skin did not clear with each treatment\\nn1 <- 18 # Treatment A\\nn2 <- 22 # Treatment B\\n\\n# Calculate the confidence intervals\\nOR_CI <- ORCI(x1, x2, n1, n2)\\nRR_CI <- RRCI(x1, x2, n1, n2)\\n\\n# Store the results in a list\\nsol <- list(OR_CI = OR_CI, RR_CI = RR_CI)\\n\\n\\n', 'rubrics': [], 'modelSolution': 'ORCI <- function(x1, x2, n1, n2, alpha = 0.05) {\\n  z <- qnorm(1-alpha/2)\\n  p1 <- x1/(n1-x1)\\n  p2 <- x2/(n2-x2)\\n  logOR <- log(p1) - log(p2)\\n  SElog <- sqrt(1/x1 + 1/(n1-x1) + 1/x2 + 1/(n2-x2))\\n  CI <- exp(logOR + c(-1, 1) * z * SElog)\\n  return(round(CI, 4))\\n}\\nRRCI <- function(x1, x2, n1, n2, alpha = 0.05) {\\n  z <- qnorm(1-alpha/2)\\n  p1 <- x1/n1\\n  p2 <- x2/n2\\n  logRR <- log(p1) - log(p2)\\n  SElog <- sqrt(1/x1 - 1/n1 + 1/x2 - 1/n2)\\n  CI <- exp(logRR + c(-1, 1) * z * SElog)\\n  return(round(CI , 4))\\n}\\nOR_CI <- ORCI(x1 = 9, x2 = 5, n1 = 27, n2 = 27)\\nRR_CI <- RRCI(x1 = 9, x2 = 5, n1 = 27, n2 = 27)\\nsol <- list(OR_CI = OR_CI, RR_CI = RR_CI)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We saw that if $X,Y$ are independent Gaussian variables, then their (weighted) sum is again Gaussian. \\nThis problem illustrates that the assumption of independence is necessary. \\n\\nLet $X$ be a standard normal random variable. We define $Y$ as\\n\\n$$\\nY = \\n  \\\\begin{cases}\\n    X & \\\\text{if } |X| \\\\geq c, \\\\\\\\\\n    -X & \\\\text{otherwise},\\n  \\\\end{cases}\\n$$\\n\\n\\nfor a fixed positive constant $c$. \\n\\nArgue heuristically or with simulations that also $Y \\\\sim \\\\mathcal{N}(0,1)$. \\\\\\nAlso argue heuristically and with simulations that (i) $X$ and $Y$ are dependent and (ii) the random variable $X+Y$ is not normally distributed.\\nTo do this, calculate the proportion of zero entries in $X$ and $Y$ as the variable ```N```.\\nThen, ```X0``` and ```Y0``` should describe the total number of zero entries in $X$ and $Y$ respectively.\\n\\nWe do this in order to calculate the probability that $X+Y=0$.\\nGiven the transformation, $Y$ equals zero only if X is exactly zero, therefore both have a very small chance of being 0.\\nWhen we take the sum of $X$ and $Y$, there is a much greater proportion of zeroes (Verify this by looking at the variables)!\\nThis proportion of $N$ should be zero or a very small number close to zero due to the nature of the normal distribution, if $X+Y$ would actually follow a normal distribution.\\nThis will allow us to show that $X+Y$ is not normally distributed.\\n', 'answer': 'set.seed(15)\\n\\nc <- 0.5\\n\\nX <- rnorm(1000)\\nY <- ifelse(abs(X) >= c, X, -X)\\nN <- sum(X==0 & Y==0)/1000 # What proportion of zero entries do we have?\\n\\nX0 <- sum(X==0)\\nY0 <- sum(Y==0)\\n\\npar(mfrow = c(2, 2))\\nqqnorm( X , main = \"QQ-plot of X\")\\nqqnorm( Y , main = \"QQ-plot of Y\")\\n\\nqqnorm( X+Y , main = \"QQ-plot of X+Y\")\\nhist( X+Y , breaks = 50, main = \"Histogram of X+Y\", prob = TRUE)\\n\\nsol <- list(N = N, X0 = X0, Y0 = Y0)\\nprint(N)\\nprint(X0)\\nprint(Y0)', 'rubrics': [], 'modelSolution': 'set.seed(15)\\nc <- 0.5\\nX <- rnorm(1000)\\nY <- ifelse(abs(X)>=c, X, -X)\\nN <- sum(X+Y == 0)/1000 # What proportion of zero entries do we have?\\n\\nX0 <- sum(X == 0)\\nY0 <- sum(Y == 0)\\n\\npar(mfrow = c(2, 2))\\nqqnorm(X, main = \"QQ-plot of X\")\\nqqnorm(Y, main = \"QQ-plot of Y\")\\n\\nqqnorm(X+Y, main = \"QQ-plot of X+Y\")\\nhist(X+Y, breaks = 50, main = \"Histogram of X+Y\", prob = TRUE)\\n\\nsol <- list(N = N, X0 = X0, Y0 = Y0)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Calculate the residuals ($y_i - \\\\widehat{y_i}$) for all $n$ points and the residual sum of squares $SS = \\\\sum_i (y_i - \\\\widehat{y_i})^2$. \\nAre the residuals normally distributed? \\nDo the residuals increase or decrease with the fitted values?\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(length(x), mean=0, sd = 2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean)) / sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\ny.fitted <- beta0.hat + beta1.hat * x # Make sure you choose right formula\\n\\nresiduals <- y - y.fitted\\n\\nSS <- sum(residuals^2)\\n\\nsol <- list(SS = SS)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\ny.fitted <- beta0.hat + beta1.hat * x\\n\\nresiduals <- y - y.fitted\\n\\nSS <- sum(residuals^2)\\n\\nsol <- list(SS = SS)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Suppose that among $n=95$ Swiss males, eight are red-green colour blind. We are interested in estimating the proportion $p$ of people suffering from such disease among the male population.  \\n\\nCompute a 95\\\\% Wilson confidence interval and compare it to the confidence intervals obtained in (d).  \\nHint: Use the formula for the CI given in equation 6.11 in the script and define your own R function for calculating the CI.\\n', 'answer': 'n <- 95\\nx <- 8\\n\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  \\n  CI <- binom.test(x, n, 100-alpha)\\n\\n\\n  return(CI)\\n}\\n\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'rubrics': [], 'modelSolution': 'n <- 95\\nx <- 8\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  p_hat <- x/n\\n  q <- qnorm(1-alpha/2)\\n  CI <- 1/(1 + (q^2)/n) * (p_hat + q^2/(2*n) + \\n                             c(-1, 1) * q * sqrt( p_hat*(1-p_hat)/n + q^2/(4*n^2) ))\\n  return(CI)\\n}\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For each of the three district sizes, fit a simple linear model using salary as the response variable and experience as the predictor.   \\nIs there an effect of experience? How can we compare the results?\\n', 'answer': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\nfit1 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize== 1)\\nsummary(fit1)\\nfit2 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize== 2)\\nsummary(fit2)\\nfit3 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize== 3)\\nsummary(fit3)\\nplot(mydata$experience, mydata$salary, xlab = \"Experience\", ylab = \"Salary\", \\n\\t col = mydata$districtSize, main = \"Salary against experience\")\\n\\t \\nlegend(\"bottomright\", legend = c(\"districtSize 1\", \"districtSize 2\", \"districtSize 3\"), pch = 1, \\n\\t   col = c(\"black\", \"red\", \"green\"), bty = \"n\")\\nabline(fit1, col = \"black\")\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\n\\nfit1 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==1)\\nsummary(fit1)\\nfit2 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==2)\\nsummary(fit2)\\nfit3 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==3)\\nsummary(fit3)\\nplot(mydata$experience, mydata$salary, xlab = \"Experience\", ylab = \"Salary\", \\n     col = mydata$districtSize, main = \"Salary against experience\")\\nlegend(\"bottomright\", legend = c(\"districtSize 1\", \"districtSize 2\", \\n                                 \"districtSize 3\"), pch = 1, \\n       col = c(\"black\", \"red\", \"green\"), bty = \"n\")\\nabline(fit1, col = \"black\")\\nabline(fit2, col = \"red\")\\nabline(fit3, col = \"green\")\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin.  \\nThe dataset anorexia in the package MASS gives the weight (in pounds) of 29 females before and after a cognitive behavioral treatment (CBT).  \\nTest whether the treatment was effective.\\nTo do this, return as a solution the p-value of the t.test, the 95 percent confidence interval of the difference between post and pre treatment, and the alternative hypothesis.\\nTo obtain the right difference (direction), make sure to use the pre-treatment weight first, and then the post-treatment weight.\\nYou can assume that the variances are equal, i.e. use the setting ``` var.equal=TRUE```.\\n', 'answer': 'require(MASS)\\ndata(anorexia)\\n\\ntt <- t.test(anorexia$Prewt, anorexia$Postwt, paired = TRUE, alternative = \"two.sided\", conf.level = 0.95)\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'rubrics': [], 'modelSolution': 'require(MASS)\\ndata(anorexia)\\n\\nanorexiaCBT <- subset(anorexia, Treat == \"CBT\")\\ntt <- t.test(anorexiaCBT$Prewt, anorexiaCBT$Postwt, paired = TRUE)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In the following settings, calculate the probabilities and quantiles $q_1$ and $q_2$.\\n\\n$$\\nX\\\\sim \\\\mathcal{N}(2,16): \\n$$\\n$$\\n\\\\qquad P_1 = P(X<4), P_2 = P(0\\\\leq X\\\\leq 4), P(X> Q_1)=0.95, P(X< -Q_2)=0.05.\\n$$\\nYou can use the following two R commands: pnorm(a) and qnorm(b) for specific values a and b.\\n**Do not change the solution list at the bottom**\\n', 'answer': 'P1 <- pnorm(4, mean = 2, sd = 4)\\nP1\\nP2 <- pnorm(4, mean = 2, sd = 4) - pnorm(0, mean = 2, sd = 4)\\nP2\\nQ1 <- -qnorm(0.95, mean = 2, sd = 4)\\nQ1\\nQ2 <- qnorm(0.05, mean = 2, sd = 4)\\nQ2\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'rubrics': [], 'modelSolution': 'P1 <- pnorm(4, 2, sqrt(16))\\nP2 <- pnorm(4, 2, sqrt(16)) - pnorm(0, 2, sqrt(16))\\nQ1 <- qnorm(0.95, 2, sqrt(16), lower.tail=FALSE)\\nQ2 <- -qnorm(0.05, 2, sqrt(16))\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Suppose that among $n=95$ Swiss males, eight are red-green colour blind. We are interested in estimating the proportion $p$ of people suffering from such disease among the male population.  \\n\\nCompute a 95\\\\% Wilson confidence interval and compare it to the confidence intervals obtained in (d).  \\nHint: Use the formula for the CI given in equation 6.11 in the script and define your own R function for calculating the CI.\\n', 'answer': 'n <- 95\\nx <- 8\\n\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  q <- qnorm(1-alpha/2)\\n  mid <- (x + q^2/2)/(n+q^2)\\n  se <- sqrt(n)/(n+q^2)* sqrt(x/n*(1-x/n)+ q^2/(4*n))\\n  CI <- c(pmax(0, mid - q*se), pmin(1, mid + q*se))\\n  return(CI)\\n  \\n}\\n\\nCI <- WilsonCI(x, n)\\n\\nsol <- list(CI = CI)', 'rubrics': [], 'modelSolution': 'n <- 95\\nx <- 8\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  p_hat <- x/n\\n  q <- qnorm(1-alpha/2)\\n  CI <- 1/(1 + (q^2)/n) * (p_hat + q^2/(2*n) + \\n                             c(-1, 1) * q * sqrt( p_hat*(1-p_hat)/n + q^2/(4*n^2) ))\\n  return(CI)\\n}\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The following hemoglobin levels of blood samples from patients with HbSS and HbSb sickle cell disease are given:\\nConstruct $90$\\\\%-confidence intervals for the means of HbSS and HbSb variants in R (assume that the variances are known and are given by $\\\\sigma_{\\\\text{SS}}^{2} = \\\\sigma_{\\\\text{Sb}}^{2} = 1$). Save the results in a list.\\n', 'answer': '# The following hemoglobin levels of blood samples from patients with HbSS and HbSb sickle cell disease are given: Construct \\n# 90%-confidence intervals for the means of HbSS and HbSb variants in R \\n# (assume that the variances are known and are given by variance = other variance = 1). \\n# Save the results in a list.\\n\\nHbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n          9.1, 9.1, 9.8, 10.1, 10.3)\\nHbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\n# CI for HbSS\\nn_SS <- length(HbSS)\\nCI_HbSS <-  mean(HbSS) + c(-1, 1) * qnorm(1-0.1/2, mean = 0, sd = 1) * sd(HbSS)/sqrt(n_SS) # mean of norm is 0 an not mean(HbSS)!!! \\n# CI for HbSb\\nn_Sb <- length(HbSb)\\nCI_HbSb <- mean(HbSb) + c(-1, 1) * qnorm(1-0.1/2, mean = 0, sd = 1) * sd(HbSb)/sqrt(n_Sb)\\n\\nsol <- list(CI_HbSS, CI_HbSb)\\n', 'rubrics': [], 'modelSolution': ' HbSS <- c(7.2, 7.7, 8, 8.1, 8.3, 8.4, 8.4, 8.5, 8.6, 8.7, 9.1, \\n          9.1, 9.1, 9.8, 10.1, 10.3)\\n HbSb <- c(8.1, 9.2, 10, 10.4, 10.6, 10.9, 11.1, 11.9, 12.0, 12.1)\\n\\n# CI for HbSS\\n n_SS <- length(HbSS)\\n CI_HbSS <- mean(HbSS) + c(-1, 1) * qnorm(0.95) * 1/sqrt(n_SS)\\n\\n# CI for HbSb\\n n_Sb <- length(HbSb)\\n CI_HbSb <- mean(HbSb) + c(-1, 1) * qnorm(0.95) * 1/sqrt(n_Sb)\\n\\n sol <- list(CI_HbSS, CI_HbSb)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Under the null hypothesis, we are allowed to permute the observations (all $y$-values) while keeping the group assignments fix. Keeping this in mind, we will now manually construct a permutation test to detect a potential shift. Write an R function ```perm_test()``` that implements a two-sample permutation test and returns the $p$-value. Your function should execute the following steps.\\n\\n1. Compute the test statistic $t_\\\\text{obs} = \\\\displaystyle \\\\widetilde y_A - \\\\widetilde y_B$, where $\\\\,\\\\widetilde{\\\\cdot}\\\\,$ denotes the empirical median. For the grading, make sure your group $y_A$ contains the measurements taken at ```12-26 Weeks``` , and the group $y_B$ contains the measurements taken ```At term```.\\n2. Then repeat many times (e.g. $R = 1000$) \\n    - Randomly assign all the values of ```pd``` to two groups $x_A$ and $x_B$ of the same size as $y_A$ and $y_B$. \\n    - Store the test statistic $t_\\\\text{sim}  = \\\\widetilde x_A - \\\\widetilde x_B $. \\n3. Return the two-sided $p$-value, i.e. the number of permuted test statistics $t_\\\\text{sim}$ which are smaller or equal than $-\\\\vert t_\\\\text{obs} \\\\vert$ or larger or equal than $\\\\vert t_\\\\text{obs} \\\\vert$ divided by the total number of permutations (in our case $R = 1000$).\\n\\n**Important for the access grading**: The path bug has been fixed, if you want to run your script, the path can remain ```read.csv(\"resource/07water_transfer.txt\")```.\\nYou do not have to change the dots anymore for running and submission.\\n', 'answer': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y)\\n  # Store the data without the group labels ( try using c() )\\n  all.data <- c(x,y)\\n  tsim <- array(0, 1000 )           # Preallocation of R-amount of values\\n  for(i in 1:length(tsim)){\\n    index <- sample(1:length(all.data), length(x), replace = FALSE) # random permutation\\n    medianxA <-median(all.data[index]) # Sample median of group A\\n    medianxB <- median(all.data[-index]) # Sample median of group B\\n    tsim[i] <- medianxA-medianxB  # Difference for the current iteration\\n  }\\n  # Sample p-value. Proportion of \"some\" values and amount of iterations  \\n  return(sum(abs(tsim) >= abs(tobs))/ R)\\n}\\n\\n# We test our function:\\nyA <- mydata[mydata$age == \"At term\",1]  # Split the data such that you have one factor per group\\nyB <- mydata[mydata$age == \"12-26 Weeks\",1] # Split the data such that you have one factor per group\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y) \\n  all.data <- c(x, y)           # Store the data without the group labels\\n  tsim <- array(0, R)           # Preallocation\\n  for(i in 1:R){\\n    index <- sample(1:length(all.data), length(x), replace = F) # random permutation\\n    medianxA <- median( all.data[ index]) # Sample mean of group A\\n    medianxB <- median( all.data[-index]) # Sample mean of group B\\n    tsim[i] <- medianxA - medianxB  # Difference for the current iteration\\n  }\\n  return(sum( abs(tsim) >= abs(tobs))/ R) # Sample p-value \\n}\\n\\n# We test our function:\\nyA <- mydata[mydata$age == \"12-26 Weeks\", 1]\\nyB <- mydata[mydata$age == \"At term\", 1]\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'On www.isleroyalewolf.org/data/data/home.html the file isleroyale graph data 28Dec2011.xlsx contains population data from wolves and moose. The information in this file is extracted and saved in the file 01wolvesmoose.csv.Download and read the file 01wolvesmoose.csv from the STA120 course page.\\n\\nCreate a boxplot containing both, Moose and Wolf data. \\nCreate a QQ-plot for Moose and a QQ-plot for Wolf.\\nCreate a plot of Wolf on Year and of Moose on Year.\\nCreate a plot of Wolf on Moose, with colors 1:3.\\nYou should get 6 plots. Use par( mfrow=c(2,3)) to plot them in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\", header=TRUE)\\npar(mfrow = c(2,3))\\n\\nboxplot(dat$Moose, dat$Wolf)\\n\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)# add QQ-line here\\n\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf) # add QQ-line here\\n\\nplot(Wolf ~ Year, data=dat, type =\\'l\\') # What type should this plot be for nice line?\\nplot(Moose ~ Year, data=dat, type =\\'l\\') # What type should this plot be for nice line?\\n\\n# How many times should the colors repeat so that the legend makes sense?\\nplot(Wolf ~ Moose, data=dat, col=rep( c(1,2,3), times=c(22, 16, 15))) \\nlegend(\"topright\", col=c(1,2,3), \\n    legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"), \\n    bty=\"n\", \\n    pch=\"o\")\\ndev.off()image\\\\\\\\png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nOzdZ1wT2fcw8JsQegcpdmStKKLAWlfBhl1EEURdxQKK6C4qirq6uvaCba0IKNgVlaIg2BVQQQQLgiBVivQWIAmkPC\\\\\\\\m\\\\\\\\8vmoYaQZCbJ+b7wk4S5M8fc5HC5cwuJw+EgAAAAxEPGOwAAAAAtgwQNAAAEBQkaAAAIChI0AAAQFCRoAAAgKEjQAABAUJCgAQCAoCBBAwAAQUGCBgAAgoIEDQAABAUJGgAACAoSNAAAEBQkaAAAIChI0AAAQFCQoAEAgKAgQQOiSElJsbGx0dLSGjhwoLe3N5vNbu3F1gQGBqqrq\\\\\\\\N5ucDAQBKJ1K9fP+xpjx49SCRSYGBgJ\\\\\\\\8XQMz12KJJkyZ17dqV+9Ta2nrq1KkIofv375NIpEePHiGErKyspk+fLoqrCxEkaEAIFRUVVlZWJBLp1q1brq6uO3bsOHr0aIsvcoucP3\\\\\\\\ezMxs9uzZurq6u3bt4j0bk8l0c3PT0dHp2bOnn58fQiguLo5EIhUUFDS5bm5ubklJSUFBQUlJSWtlm79SUlKyYMECPT296dOnf\\\\\\\\jwoby8fObMmerq6mPHjs3IyBDpG0Vw4q\\\\\\\\H5sdkZmY+f\\\\\\\\782rVr3GOmTZuWkJCAEHr\\\\\\\\\\\\\\\\r2Kikp8fDyHw0lKSrKxsWlenMvGxsbJyQkhdOrUKV1d3ZKSEt5abvIZEMm7iRDiAEAAp0+fVlJSqqysxJ6uX7\\\\\\\\e0NCwxRe5Rby9vRFCBw4cOHv2LELo06dPAQEBampqHA7n0qVLCgoKMTEx3t7eFAolOzvb3NwcITR69Ghu8YCAAITQiBEjQkND7969O2LECIRQQEBA87LNX9m\\\\\\\\f3+3bt1ycnJ+\\\\\\\\\\\\\\\\33ZcuWbdiwYdiwYVlZWTNnzpw+fboY3zbCEX89Nj\\\\\\\\G0tISIdSrVy\\\\\\\\uMUlJSVjinjx5souLy4wZM759+4YQSk5Obl6ce\\\\\\\\V\\\\\\\\\\\\\\\\\\\\\\\\3XwMCAw+HMnz9\\\\\\\\8eLFTWq5yWdARO8ntKABIWRnZ3fv3l1LSwt7Onjw4KKiopSUlOYvvnz5MioqKjY2FiGkpKTk6em5atUqRUXF+Ph47tnevHljaWk5duxYFxcXNpudkJBw7tw5hFBQUFCT644dO\\\\\\\\bNmzfv3r0bPXp0a2Wbv9K1a9fCwkI7O7vhw4efP3\\\\\\\\+w4cPmZmZEydOfPv27du3b0X9XhGZ+Oux+TFY2zkiIoJ7jJmZmaGhYXx8\\\\\\\\IcPH9zd3bEH3bp1Gzx4cPPi3FKzZ88uLi5OTU2NiYmZNWtWk1pu8hkQ0fsJCRoQQp8+fQoKCqqrqxsbGzdv3vzy5UtDQ0MTE5PmL+7cuXPatGlr1qxBCJFIJOxfMplMJv\\\\\\\\3Yeb8b6dNEolEIpFYLFZr1x07duzbt2\\\\\\\\fvXs3ZsyY1so2f2X58uV37txRV1fftGnTggULVFRUli1blp2dXV5eXllZKYK3R2KIvx75OYZEIk2dOvXWrVuamppmZmZKSkpBQUFYr3QbxY2MjAYPHuzj41NWVjZ16tQmtdzkMyCUd685SNCAEBYtWqSqqrpw4UKsYXXr1i0XF5cWX4yOjuZwOF++fEEI0Wi0kydPnjhxgkajYX0UmFGjRiUkJMTHx\\\\\\\\v7+yOEfv31V+x1BoPR5LqjR49OTExMSkoaOXJka2Wbv7Jly5agoKC7d++6urp++fJl5MiRT58+zcrK2rp1q6urq+jfLeISfz22dkwT06ZNe\\\\\\\\jwIfbTESNGPHjwwMbGpt3is2fPvnjx4m+\\\\\\\\\\\\\\\\aatrd2klpt8BoT6LvIQUdcJAB2VnJw8efJkdXX1rl27WllZGRsbs1isFl\\\\\\\\Ejvf29tbX17eystLS0tq7dy+Hw+H2HjY0NLi4uGhpafXo0cPPz4\\\\\\\\D4dTV1ZmYmAwZMoR7OawPura2dujQoYMHD66qqkIIBQQENC\\\\\\\\b\\\\\\\\JUvX75YWFgoKip27979ypUrlZWV06dP19DQmDRpUmJiovjfOkIRcz02P4bbv8wbVVlZGZlMPnLkCIfDOXToEIlEKi0tbbE49+ocDgfrgcFKNanlJp8BEb2ZkKABEdXX1+\\\\\\\\Zs6ftF729vY2MjMQbF+gYqMdOInH+1wUDgGQ5duzYmTNnsrOz8Q4EdArUYxsgQQMAAEHBTUIAACAoSNAAAEBQkKABAICgIEEDAABBQYIGAACCggQNAAAEBQkaAAAIChI0AAAQFCRoAAAgKEjQAABAUJCgAQCAoCBBAwAAQVHEf8msrKynT5+K\\\\\\\\7qSa\\\\\\\\LkycbGxnhHwS+o346C+pVunalfHBJ0VFRUeno6d4ch0LZ37941Nja6u7vjHQi\\\\\\\\oH47BOpXunWyfnFI0AihUaNGiW4XL+lTUlKCdwgdA\\\\\\\\XbIVC\\\\\\\\0q0z9YtPggYAEERERISPjw+ZTGaxWGQyefXq1dOnT8c7KPB\\\\\\\\IEEDIFZsNvv27dvfv3+fN2\\\\\\\\ekCFD8A4H+fr63r9\\\\\\\\X05ODiHE4XCcnZ0hQXeGcOtX4kdxlJSU2NjYjB8\\\\\\\\PiEhAe9YAGjf33\\\\\\\\\\\\\\\\\\\\\\\\e3bt7Fjx65bty4jIwPvcBCJRHr9+nVZWVl5eXlsbCyTycQ7Iskm3PqV+BZ0WFjYkiVLLC0tT548aWlpiXc4ALQjNjb2xYsXCKGSkpLnz59ra2vjG4+Pj4+\\\\\\\\v39gYCCTyTQxMTl58mSTA6qrqx0cHNhsNvY0LS1tzpw5jo6OYo9UMgi3fiW+BT1mzJjz58\\\\\\\\\\\\\\\\8ccfNjY2eMcCQPt69+79+PFjOp3+8OFDU1NTvMNB3t7eW7duHT58+Ldv3x49ehQeHt7kAE1NzaioqCf\\\\\\\\M3bsWApF4ht2oiPc+pX4BG1iYvL48eNbt27Z29vjHQsA7Tt+\\\\\\\\HhYWJidnZ2Njc3o0aPxDgelpKQghCIiIhISEqKjo4ODg\\\\\\\\GOSLIJt36l4Tehurq6uro63lEAwBcdHZ0zZ87gHcV\\\\\\\\cnNzQ0NDNTQ06HQ6lUpVVVXFOyLJJtz6lfgWNACgMy5dusRgMCwsLCoqKkJCQjw8PPCOCPxHGlrQAACBWVpacu+uu7i44BsMaAJa0AAAQFCQoAEAgKAgQQMAAEFBggYAAIKCBA0AAAQFCRoAAAgKEjQAABAUJGgAACAoSNAAAEBQ0pCg09PTP3z4gHcUAAAgZEKY6o3vljlxcXE7d+40NDQcPXq0m5ub2K4LAACiJoQEje+WOV+\\\\\\\\frWzs7O0tLx8+bLYLgoAAGIghC4OfLfMcXR0fPv27b59+zw9PcV5XQDa0NDQ4OnpOXHiRC8vr8bGRrzDAZJKCAnax8cnLi7O09Nz48aN0dHRzbfMESlVVdUrV66EhoYaGxuL87oAtOHUqVPGxsbPnz\\\\\\\\v1q0boVZ\\\\\\\\BpJFCAn6\\\\\\\\fv3b9++ra6urqysjIuLg81bAUhLS5s6dSpCaNq0aWlpaXiHA4Svtrb248ePdXV1Ir2KxPdBI4Ti4uIqKiqmTp1KJkvDoBSiwfcmsISys7PbvHnz8uXL\\\\\\\\fz81q5di3c4QMhSUlJWrVo1cuTIuLi4y5cvDxgwQEQXEkKCxvqgTU1NSSRSamqqmPugX716deLEiV69eqWkpGzatEmcl5YRuP8ClkQzZ87U1dV9+\\\\\\\\btX3\\\\\\\\9NWLECLzDAUJ27ty5c+fODRs2LCEh4fz586Lr1xVCguZu287hcAYOHNg8Vjab\\\\\\\\fHjRw6Hgz3NyMgwMTHp\\\\\\\\HUxubm5Y8aMMTc3Dw0NFdY5AS98fwFLrlGjRo0aNQrvKIBIKCsrV1dXI4SqqqqUlZVFdyEhJGisDxr7EzguLm7YsGFNWli1tbVBQUHcBB0ZGVlRUbFy5crOXxoh5OjouG3btmvXrh04cEAoJwRNtPsLGABZUFBQcOPGDT09vUWLFm3cuHHx4sXKysp0Ov3mzZuiu6g4+qA1NDQOHjzIfZqbm6upqdn562IUFRWPHz8urLOB5tr9BQwwoaGhZ8+e1dbWPnDgwC+\\\\\\\\\\\\\\\\IJ3OECYqqurFyxYsHnz5h8\\\\\\\\fri4uAQGBj5\\\\\\\\\\\\\\\\pxGo4m0+YykoA8aiBr0QfMjNzf3\\\\\\\\PnzISEh+fn5bm5ujx8\\\\\\\\xjsiIEwfPnyYMWOGnZ0dQmjChAnYi6LOzkg8fdBAosEvYH5kZmb+9ttvKioq\\\\\\\\fv3h5kp0qdv375Hjhypra3Ny8uTl5cX23WFkKDDw8NjY2MRQufPn+\\\\\\\\Ro4ednV1wcHDnTwsIot1fwNXV1Q4ODmw2G3v67du3mTNnOjo6ij1SPFlaWu7cuXPQoEG5ubm9e\\\\\\\\fGOxwgZL169XJ3d58\\\\\\\\f76uru6FCxfEdl0hJOgnT548ePCgsLDQ1dU1LCys8ycEhNJuH7SmpmZUVBT3qZOTk5KSktjDxJmGhsbdu3dv3rzZpUsXX19fvMMBwjd79uzZs2eL+aJCSNA\\\\\\\\f\\\\\\\\58+fKllZWVs7Ozp6cnjUbr\\\\\\\\DkBcUAfNJ+6du26ceNGvKMAUkUICdrPz8\\\\\\\\f39\\\\\\\\S0tLe3l5FRaWmpqbz5wTEAX3QQMbV19erqKjgcmkhJGhjY+P9+\\\\\\\\djj2fMmDFjxozOnxMQB9wEBjKrpKRk4cKFKioqdXV1169f79atm5gDEEKCBtINbgIDmXXy5Mlt27ZNmTLl9evXx44dO3bsmJgDgAQN2gE3gaUbLIbVBjqdjs2q09DQoNPp4g8AEjRoB9wElm5wE7hFdDr96dOnI0eO9PDwGDFiRHx8vJ+fn\\\\\\\\jDkJgEHRcX9+nTpxZ\\\\\\\\VFdXR6VSDQ0NW\\\\\\\\xp165dxT84RprATWDpBjeBm2MwGNOnT586dWp+fv6vv\\\\\\\\66YsWK\\\\\\\\fv3q6qqij8SiUnQKioq2traLf4oLy8vIyNj0KBBLf5UQ0NDlHFJP7gJLN14bwIbGBg0vwlcU1Pj5eXFnYiUkJAwZswYsYcpVtj\\\\\\\\cevWrQgha2vroUOH4hWJxCRoU1NTU1PTFn+kpaWlpKS0YMECMYcEgBRITEwcPnz48OHDEUJHjhxJTEzE9oLhUldXX7NmDbdlnZubq66ujkOgYmRgYJCWlsbhcKqrq1ksFo6RSEyCBgCIQmRkZFRU1OrVqykUCpVKzcjIaJKgSSSSmZkZ96m2tjaFIuV5o2\\\\\\\\fvtbW1lZWVhQK5dChQzhGIg1v9IgRI\\\\\\\\r27Yt3FABIpBMnTrx58+bChQtbtmx59+6du7s73hERwrp169atW4d3FFKRoDU1NYW4wLQU+\\\\\\\\HjB41Gk5eX9\\\\\\\\X1tbe3t7CwwDsiafDly5fo6OgxY8YMGzYM30gErt8xY8ZYWFgcOnQIlrEmGmnYZbW8vPzbt294RyEBNmzYoKiouHHjxjlz5vz77794hyMNXrx4sXnzZl1d3R07dvCuGIWLztSvoqLirl27du\\\\\\\\eLZrQgICkIUEnJibeu3cP7ygkgJKSUkVFBYvFGjZsGL63PqTG3bt3jx8\\\\\\\\7ujoeOrUqaCgIHyDgfoloKSkpM6MXJSGBA34tG7duhs3bhw+fPjBgweLFy\\\\\\\\GOxxp8Msvv7x+\\\\\\\\Roh9OrVK2NjYwHOkJmZKaxkCvVLNKmpqSEhIWSy4GkWErQMyczMTEpKunz5cklJSV1dHd7hSAN3d\\\\\\\\fU1FRra+sPHz4IsNZoXl7e5cuXSSSSUIKB+iUUKpXq4uKydu1anBN0RESEra2tnZ3dnDlz5s6d++jRo86fs0NGjBixaNEiMV9UEt29e\\\\\\\\fZs2cIoXXr1kVEROAdjjRQVFQ8derUy5cvz54929FtCuh0+rJly1xdXTvzBeYF9UscbDZ7yZIlO3bsMDAw6Mx5xLGrt6jBKA4+MRiMpKQkFov1+fPn\\\\\\\\Px8vMORbA0NDc+fP9fR0RkxYoQAxTkczqpVq9asWUMikUpKSoQSEtQvcezcudPa2nratGmdvDMhhF\\\\\\\\d2Fz+srKy8vLy2NhY8c\\\\\\\\lh1EcfPL19b1x40ZhYeGtW7cCAgLwDkeCYWs1JCQk+Pv7e3l5CXCGw4cP9+vXz8HBQYhRQf0SREhIyI8fPzZs2ND5U0nDrt6JiYnx8fF\\\\\\\\\\\\\\\\fWXmK8rWbClppYsWYI9LS0tFf\\\\\\\\q41IjISFh5MiRO3bsQAhZWVl1tHhUVFRCQsKdO3eEGBLUL0GkpqaeOHFCWD29QkjQ7W4qCoggMjKyySu883dBh+jr63\\\\\\\\\\\\\\\\\\\\\\\\p3D4dTU1HBXEeJTWlraP\\\\\\\\\\\\\\\\8ExkZKayuZwzULxFUVlYuX7785s2bwtoiSxr6oAE\\\\\\\\Ro8ejct6iVKpX79+Y8eOtbKyIpPJBw4c4L9gTU3NqlWrrl69KvRFFqF+ccdms52dnQ8dOtSnTx9hnVMICRr39WRhLQ5+JCYmNhlvC1O9O8PDw8PDw6NDRdhs9tKlS\\\\\\\\\\\\\\\\55x9RzKiG+sUdtjmWtbW1EM8pzD5oJpNpYmLSvA+6urray8uLw+FgT9+\\\\\\\\fy\\\\\\\\c9WRhFAc\\\\\\\\evbsGRgYuGzZMoQQh8MJCAjYtGkT3kHJFi8vr8mTJ0+cOFEUJ4f6xdf9+\\\\\\\\eLiooOHz4s3NMKIUF7e3sfPnz41KlTV69ezc3N7datm7OzM+8BGhoavAm6sLBQuPm0vLy8tLR04MCBQjynVNLS0sIekEgkuKcqZtevXy8rKzt69KjoLgH1i5fPnz+fPHlSFIuxCCFBp6SkIIQiIiISEhIQQra2tk0SNIlE4u2UUVNTwzqshQVGcfBj\\\\\\\\vz5379\\\\\\\\v3btGjaf4rfffhs9ejTeQcmKpKSkgICAhw8fiu4SUL94qaiocHNzu337trKystBPLoQEnZubGxoaiu16S6VS4U4FYVVXVwcHB3e0FOz63ElFRUVr1qwJDg5WVFQU6YUEq1\\\\\\\\QGSwWy9nZ+eDBgz169BDF+YWQoC9dupSVlWVhYVFRUREeHt7ROydAbBgMxpUrVwYNGoQN8OLzJhKM0umMxsbGZcuWnTlzRgyjkgWrX9BcQ0ODgoICP0du3rx5xowZ48ePF1EkQkjQlpaWlpaW2GMXF5fOn7CjYBQHn7p3715aWlpaWooQysnJ4fMLjPsoHYnm7u6+bNmyX3\\\\\\\\9VQzXEqx+Aa\\\\\\\\6+nonJycajUan0\\\\\\\\38\\\\\\\\Pr379\\\\\\\\GwdevX6+srFyzZo3o4hFCgnZycqqsrOTtfxHz31kwioNP3bt3v3XrFpvNZrPZDQ0NfJbCfaao5Dp16pSurq7YVvISrH4Br4CAAFtb2xUrVqSnp+\\\\\\\\evfvGjRutHfnx48dLly6JelEqIcxlunjxopqaWjCPzp+zQ2AtDj6FhobeuXNHS0vrypUrbTcNeGEzRaurqysrK+Pi4rBbwaBdz549e\\\\\\\\Lkyb59+8R2RcHqF\\\\\\\\Cqr6\\\\\\\\X1dVFCOno6NTX17d2WHl5+dq1a69cuSLq+wpCaEGrq6vj26qCURx8YjKZeXl59fX1VVVV\\\\\\\\K8XDH3QTdDp9JSUlD59+mhra7d2TE5Ozq5dux4+fCjcAUttE6x+Aa8lS5bMmzcvJiYmPj6+tQ3AmEzmokWLDh8+3L17d1HHI5zVAER0BxMI18mTJ6urq\\\\\\\\ft23fo0CE7Ozs+S+G+WiGhFBUVTZo06fr167a2tq9evWrxmNra2sWLF1+8eJE7MFk8BKtfwMvQ0PD58+cODg7379+fMGFCi8ds3LjR3t5+3LhxYohHGnb1Bnzy9PRECLFYrOzsbBKJNGfOHH5K8TNT1MHBgbtmUHJysogmyxHBtWvXNm\\\\\\\\ePHfu3NLSUhcXl+ZL2WELPW\\\\\\\\fvt3ExETMsQlWv6AJJSWlNm7qXr16lcViiW00hDQkaBjFwaebN29iD6hUKv+L1bY7U1RTU5N3DpWTk5Oenp6QQiYcFRWVyspKhFBVVVWLK5bt2rXL0tJy5syZYg9NwPoF\\\\\\\\EtKSgoMDBTnbjXSkKBhFAefvn79ij2gUqn87+LR7kxRmeLs7Ozk5HT79u36+npfX98mPw0ODs7Jybly5QousQlWv4BPxcXF2IQjPodIC4U0JGhYi4NPd+\\\\\\\\exR6QyeQ9e\\\\\\\\bwWQpmivJSUVEJDQ1lMBjNb99\\\\\\\\\\\\\\\\vz5xIkTzddlFhvB6hfwo7GxcenSpadPnxbzNgjSsKt3YmLivXv38I6C6BoaGuTl5aOjo6Ojo0kk0ps3b06fPs1PwUuXLjEYDGymaEhICMwURQg1z87l5eVubm43btwQ1krtHSVw\\\\\\\\QJ+\\\\\\\\PHHHw4ODoLtP9kZ0tCCBvzYunWrqanpkydPsKXObty48fz5c34K4j5TlPgaGxsXLVp06NAhHIczCVy\\\\\\\\oF2BgYGKioorV64U\\\\\\\\6UhQcuK\\\\\\\\Pz848ePY4+trKxyc3P57ErDfaYo8Xl4eIht3FVrBK5fgOFwOFu2bHn\\\\\\\\\\\\\\\\r2Ojg7v2inv3r27cuWKsPYY7ChpSNAwioMfvOOXbWxsLl26xGfBixcvLl++nNu\\\\\\\\CZoICAiQl5fH\\\\\\\\W8LgesXYO7du6esrPzy5csPHz54eXldvXoVIVRUVLRx48aQkBC8fttJQ4KGURz8GDNmzJYtW9avX0+hUPz8\\\\\\\\ExNTfksiPtMUSJ78+bNnTt3wsLC8A5E8PqF5WQx+fn55ubmCCFTU9OioiL0vxuD\\\\\\\\\\\\\\\\77r76+Pl5RSUOChlEc\\\\\\\\PD09AwNDd29ezeLxZo+fbqjoyP\\\\\\\\ZWGmaIt+\\\\\\\\PixYcOG8PBwCgX\\\\\\\\75HA9SvLU\\\\\\\\k5HE5WVpaCggKDwTA3N\\\\\\\\f09CwtLX369Cm2vpW7u\\\\\\\\uiRYu4N2Bwgf8Hq\\\\\\\\NgLQ4+2dra2tra4h2FlKDRaM7Ozn5+fl26dME7lv8jWP3K7HKyTCZzwYIFNTU1iYmJ2DY0AwYMiI6O3rp16\\\\\\\\Dhw8+dO6ehoYH7kH9pSNCgQ5hMJhFafJIoKSkpLCxs8ODB8+bNW7VqlZubG\\\\\\\\89CWLT0fptdzlZGo127do17p6imZmZ0jEW\\\\\\\\uXLl0OGDHn79m1kZOTcuXP\\\\\\\\+usvLS2tCxcumJmZvXnz5uHDh0TouRLCF1WIfVhUKlWAX+C1tbU0Gg2bgNtRbSxIJn2uXbt2+fJlc3Pz3r17Gxoa2tvb4x2RJPn8+fPmzZu3b98eGRnp5+c3duzYBQsW4B3U\\\\\\\\0ew+o2NjY2NjZ01a5aPj096erqBgcGKFSt4D5CTk9PW1uYmaAUFBXEu0Sc68vLyDQ0NcnJyLBaLzWYzGAx5eXk2m11UVOTp6RkWFkaEdowQIhBiH1a\\\\\\\\fv3MzMw6WorJZDY2Nr5\\\\\\\\\\\\\\\\76jBdPS0kJDQwW4ooS6e\\\\\\\\fus2fPNm\\\\\\\\evG7duhUrVkCC7pAnT554eHhMnDixoaEhMDAQr3FXbRCsfu\\\\\\\\evRsSEmJnZ3f27NnRo0e7uro2SdAKCgq8p7p\\\\\\\\\\\\\\\\74odkcVp8bGxqCgoKSkpBcvXrBYrGnTpqmpqR05cqR\\\\\\\\\\\\\\\\\\\\\\\\7Lly9ftGjRmTNnCNJzJYQELcQ+rF69eh07dqzzIfHJ29tbdnrcEEIMBiMpKYnFYn3+\\\\\\\\Dk\\\\\\\\Px\\\\\\\\vcCTM0KFDg4KCevfuvWnTJltbWxKJhHdETQlWv2QyOTMz89ixY\\\\\\\\369auoqKDRaCINkggWL14sLy+flZVFo9G0tbUjIyMHDhxIoVAUFRXd3d3XrFmDDecgAiFM9fbx8YmLi\\\\\\\\P09Ny4cWN0dDQMySIsX1\\\\\\\\fGzduFBYW3rp1KyAgAO9wJMnHjx\\\\\\\\v3LmTnp7+22+\\\\\\\\jRw50tvbG++IWiBY\\\\\\\\e7YseP58+f9+vVDCB06dMjV1VWEIRJAY2MjtqFBZGTktGnTli9fHhkZqaOjo6Gh4ePjo6ent3DhQrxj\\\\\\\\I8QWtDYlkhYH3RcXNywYcNkZ5iOBPn06RNCaMmSJdjT0tJSMS\\\\\\\\7IqE4HM6dO3e2bdt2\\\\\\\\vz5vXv39uvXj5hzQASu3\\\\\\\\79+3P3xzpy5IiIwiMOeXl5Go3Wt2\\\\\\\\fiIiIpKQkOTk57E5vTExMVFQUEW4M8iJWHzQQHWyVNTabXVBQYGBgoKCgIDud752xZ8+e9PT0YcOGrVixYs2aNa9fvybmMBioXz49efJETk4uLCwsODhYT09PSUlp8eLFP3782LRpU3h4ONHufwqhiwO2RJIIXl5eZDI5NjYW++NO1JtdSgdscWdra+vk5GQDA4PS0lJ5eXkCZmcE9cufgoKCw4cP37t3LywszMzM7PPnz3v27GloaFi2bJm\\\\\\\\vz9BbgzyEsJHrd1xlIAgCgsLHz58iD12dHSEhUPb0NjYePDgwTNnzujq6j579qympkZeXp5KpeK1GD8\\\\\\\\oH7blZaWZmVlpaurq6ury2AwsBfXrl3r5uY2ZMgQfGNrkTj6oGVqzzoiU1FRefjwoYmJyefPnxUUFMrLyxFC2CbzoIktW7ZkZGSsWbPmy5cvkZGRJBJp3bp1bm5ueMfVFqjfdpmbm+\\\\\\\\cuXPEiBG5ubldu3ZFCB07dqx79+4ODg54h9YycfRBy9SedURWU1MTFRWF1YWWlha2qzws697c9u3bg4KCxo8f7+vrq6+vb2VlxWazCZ6dEdQvH7S0tK5fv37t2jVdXV1\\\\\\\\f\\\\\\\\9nz549f\\\\\\\\6caDcGeRFrHDQQqdOnT7NYLOwxmUwm4EheImAymW\\\\\\\\fvt2wYUNNTc2LFy+ys7MNDAz8\\\\\\\\f3xjqt9UL\\\\\\\\8MDIy2rFjB0IoNzd3165dDx8+JNqNQV7E6oOuq6t7\\\\\\\\Phx50PiU2FhodiuRQSrVq2qrq7G1oUZM2YM8ZuEuJCTk6uurl60aJGHhwedTj9+\\\\\\\\PiqVavwDoovUL\\\\\\\\8o9Foy5Yt8\\\\\\\\Hx0dLSwjuWtgghQevp6W3durXz50EIlZaWbtq0SSin4odMLcSBENLX1\\\\\\\\fz88M7CkJjs9mLFy9WV1fv168fh8PZuXOnpGRnBPXbnuLi4piYGBaL9euvv\\\\\\\\7111\\\\\\\\r1q0bPHgw3kG1QwgJWohbIpHJZA0Njc6HxCd5eXmxXYsIqqurZ86cyZ2\\\\\\\\4Ovri288RPPgwYOdO3cWFBSMGzdu8ODBZDJZWC0P8YD6bUNCQoK7u\\\\\\\\vPnz\\\\\\\\JZDKHwxk9erRErEUjhAQtxC2RevXqJc5pWsScsCs6dDo9MDBQ0le6EZF9+\\\\\\\\ZdvXrV0NCwvr4+MTHR0tLy58+feAfVMVC\\\\\\\\bbh06ZK1tfXIkSPLysoOHTok2OKX4ieEBA1bIkkKdXX12NhYQ0ND7OnIkSPxjYc4AgMDAwIChgwZkpmZSaVSWSzWs2fPLly4gHdcHQP124YuXbrU1tYmJibev39\\\\\\\\4sSJtbW1eEfEF+HMiYItkSRCz549MzIyMjIyEEI5OTl8foFlYc+6S5cuTZgwQU5OLjY2lkKhGBkZLV26tEO7ghGBYPUrC9hstoGBwdWrV\\\\\\\\Pz89XV1bOzsyWl\\\\\\\\4eIk1aBiHTv3v3WrVtsNpvNZjc0NPBZSurXWgkICG9NzfwAACAASURBVMjPz+\\\\\\\\Xr9+9e\\\\\\\\doNJqJicnRo0etrKzwjqvDBKtfWeDt7U2lUgcMGNC1a9dDhw6NHz8e74j4JYS1OICkCA0NvXPnjpaW1pUrV7gLmLVLitda+fTpk5ubm4eHx6BBg1JTU+vr63\\\\\\\\77bd3795JYnZGgtavLHj58qWcnNz48eP379\\\\\\\\\\\\\\\\4sULvMPpAGhByxAmk5mXl1dfX4+th8tnKalca4VGoy1ZsuTZs2eKioqNjY1ZWVkFBQXz58+fP38+mSyprRbB6lcW6OjohIaGPnr0aPv27UTbqKxtkvpZBAI4efJkdXX1vn37Dh06ZGdnx2cpbK2V6urqysrKuLi4hIQEkQYpHg4ODm\\\\\\\\evOndu3dDQ8Pvv\\\\\\\\+enZ2toKBQVFQ0Z84cvEMTnGD1K63S09MnTpyora2toqJy8+bN3NzcKVOmWFtbS1YHHSRoWfHp0ycfHx9zc\\\\\\\\Pbt2+npKRw9wBtF9YHHRwcjC2he+vWLZHGKQY7d+6Mi4vT1tbOz883MDC4ffu2np5e\\\\\\\\\\\\\\\\79T58+LbnTowWuX2nl4eHB4XDMzMxYLJa5ufm4ceMGDRqkr6+Pd1wdAwlaVpw6dWrFihXp6elZWVkvXry4ePEinwWlrA86LCzszJkzOjo6jY2NampqGRkZdDp96NChhw4dGjBgAN7RCU7g+pVW2OaKqampXbp0MTMz69q1q76+fk5ODt5xdQz0QcsQIyOjU6dOzZ8\\\\\\\\X15env9ZlO32QVdXV69evZq7nGx8fPy4ceOEGbfwUKnU9evXKygoODo6vnv3LiEhoX\\\\\\\\\\\\\\\\\\\\\\\\p8\\\\\\\\fybmGvwdJVj9Shkajfbjxw82mz1o0KDg4GAmk1lTU3P79u0uXbro6up6eXnhHWDHSMPnEvBDUVHxwoULt2\\\\\\\\fjoqKevz4Mf\\\\\\\\DsNpd71tTU\\\\\\\\PChQvcv6lXrVqlo6Mj5OiFZNu2bTo6OqdPn160aBGDwSCTya9fv5aO7Cxw\\\\\\\\UqTmJiY1atXFxQUYPdIyWRyr169lixZgo1tt7e3x9aAliDS8NEE\\\\\\\\Dh8+HBQUNDFixdVVVVfvnx5+fJlPgvyMw6ad0kwBQUFYvbkVlZW3r9\\\\\\\\39DQEFuR\\\\\\\\Pv379HR0QTc5UgwAtevNDl48KC+vn6XLl1+\\\\\\\\PhRW1s7YcIECoViY2Mzc+ZMvEMTECRoWaGhobFy5Urs8YEDB\\\\\\\\gvKB3rfTc2Nrq6upqYmJiZmVVUVAQHB+\\\\\\\\atWvYsGF4xyU0AtevNMFWwWaz2cXFxVZWVti6SMRsLvAJEjRohxSMg87Ozp49e3ZGRoa+vn5mZqaSklL\\\\\\\\\\\\\\\\v09PT3xjgt0Frarb1ZWFkKIw+Gw2ezk5OTKykoOh\\\\\\\\P8+fMuXbqMGjXKxsYG7zAFR6wETaVS3717J7bLSdxyZbgQ4nrfuMjNzV22bBmDwVi\\\\\\\\fv2nT5\\\\\\\\y8\\\\\\\\Nzc3Pfvn2Ld1ygszIyMhYsWFBRUVFRUdHY2IgQolAoFAqlS5cuV65cGTBggKKiooGBAd5hdgqxEvTatWuxnS47pLKysqampnfv3h0tOHHixF9++aWjpWSNENf7Fr\\\\\\\\U1FQnJ6e8vDyEUFhYmIWFRWxs7OrVq4cOHYp3aKCzIiIiTExMmExmY2Pj69ev2Wy2kZFRWVnZqFGj3r17N2XKFLwDFAJiJej169cLUOrJkyfx8fESN4BGUghxvW\\\\\\\\xCw4OHjBgwN69e\\\\\\\\\\\\\\\\5558vX758\\\\\\\\\\\\\\\\7dyspq7969eMcFhMDY2DgqKopEIlVWVpJIJBKJlJGRMXbs2Lq6OqlpeMFEFdAOiV7vW1NT8\\\\\\\\v37zExMYcOHdLQ0HB0dHzx4oWqqirecQEhoNFo2dnZ0dHRSUlJtbW1VVVVjY2NX758MTMzW7hwId7RCYcQWtC4rxdMJpMld4EbiSCJ631\\\\\\\\\\\\\\\\fp148aNMTEx2trap0+fPnnypKmpqcStwQ9a8\\\\\\\\79+zt37sTExMTExISEhJSXl3t4eEyYMAHvuIRMCAka9\\\\\\\\WCraysYG1ywCsmJsbR0ZHD4cyZM4dOp5eUlOTk5EjHMk9Ch3sDSzAfP360s7PT0dGZM2fO+vXrPT09pS87I6EkaNzHyVIoFDU1NTFfFBBWUVHR8uXLBwwYQKfTs7KyWCzW9+\\\\\\\\fZ8yYgXdcBIV7A0sw48ePX7t2be\\\\\\\\evS9cuKCuri7Y7SviE0KCxn2cbG5ubn5+\\\\\\\\tixY8V8XUBM0dHRDg4OCQkJjY2NX79+ra2t7dOnz9GjR\\\\\\\\GOi6Bwb2B1yIYNG4KCgsrKythsNoVCsbW1VVFRSU5OxjsuURFCgm53rQZRS09Pj4+PhwQNMAoKCiEhIb\\\\\\\\99lt8fHx9ff3WrVv37NmDtRBBc+02sFgsVnR0NDdxFxcX47XWyqtXrwoKCkaOHNnQ0PDp06cePXp8\\\\\\\\fq1T58+GhoauMQjBuLog6bT6deuXeOudpaZmQk9EkBEXF1db9++raWlFRkZWV1dferUqbVr1+IdFKGFh4fHxsYihM6fP9+jRw87O7sm49zr6+sfP37M\\\\\\\\f42NDTgtYBJVVWVuro6i8Vis9mKiorp6el9+vSR7gEC4uiDJpFIWlpa3NXOhL6YDoziACwWy8XFJSQkpLa2Vl9f\\\\\\\\8yZM5s2bdLS0oLs3K4nT548ePCgsLDQ1dU1LCys+QHq6uq8i3ucP39e\\\\\\\\C3o6urqN2\\\\\\\\eVFVVvXnzpqamprKyksFgqKqqstns33\\\\\\\\\\\\\\\\XczBiJMw+6CZTKaJiUnzP5EUFRXt7e25T+\\\\\\\\fv6+iotL563LBKA4Zx2az7ezs4uPjNTQ07OzsHj58uGPHjuLi4smTJ+MdmgT4+fPny5cvraysnJ2dPT09sXXuCeXHjx\\\\\\\\z58\\\\\\\\\\\\\\\\+fNneXm5tra2urr6gAEDGhsb3d3dR44c2adPH7wDFCEhJGhvb+\\\\\\\\Dhw+fOnXq6tWrubm53bp1c3Z27vxp+QejOGTcjRs35OTkFixYwGAwHj58iK2YM3LkyHPnzuEdmgTw8\\\\\\\\Pz9\\\\\\\\e3tLS0t7dXUVGpqanBO6Kmbt68OWbMGCaTaWRk9OrVq9LS0o8fP\\\\\\\\78+VNRURHv0EROCD0DKSkpCKGIiIiEhITo6GjxL9SQm5uLdaIB2fTjx48lS5YkJCQ8ffq0srKytrZ269atb968kfSFcsTD2Nh4\\\\\\\\\\\\\\\\79WBNnxowZfn5+eEfUlLa2Np1Or6+vT01NJZFI6enpQ4cOlYXsjITSgs7NzQ0NDdXQ0KDT6VQqVfzzaGEUh4yzs7NzcXFZsWLF9evXKRTKnj17pGamL0AIdenS5fXr18XFxfX19SwWq2\\\\\\\\fvseOHcM7KDERQgv60qVLDAbDwsKioqIiJCTEw8Oj8+cEgH+DBg26ceOGvLy8sbGxm5sbZGdpcvfu3bCwsICAgLlz506YMOHcuXOpqakWFhZ4xyUmQmhBW1paWlpaYo9dXFw6f8IW3bt37\\\\\\\\Hjxy3+qKCgoLS09MePHy3+dODAgRs2bBBRVIAgevXqhQ3AgrqWMk+ePNm+fXv\\\\\\\\\\\\\\\\v1jYmLevXsnugxDTMRabrQN48ePNzIyavFHLBaLwWC0NjJEajadA625evVqSEjI169fExMT8Y4FCJmFhcX169cnT5587tw5GfzrXGIStJ6enp6eHt5RAGIpKSmZO3duTk4Oh8OZMWNGUFDQsmXL8A4KCEFwcPChQ4cyMzM5HA6ZTD5y5MjmzZvd3d3xjkvcYH4HkFR5eXnjxo3Lzs7W1dW1sbExNzd\\\\\\\\\\\\\\\\fo13kEBISgpKTl79qyysvK4ceMMDAxIJNL06dPNzMxkcD6azP2HgXR4\\\\\\\\fq1paVleXl5t27dCgsLzczM7ty5AyN5pENhYSE2M7muro5KpY4aNcrS0hLbGVbWSEwXBwBclZWV27Zt69evn46OzrNnz0xMTPbu3bt58+bly5fjHRrolIKCAhUVFR0dnXfv3snLy6elpVVVVaWlpZWWlgYEBOAdHQ4gQQMJU1NTM3PmzOLi4oqKCgMDg549e1ZWVr569Qr2gZVoDAZj\\\\\\\\vz5VVVVnz59olAoGhoabDabRCK5u7t3797d1tZWuqd0twa6OIDEKC0tPXLkiJmZWWVlJZPJ1NTUpNPpCKEnT55AdpZ0ISEhkyZNIpPJnp6evXr1mjt3rrKy8siRI48ePerh4SGb2RlBggYS4dOnTzY2Nv369Ttz5oyamtqoUaPq6+stLCx0dHQ+fPggs99eaYKN1iCRSBwOh8PhPHjw4Pfff5eR+dxtgC4O0A7c96xjMBguLi6Ojo4LFizw8vIKCwsbMWJEv379vn375u\\\\\\\\vD1t0SwE2my0nJ3f58mU1NbXjx48zGAwNDY1Hjx7BcleQoEE7xL9nHZvNDg0NTU9Pf\\\\\\\\ToEZVKzc3NpVAoN27cGDlyZP\\\\\\\\+\\\\\\\\R0cHLp06SIvLx8eHt69e3eRRgLEY8WKFUZGRi4uLlevXt2+fXt2dvaOHTsMDAwUFBTwDg1nkKBBO8SzZx2TyaRQKNi6V2FhYUOGDImMjKTT6YaGhk5OTkFBQUZGRm\\\\\\\\evPn+\\\\\\\\buSktL27dtXrlyppaUlikiAmLFYrPz8fGyQxps3bx48ePDq1SsKBVITQpCgQbtEvSlwZGTk7t27FRQUunfvXlZW5uTk9PTp0z\\\\\\\\\\\\\\\\\\\\\\\\PPDhw8DBw6Mjo7u1q2bra1tXl5ez549VVVVHz9+DN0a0kROTo7BYJSWltJotPDw8JiYGMjOXPBGgHaIelPgffv2vXjxQllZedCgQQcOHLCzs\\\\\\\\Px8bl48eLq1auXLl06efLkNWvWTJkypaysrL6+\\\\\\\\s6dO5CdpQODwThy5EhSUhK2weCkSZPy8vK8vLyGDBmCd2gEAgkatKPdPuiampqDBw9y95z8\\\\\\\\PnziBEj+D8\\\\\\\\mUxWUlJCCOnp6X38+NHOzs7W1vbq1as\\\\\\\\fvzYt2\\\\\\\\foEGDzp49S6VS\\\\\\\\\\\\\\\\jjjz179sCADamxd+\\\\\\\\ebt26GRgYfP361c3N7e+\\\\\\\\\\\\\\\\16\\\\\\\\fv22bdvwjotYIEGDdrTbB62uru7g4MDd9ZnFYg0ePJj\\\\\\\\89vZ2c2bN69Xr16qqqpZWVlWVlbGxsYfPnzgXZ5wz549M2fOtLKy6vx\\\\\\\\BxDEhw8fduzYMXPmzF27dh0\\\\\\\\fnzYsGHq6up4B0U4kKBBO9rdFJhEIg0fPpz7ND4+XllZuY0TNjQ0eHl5JSUlmZmZHTlyZMOGDfPmzSsrKxs+fHiLq+FcuXKFyWSuXr1aKP8dQBATJ07cv39\\\\\\\\v379Vq1apaGh0aNHjwkTJuAdFOHARBXQDm9v761btw4fPvzbt2+PHj0KDw\\\\\\\\v5AnPnDnTt2\\\\\\\\fly9fDh48+MSJEwih3r17W1hYtJid3759e+XKFewwIB2eP38+bty40NDQtLS0xsZGOp0+ZswYLy8v7r4fgAsSNGiH0DcFzsjImDhxIkJo0qRJ379\\\\\\\\b+PInz9\\\\\\\\enp63rhxA8bDSpO\\\\\\\\\\\\\\\\\\\\\\\\770aNHMTExCKHk5OTHjx+fP39+\\\\\\\\PjxeMdFRJCghenp06eqqqq6urolJSV4xyI0vJsCl5aWdn4Qxbx58zZv3hwSErJhwwZ7e\\\\\\\\vWDqPT6U5OTv\\\\\\\\++6++vn4nrwgIRU5ODttEPC0tbdasWaampnhHRFzQBy1Ms2bNkpeXr66utra2xhqeUuDSpUtZWVnYpsDh4eH8bzvEYDASEhKMjIyazPebPHmyrq5udHT0rl272tj9093d3c3NTXa2B5U4rdUvQqiysvLr16+DBw\\\\\\\\W1tZGCGVkZJSXl1taWlZXV6ekpIwaNWrZsmUFBQW1tbVbt27FI3aJAQm6ZXQ6fezYsQUFBS3+lEqltjihrqGhgcFgIIS+ffvW4jovioqKre2dOG7cuKCgoE6ELCqCbQpcVVU1e\\\\\\\\bscePGJSYmLl++3NHRkfenw4cP572v2NzRo0e7d+\\\\\\\\epBQgjjbqNzk52dXVdfLkyVu3bj1z5syTJ0\\\\\\\\i4uKMjIw2bdrEZrMnT54cExNjY2OTlpaWkpIiLy+P4\\\\\\\\+C+ISQoHFfTEcUfvz48enTJxaLJVhxDofT0NDQ\\\\\\\\PWGhgYqldpikYcPHwp2LWIKCwtbunSpi4tLQ0PD9OnTO5Rqnzx58u7dO2L+ugKYNurX19f3zJkz5ubmDg4OZ8+e\\\\\\\\fr166tXr0gkkoWFxbp165YvXz5y5EgXF5eUlBRYrK5dQkjQ7U5kqK6udnR05Ca7lJSUadOmdf66ItW\\\\\\\\f\\\\\\\\\\\\\\\\bt2+Xl5e3+NP8\\\\\\\\PzW8mx9fb2CgkJrc1X19PRa22V8wIABgoVKTBoaGsnJyQihiooKbB4Kn9LT03ft2vXo0SMZ3IBOgrRRvxoaGkVFRQihnz9\\\\\\\\amhoIIRoNJqKigqTyWQwGDQabdu2bXPmzIGlVPghhATd7kQGTU3NyMhI7tPz58\\\\\\\\r6Oh0\\\\\\\\rqiNn\\\\\\\\+fLxDkGCzZ88OCwubMGECk8k8ffo0n6WoVOrKlSuvXLmiqakp0vBAJ7VRvxs2bFiyZIm3t7eCgsLVq1c\\\\\\\\fvw4efJkOTm5iRMnhoSE7N69u1u3bgcOHMArcskihAQt6sV0gCSSk5O7dOlSh4qw2ezff\\\\\\\\99+\\\\\\\\btffv2FVFUQFjaqF8dHZ2IiAju0ylTpkyZMgV7fPjw4VGjRu3evVsMEUoHISRoPT09uBULOm\\\\\\\\79u0TJkyQghsYoEVPnz6Nj4+HWwsdAqM4ACHcu3evqKjo0KFDeAcCRCInJ2f37t3h4eFwa6FDcEjQurq6f\\\\\\\\\\\\\\\\999GjR4V1wurq6ry8POwuJe5YLFaPHj2EeAOkrq7un3\\\\\\\\+EdbZxKDd+k1LS+OurMTV2NgoLy\\\\\\\\fbvMKO0ywwPAqSyaT27gDLCP1y2Qy5eTkunXr1vbJoX6b4ki+x48f79u3D+8o\\\\\\\\s+BAwciIyPxjoLQbGxsGAyGYGWtra0Fvi4uZRsbGydPnizwdSUR1K8QwZ8bAABAUJCgAQCAoCBBAwAAQclJwZhEDoejpKREkMGz9fX1xsbGurq6eAdCXFQqdcSIESQSSYCytbW1HdpPC\\\\\\\\eyJBIJ+\\\\\\\\8Kdl1JBPUrRCTO\\\\\\\\7aSAwAAQCjQxQEAAAQFCRoAAAgKEjQAABAUJGgAACAoSNAAAEBQ0pCgqVSqk5MT3lEghFBWVtakSZMWL14cGBiIdyzE1cl3SbDqLi0tnTdvnp2d3aNHj8RzRSSrnweoX2ES3Sxy8cjLy7O3t586dSregXA4HM727dtfvHjB4XBmzZqFdyzE1Zl3SeDqPnjw4LNnz5hM5pw5c8RzRY6sfh6gfoVI4hM0Zu7cuXiHwOFwOFQqlc1mFxQUzJw5E+9YiKvz75IA1b1s2bLS0lLBygpcSjY\\\\\\\\D1C\\\\\\\\QiQNXRzEoaamdu\\\\\\\\ePVdX1wsXLuAdC+Fcu3Ztw4YN2dnZArxL3LICX53D4WBz2wTeCFgAMvV5gPoVBViwX5giIiLevHkTFhYGq5I3t2TJkiVLliCB3iVuWYENHDgwNTV17Nix4qwamfo8QP2KAiRoYbp\\\\\\\\\\\\\\\\35+fj6222xwcDDe4RAULu\\\\\\\\SqlWr\\\\\\\\vzzT19fX1dXV\\\\\\\\FcEcnq5wHqV4hgLQ4AACAo6f\\\\\\\\LCwAAJBQkaAAAIChI0AAAQFCQoAEAgKAgQQMAAEFBggYAAIKCBA0AAAQFCRoAAAgKEjQAABAUJGgAACAoSNAAAEBQkKABAICgYDU7gLNNmzYVFha+ePFiwoQJlpaWCCFra2sLC4t2C9bX16uoqHCf3rt3DyGUl5dnbm4+fvz4FoscPnx42rRpZmZm2NNjx469efOGQqH06NHj4MGDCgoK7V6U9ypv377lPRtoEdRvZ0CCBjg7duwYQmjKlCk3b97Enh45ckRBQWHo0KFOTk4uLi6KiooLFiwYPXr08uXLyWSym5tbXl5ebGystbX1vHnzuAdERUVVVVVZWVmpqqp+\\\\\\\\\\\\\\\\7d1dVVX1\\\\\\\\fzc2tX79+GzZskJOTs7W15b1uWFhYcXEx9oW8fPnysWPHGhoa7O3tBw8e7OTk5O3tzS1VUFBQUFCgqKioqamZkpLCvQp2nvz8fG4MxsbGZ86codPpJ06c6NWrl9jfSyKC+u0MSNCAcKZMmbJq1ao5c+aUlJTs37\\\\\\\\f3Nx80qRJcXFx3t7eFhYWVlZWc+fOnThx4rp16zZv3sw9YO3atQihnJwchNDRo0fPnz\\\\\\\\ftWtXf39\\\\\\\\DQ2NgwcP9uzZ08HBYfTo0dyrhIaG7t69G3vs7Ow8efJk3nZZcXExt9S4ceOGDRu2dOnSuXPn\\\\\\\\v7779yrYE6dOsWNYfjw4Zs2bdLR0aHRaGJ4oyQU1C\\\\\\\\\\\\\\\\IEEDwhk6dChCSFVVNS8vLyAg4ObNm+bm5t++fRs6dCiZTNbQ0GCz2dgfy7wHMJlMCuX\\\\\\\\Ps8FBQUDBgwgkUgbN2789u2bl5eXiooKm83mvQqLxeIeTyKRsA2TuD9SUVHhLTVo0CCEkLKycvNoeWNYvnz5li1bKBTK8ePHRfLWSAWoX\\\\\\\\7BTUJAOHJyctgDY2Nje3v7o0eP9u7du3fv3snJyRwOp6qqikwmy8vLNzmAQqFwd5\\\\\\\\Q09PLysqqr6\\\\\\\\\\\\\\\\999\\\\\\\\jx8\\\\\\\\fvjw4ZMnTzb5Ak+fPt3f3x8h9Pjx4x07dlhbW5PJZCqVSqVSs7Ozm5Ti3dOoyR4XvDEkJycHBQV5eXn5+vqK8h2SbFC\\\\\\\\\\\\\\\\IMWNCAud3d3Z2fnnj17Tp8+fdq0aStXrpSXl1+\\\\\\\\fn1BQUHzA7p167Z\\\\\\\\\\\\\\\\\\\\\\\\4JEyYghLZs2bJq1arevXuvWbPGyMho3759KioqDQ0NvH+6Ojo67t+\\\\\\\\f+HChRQKJScnZ9GiRaNHj\\\\\\\\7777\\\\\\\\19fXNzc1nzpzZvNRvv\\\\\\\\3Ge5XmMaiqqq5atUpOTu7PP\\\\\\\\8U27skuaB+2wVbXgGAGhoaLly48Mcff+AdCBAJya1fSNAAAEBQ0AcNAAAEBQkaAAAIChI0AAAQFCRoAAAgKEjQAABAUJCgAQCAoCBBAwAAQUGCBgAAgoIEDQAABAUJGgAACAoSNAAAEBQkaAAAIChI0AAAQFCQoAEAgKAgQQMAAEFBggYAAIKCBA0AAAQFCRoAAAgKEjQAABAUJGgAACAoSNAAAEBQkKABAICgIEEDAABBQYIGAACCggQNAAAEBQkaAAAIChI0AAAQFCRoAAAgKEjQAABAUJCgAQCAoCBBAwAAQUGCBgAAgoIEDQAABAUJGgAACAoSNAAAEBQkaAAAIChI0AAAQFCQoAEAgKAgQQMAAEFBggYAAIKCBA0AAAQFCRoAAAgKEjQAABAUJGgAACAoSNAAAEBQkKABAICgIEEDAABBQYIGAACCooj\\\\\\\\kllZWU+fPhX\\\\\\\\dSXX5MmTjY2N8Y6CX1C\\\\\\\\HQX1K906U784JOioqKj09PQxY8aI\\\\\\\\9KS6N27d42Nje7u7ngHwi+o3w6B+pVunaxfHBI0QmjUqFELFizA5dKSqKSkBO8QOgbqt0OgfqVbZ+pXCAk6IiLCx8eHTCazWCwymbx69erp06d3\\\\\\\\rQAADGA7y+RCSFB+\\\\\\\\r63r9\\\\\\\\X05ODiHE4XCcnZ2hggGQFOL\\\\\\\\\\\\\\\\tISvzIycpWGDlAa+ItILyQFhJCgSSTS69evTU1NSSRSamoqk8ns\\\\\\\\DkBAOIh5u9v7as4+tcMNasRNaHPUCNLybS\\\\\\\\SC8n6YSQoH18fPz9\\\\\\\\QMDA5lMpomJycmTJ5scUF1d7eDgwGazsadpaWlz5sxxdHTs\\\\\\\\KUFsHv37t27d+NyaSChamtrL1y44OnpiXcgIiHm7y8t8avOigVymupkZcXamA+QoNsmhHHQ3t7eW7duHT58+Ldv3x49ehQeHt7kAE1NzaioqCf\\\\\\\\M3bsWAoFn5uTCKGgoCC8Lg0kVF5eXkxMDN5RiIqYv78KvbrXv\\\\\\\\vIYbLq3n1S6N2tc7ELgkqlOjk5IYSSk5OnTZs2Y8aMe\\\\\\\\fuvX\\\\\\\\\\\\\\\\fujQobNnz\\\\\\\\by8uJ9vd2CRUVFS5YsWbp06f3790tLS+fNm2dnZ\\\\\\\\fo0SNhRSuERJmSkoIQioiISEhIQAjZ2to6Ozt3\\\\\\\\rSiwGKxysrK8I4CSJiioiIp7rgT8\\\\\\\\dXY86kqruPSg6eVzIdoDZ+hCgukZWVtXz5cjKZ7Obm5uDgwPuj\\\\\\\\Pz8DRs2UKlUhNDRo0cvXLjQu3fvadOmrVy5cu\\\\\\\\evba2tgihZcuWcV+fP39+2wULCgocHR1nzpw5ffr09PT0devWWVlZzZs3T1j9+EJI0Lm5uaGhoRoaGnQ6nUqlqqqqdv6cIlJVVUWj0fCOAkiY4uJiKU7QYv7+kuQp2k6zRXqJkydPent7W1hYWFlZNUnQPXr0CAoKsrOzQwiZmJgkJCTQ6fSEhIQJEyZ8+PDh7Nmzs2bN4n293YI+Pj4LFiw4d+6cra1tfHz8qlWr5OTkyGShzdAWwokuXbrEYDAsLCwqKipCQkI8PDw6f04RqaioaGhowDsKIGGKi4sbGxvxjkJUJOj7y6e8vLyhQ4eSyWQNDQ1u13lz69at+\\\\\\\\nz5+3bt3\\\\\\\\99delS5devXr18ePHV65ccXNz475+7dq1DRs2ZGdnt1bwypUr69evP3PmzP379zkcDolEQgixWCxh\\\\\\\\V+E0IK2tLS0tLTEHru4uHT+hKIDCRoIQLpb0BL0\\\\\\\\eVT9+7dk5OTzc3Nq6qq2mjMRkdHT5s2rWfPnsuWLQsPD587d66SkpKysnJMTAz39SVLlixZsqSNgqmpqUuXLjUyMqLT6X379k1NTR07dqwQW9C43azDRWVlJYfDaWxslJeXxzsWIDGKioqkuAUtfTw8PFauXCkvL79+\\\\\\\\fo2DjMxMdm0aROZTN6yZQuTyfzzzz\\\\\\\\r6uqWL18+ZMgQ7uvtFiSRSLt37yaTyYsXL7a3t\\\\\\\\\\\\\\\\zzz99fX1dXV2F9X+RrQRdUVGBEGpoaIAEDfhXUlLSxl\\\\\\\\KgGj69u376tWrNg4IDg5GCPXq1Yt3TNeNGze4j1sb69ViwYCAgBZPIhSytdxoVVUViURiMBh4BwIkSU1NjbKyMt5RAFkkWwm6vLxcV1cXuqFBh2B3fgAQP9lK0JWVlYaGhpCgAf84HI4Q7\\\\\\\\kA0CGy9cmrqKiABA06pKKiQltbG+8oQAeUNhQfyvjrSOaO91WxzX\\\\\\\\a7oRA3mPaLcj7mEajrVixYtGiRTdv3hTW\\\\\\\\0XmbhIaGBhAggb8Ky4uNjQ0rKysxDsQwK8npWGO3ZyNVPoeytj+q9ZY3h\\\\\\\\xMyFwxIgR3GPaLWhoaMh9XFlZOXfu3Dlz5jRfz0RgstWCrqmpgT5o0CFFRUUGBgZ4RwE6oKKxrKeyEQmRlOVUOIjD+yNsQiB2yxebEJiWlpaQkDBnzpw9e\\\\\\\\bMnDnTZBah8wAAIABJREFU1taW95h2C\\\\\\\\I+fv\\\\\\\\+fWFh4c6dO2fNmiWs\\\\\\\\4tsJWiEkJKSEoziAPwrLi6GBC1ZtOR18+k\\\\\\\\OIhTz6ojoVZv8LY2IZD3mHZnEvI+rq2tpdPpK1euFOJsTNnq4kAIKSoqQgsa8K+4uLh37954RwE6wKbL7Et5ZygkuUldZrZxWGsTAplMJne5vnZnEvI+NjY2HjNmjJGREZVKZbFY2B4InSRzCVpeXh4SNOBfcXHxyJEj8Y4CdIC+Ytetffe3e1hrEwLbXUyVt6Cenh73saGh4erVqxUUFObPny+U7IxkKkHX1dWpqqoqKChAggb8gz5o6dPuhEDuMfwU5H388OFD4YYqQ33QlZWV2trakKBBh0AfNMCRDCXoiooKHR0dRUVFuEkI+If94YV3FEBGyVyChhY04B+bzeZwOAghCoUixSuOElN9ff3Hjx+bjEfuvHbnmxw7dmz27NmzZ8\\\\\\\\u3r17eXk5ViorK2vSpEmLFy8ODAxssrUV76yWFme4dIYM9UFDF4dgIiIifHx8yGQyi8Uik8mrV68W1nY+xPf58+chQ4ag\\\\\\\\yVoHPfSlDU5OTlOTk6jRo2Kj48\\\\\\\\ffq0ubk5\\\\\\\\2XzalhbXlSRSGjxYNWZvyjx\\\\\\\\oif+SZRUVGbNm0qKCg4deqUrq4uVtDf33\\\\\\\\nzp3W1tazZ8\\\\\\\\++fMnd2srU1NT7gl5Ty4sUtuCZjKZz58\\\\\\\\530FS9AwzK6jfH1979+\\\\\\\\HxwcHBYWFhwcfOvWLbwjEp8XL15MmDABQQta7Pz8\\\\\\\\A4ePHjixInAwMB\\\\\\\\\\\\\\\\\\\\\\\\23Q2Uvfa7bNlrj2mzdK1\\\\\\\\qmvyIn\\\\\\\\km2JFHjhzx8vLiFty2bZuVlVVhYSGHw\\\\\\\\n27dvQoUOxra14T9jiDJdOktoEnZaWdvz4cd5XysvLdXR0YJhdR5FIpNevX5eVlZWXl8fGxspUnnr58qWVlRVCSF5eHtbsFydlZeXq6mqEUFVVVUdT3s861kBdCpmE1BRIbE6rh7U23wQhlJ2draysrKury52ooqamdu\\\\\\\\ePVdX1wsXLohia6vWSO2fbCkpKU3+1qisrNTR0amsrISbhB3i4+Pj7+8fGBjI4XAGDhwoxHUGCI7FYlVVVenr6yNoQYvG58+fw8PDBw8ePHv27CZruq5du3bhwoU+Pj719fWBgYEdOq2hKjm9gjlYT76mgUNufaXY1uabIISCg4OnTZuGeCaqREREvHnzJiwsjEwmDxw4UOhbW7VGahN0ampqbW0t7ytYgq6rq4MWdIe8f\\\\\\\\\\\\\\\\+7du3WB90XFzcsGHDZKQP+sOHD9yuT0jQQvflyxcPD48tW7ZERkamp6d7enry\\\\\\\\lRbWzsqKopGownQY7DcVHXry2oKmbRsiEobh7U23wQh9PTp0ybbZd2\\\\\\\\fz8\\\\\\\\P3\\\\\\\\+\\\\\\\\PkIoYsXLwp9a6vWSG2C\\\\\\\\vbtW5OWcnl5uba2dklJCSToDsH6oLGZURwOx9nZWUYSNLcDGkEXhwg8fvx406ZN06ZNmzJlytSpU5skaIxg\\\\\\\\bm9NSk3bXXbOKDd+SYRERFNivj5+fE+bbK1Fe+slhZnuAhMavug8\\\\\\\\Pzu3TpwvtKUVGRvr4+fNM6Smb7oOPi4saMGYM9plAo8LERLhMTk4iICBaL9ejRo379+uEdDkFJZwuazWbLyclhI1h5XyGRSAoKCtAH3SHt9kFXV1c7ODhwt1X99u3bzJkzHR0dxR6pkFVUVHB\\\\\\\\x8vLy8vObybxmD59ekZGho2NzaBBgw4ePIh3OAQlnQk6OzvbyMgoJyeHzWZjHfnYKwhWs+u4dvugNTU1o6KiuE+dnJyUlJSanUayQR+0KKxfv75JVy9oQjoTdGpq6qBBg0pLS+vr69XU1LivIIRgokpHyWYfNIPB4P01Awka4EI6+6CxdKympsYdyAEJWmCy2QddUFDQvXt37lO4dYEvGo3G22MpO6S2BT1v3jx1dXXeBD1v3jwECbrjZHMcdH5+fo8ePbhPoQWNFzabvWLFip8\\\\\\\\f9bU1Bw8eNDa2hrviMRKOhN0VlaWkZGRmpoad64K9gpCCG4SdlR4eHhsbCxC6Pz58z169LCzsxPuQCJiys\\\\\\\\P521BwygOvDx9+rR79+4BAQFUKnXu3LmQoDuMmIvpyMnJqaurcxM0NooDwU3Cjnvy5MmDBw8KCwtdXV3DwsLwDkdM8vLyTE1NuU+luAVNzO8vF51O19TURAgpKSmJYWo10QghQRP2JpKqqirWxcHbnwhdHB318+dPbEkKZ2dnT09PGo2Gd0TiUFBQMGPGDO5TKR5mh9f3l8PhvHr1qr6+fsqUKfLy8q0dZmNjc\\\\\\\\bs2dzc3PT0dDHM3CMaISRo7CaSqakpiURKTU0lwucYm9fP7YPm3iFEkKA7zs\\\\\\\\Pz9\\\\\\\\f39LS0t7eXkVFpaamBu+IxKF5H7S0dnHg9f1ds2aNmpqajo7OyZMnIyIiWlvKVUlJ6dGjRykpKfr6+ti6KDJFCAma9yaSgYFB85tINTU1Xl5e3IkMCQkJ3AlaokCj0bABUtwujm\\\\\\\\fvg0cOBD7KYlEks3bwQIzNjbev\\\\\\\\\\\\\\\\\\\\\\\\tuCcMWMGb7tSimGL03KfSnEXBy7f38bGxszMzKdPnyKESkpKkpOThw0b1trBZDIZW5VbBgkhQScmJg4fPnz48OEIoSNHjiQmJk6dOpX3AHV19TVr1nA\\\\\\\\37m5uerq6p2\\\\\\\\bmtqa2ux86upqf348QMhlJ+fb2FhwT0AEjRoV5MPiRR3ceDy\\\\\\\\ZWXl6+vr6+trVVWVv7+\\\\\\\\bsMNo35JIQEHRkZGRUVtXr1agqFQqVSMzIymlQwiUQyMzPjPtXW1hbpzhRUKhWbnMIdB11WVqanpye6KwIp09jYqKCgwPuKFHdx4PX93bdv36xZs9hs9rJly7p169b5E0olIUxUOXHihJ+f34cPH6ysrAYMGODu7t75c3YGbwsaS9ClpaW8CbrJyrMANFFQUNAkZUhxCxqv7+\\\\\\\\EiRNfvnz5+vXrlStXiueKkkg4LdkxY8ZYWFgcOnTol19+EcoJO4PbgubeJKyqqtLQ0MA7LiAx8vPze\\\\\\\\bsyfuKFLegEcG+v4CX0LoaFBUVd+3aJayzdUZtbS23i4M7DhpazYB\\\\\\\\TWapIIQoFAqdTscrHjEgzvcX8JLCtTi4CZrbgm6SneEmIWjbjx8\\\\\\\\mrSgYS0OgAspTNBUKpXbB02lUhsbG9sYBg9Acy9fvhw1ahTvK1I8zA4QmRQmaG4LWlFRkcFglJWV6er+f\\\\\\\\vfQHcHaENdXR2TyWzymYEEDXAhhQma24LGNB9jB10coA2PHz+eNGlSkxehiwPgQgoTdF1dHdaCxpSWljbZnJBCocjgqiuAT+Hh4bNmzWryIrSgAS6kMEFzh9lhmgyCRrAcB2gdh8NJSUkZPHhwk9eleBw0IDIpTNDciSqY5l0csCQ0aM3Hjx+xSc9NQBcHwIUUJmjeFjSFQvn582eTLg5YEhq0Jjk52dzcvPnrcnJy0C0GxE8KEzRvC1pNTS0nJwe6OACfsrOz+\\\\\\\\Tp0\\\\\\\\x1aEEDXEhhgqbRaMrKythjdXX17OxsSNCATzk5OdjWaE3ATUKACylM0Lyj6NTU1LKzs3V0dHgPgAQNWtN8DiEGWtAAF1KYoHmpq6szGIwmMwmxCSx4hQSIjMlktjjvFFrQABdSnqBVVVWb3CFE0IIGrWgtOyNI0AAnIlw4nwjU1dWbL9UPCbpDCL7rsxDl5eXx7kPIC7o4AC6kLUGz2Wxsf2KMmppa8xa0vLw8JGj+EXbXdqFrbQgHgha0WDCZTDKZTCZL+Z\\\\\\\\1HSJt70VdXZ2qqir3KbSgOw\\\\\\\\b9bmsrKy8vDw2NlaK81R2dnaLQziQtC\\\\\\\\YTwQHDx6cMGHCb7\\\\\\\\9dv36dbxjIRBpa0E3meetpqbWPEHL+E1CJpPZoT3leHd9HjhwYPNdn6VGTk6OjY1Niz+Cqd4ilZ+fHxcXFx0dzWKxxo0bt3DhQt6\\\\\\\\g2WZtCVo7lqjmF9\\\\\\\\\\\\\\\\bV5r6LMziS8du3a5cuXzc3Ne\\\\\\\\fubWhoaG9vz0+p9+\\\\\\\\fv337FuuDjouLGzZsGHRxAOGi0WjYWFg5OTllZWUmkwkJGiNtCbrJWqOGhoaGhoZNjpHZPui7d+8+e\\\\\\\\Zs8+bN69atW7FiBZ8JWnb6oAsLC1vbXhpuEopU3759GxoaXF1da2pqRo0apaioiHdERCFtCbrJSkktktk+aAaDkZSUxGKxPn\\\\\\\\+nJ+fz2cprA\\\\\\\\a1NSURCKlpqZKcUOSzWa3docKWtAiRSKRrl279uXLFxUVFdi4ltd\\\\\\\\CRr7\\\\\\\\HWod5KAamtreW8StkhBQQHbq1DW+Pr6njp1qrCw8NatWwEBAXyW4vZBM5lMExOT5n3Q1dXVDg4ObDYbe5qcnDxx4kQhhi0edDq9jYYb8RO0FHx\\\\\\\\TU1N8Q6BcP6rTnt7exaLtWTJEu4rjo6OeITUKU26OFqkqKhYXl4unngIhc1mr1q1Sl5e3tfX9+fPn639Od+Et7f34cOHT506dfXq1dzc3G7dujk7O\\\\\\\\MeoKmpGRUVxX3q5OTU\\\\\\\\MYs8WVnZxsbG+MdheCk4\\\\\\\\sLmvjvD7q9e\\\\\\\\caGBgo8cAxLIE1uUnYIpnt4tiwYYOiouLGjRvnzJnz77\\\\\\\\\\\\\\\\8lkqJSUFIRQREZGQkBAdHR0cHCzKGHHz\\\\\\\\ft3if7jWjq+v6CJ\\\\\\\\1rQbDZ7\\\\\\\\fr1OIYiFFQqtd3mm8wmaCUlpYqKChaLNWzYMP5XN87NzQ0NDdXQ0KDT6VQqtd0eJAmVkZHRt29fvKMQnHR8f0ET\\\\\\\\yXoyMhI7AH3VomZmRk+QXUCtKDbsG7duhs3bhw9evTBgweLFy\\\\\\\\ms9SlS5eysrIsLCwqKirCw8M9PDxEGiReMjMzp06dincUgpOO7y9o4r8E7eXldfv27TNnzmhoaFRVVUnob2NI0G348eNHXFxcampqh+rX0tLS0tISe+zi4iKy6HCWmZkp0X3Q0vH9BU38f\\\\\\\\d8L1y48OrVKzKZzOFwpkyZsnDhQrzCEhg\\\\\\\\w+xkdqKKYPXr5ORUWVnJ3QMBISSV3dC8+zxIKCn4\\\\\\\\rZt3759T5480dDQOHHihET3R\\\\\\\\Hv\\\\\\\\0vQLBbrw4cPQ4cOTU5OJvigotY0merdIpltQQtWvxcvXly+fPndu3dFGhu+GhoaFBQU8I6is6Tg+9uGV69eFRQUvHz5MjMzc+PGjWFhYXhHJA7\\\\\\\\Jeh37975+vqePXsWW3TR39+fz1MQajlKPofZyeZaHAEBASdPnszNze3Vqxf\\\\\\\\9auuri7F629g2pjkLSmk4\\\\\\\\vbhvz8fHNzcxKJ9Msvv1CpVLzDEZP\\\\\\\\EvT169c\\\\\\\\f\\\\\\\\6sqqo6evTo8ePH8zlIFhFsKnBVVZWmpmbbx8jstN33798nJSVpaGgkJia+f\\\\\\\\+e\\\\\\\\1Flra2SLDUkfQgHwvX7y0GcUkaROkVTWU4FIVTeUKpAVlSnaLR8cGMjs7SCYtCF1MHVNmxsbObMmcNisd6\\\\\\\\fz9jxowOlZVc\\\\\\\\yXo06dPI4RoNNrDhw\\\\\\\\\\\\\\\\\\\\\\\\PPP9PT0+vp6fk5BqKnAHA6n3fVkFRQUZLMFLfV9lAKTggSN1\\\\\\\\e3gd1wJueglrxOCaNour7dx5r4elYdnUUzUTebqmfb5ODG\\\\\\\\KKyc9cVendr+PFTb8NyShdt\\\\\\\\i+kp6cXHh4eFRXl4uIyatSoDgUpuf5L0I8ePXry5ElmZmbXrl137NgxadIkPk\\\\\\\\R7nKUNBrt2rVr3L1cMzMz8R1LS4Qujvv375eVlQ0aNGjcuHFiu6h091F2RkZGxoQJE\\\\\\\\COolPw+v5+qnk\\\\\\\\5P+1d+YBTVxbA7+TnSUJi+wgm\\\\\\\\rYtKAsLiA+t4qiiFJbtFp324dWrXu19umn4lYtSlWqtS6tz7qhqGjBpZiixa0qCCiyIyA7gYQly3x\\\\\\\\TN80LyEhG8kk3N9fyWTmzsnczMmZc8\\\\\\\\CDBhvM6VT3Lmn8Ct7htNnrmsAADvffDmuTyQJ+R8zmXv9rvWSj2iuTu25BS0371l+LK3BFWNlZRUbG6vSIYbO3wp627ZtFApl\\\\\\\\vz5Y8aMUemRNjMzMzMzMzIyMikp6fXr13Z2dvPnz5fcgUwmW1pa4hNMo9H0W0tQ7wr6xYsXx44dmzVr1q5du3SpoDEftKo+yt5AYWGhQacRAv3dv2SELESFAAARKkQAIhQLAAAoQMVADAAifTIyGRUIAQCoQIhQYEHR7vlbQWdmZra0tGRkZHzzzTdFRUUuLi6JiYnKDHHhwoXLly9HR0d\\\\\\\\9913w4YNW7x4sdQE02g0ycqWly5d6qF4JiUjpfSuoOPj43fu3Dlw4MBjx47p7KQikcjV1XX\\\\\\\\\\\\\\\\v06O6OhIBaLm5ubDT1DUl\\\\\\\\373usoAelew+WxHOFTdMdZme3PPmm6N8CcWeo1RgSIu1sFEx67\\\\\\\\qvB+3uWXuWmNh8sUCeSA2Cuj+bs2xodgNZQxBZLd+b+FtBV1dXP3jw4MGDB3l5eTQazcHBQckhSCRSYWHhN998079\\\\\\\\\\\\\\\\4aGhra2tp4RtXsaGhqwst+KodPpelwkfPPmjUAgGDRoEAAAt0p0AIVC8fX19fb2xrecP39eZ2cnMsnJyePGjet2N11Olhro6\\\\\\\\4lI+Q4t3U8UasJyYSEkL3M\\\\\\\\drFbWSETEWkwxZrOqp+5J0YNzU6t+FpK7Pv+xZdR1s1CRoOl+4Z32dKfmtOIf91tP1MleQxMv7+i1u4cGFBQcH06dOvXbuWkpKyceNGJYfYtGnTnTt3+vfvDwDYuXPn4sWLe0RSJWhsbLS0VGrZQTc32969e2U37tu3b82aNTo4uxS5ubkfffQRnU739vbetGkT1M44hw4diouL63Y3MpmMl1QlIPq9f83I5ri7mUEykdXOAIDslqfjbaYEWoyY7bH0OfexvKHyWl+MtBoXZDFihuPcAl6uGsIYE39b0NeuXVNviAEDBgwYMAB7vXv3bi0IpS719fXW1tbK7KkDBY2i6MGDB1evXi21vbi4WC9FEjC9jAlw5MiRDz\\\\\\\\8MD8\\\\\\\\X\\\\\\\\diEI07d+74+fkpUx8VKwlN2HwW4t+\\\\\\\\dnTHZ9xHg9lD3\\\\\\\\Dyrah9FOx2py51hOXoivZSM3I3OQ1GjwGX95ZFeQtaB1RXV9fV1club2trw0tB6vipubKyMjk5+Y8\\\\\\\\\\\\\\\\rCxsfn+++91eWrCkpSUtHPnTmX2xMLnCaugCUhDQ8PXX39dVFT08ccfx8bG+jEDKtpL9xRutqJaz3CcJ+8oD9MBZWZFe4u+ZlHYM50W6lJgAmJUCrqhoUFJBY0gPb7yUFpayufzFbfQZjAYOksyHjFiBJfLnTZt2syZM0kkkh6XClTl2bNnf\\\\\\\\zxx6efftoTg1dWViqZQ0ihUHpnfpParFixYubMmaGhoQsWLPD09AwODp5gM3WCzdRuDxxlPWGU9QQdSEh8iK6gR40adffuXSX1aVNTE3HSDcrKygAAra2tFhYW8vZhsVjNzc266T8yZ84cScEMiF27djU1NdHp9Hnz5Jpd6qFM7UMcKpUKg8dVory8fMKECQCAKVOmvHjxIjg4WN8SGR6EVtAFBQUZGRn5+fmSsQcKUDKKQzeUlpZaWlp2q6CV6TCgFZYsWaKDs2idyspKLpebkpIyY8aM4uLizz\\\\\\\\\\\\\\\\vE8fue5LVcnJyfHz81NyZ+K3JSQaISEh27dvHzFixNGjR3UZUWpMdJMVrV\\\\\\\\u3bsXHh7O4XCU3F95Ba0D529JSYmvr6\\\\\\\\i7rRMJpPL5fa0JAbNkSNHlixZQqVSL168+N57702YMKGkpERbg2dnZyvfqLTXlnBRm23btvXt2\\\\\\\\fu3bsHDx4kzqOtYUFoBc3hcDZu3NgTChpBkJ7W0aWlpbIKWiwWS7qkMQu6R8UwaAQCwa1btyIjIwEAJBJp+vTp\\\\\\\\\\\\\\\\d\\\\\\\\\\\\\\\\3f06FFtja+SgoYWtKpQKJTZs2dv2bIFtutWG0Ir6NevX48bN66oqEjJ\\\\\\\\ZVfJNRBzf7W1lZ7e3spBd3a2iqZsQYtaMXk5OQEBQVJVr96\\\\\\\\\\\\\\\\3379y5oy1L9uXLlz4+PkruDBU0RPcQV0FXVFS4uroCANzd3ZV8qu3s7KTT6crsSafT29vbNRGvWxAEYTKZUgayVD8BFosFFbQCnj9\\\\\\\\LhUzTiKRJk2adPXqVa2MLxAIlPzBAKigVae5uTktLe3PP\\\\\\\\+8efNmVVWVvsUxSIiroDMyMrBCQmFhYffu3dPu4AwGo0fLcTQ2NlpYWJibm8ta0JL9BKAFrRhZBQ0AmD9\\\\\\\\\\\\\\\\vHjxzUfvKKiwsnJSfn9oQ9aJbAQjuvXr48ePfrMmTMfffRRZmamvoUyPIiroH\\\\\\\\\\\\\\\\\\\\\\\\feRI0cCAFRaJ1QSBoPRo4HAWNcSWQtaysXBZrOhglbAy5cvfX19pTY6OjpSqdTy8nINB3\\\\\\\\x4oVKvlF5cdBQa3fJuXPn1q9fT6VSk5OT6+vrf\\\\\\\\zxRy0uHvQeiKugCwsLsfoAAwYMUMYNLRKJlK9i2tMWdGlpqZubm6wFLdWRi8lkKg7z6OW0t7fjWZeSzJ49+6efftJw8CdPngQEBCi\\\\\\\\f5dx0AUFBViggobCGB\\\\\\\\W1tYlJSXW1taPHz+2tLQsKipSsgwDRBLiKuiOjg7MP4h1S+t2\\\\\\\\6amJgURx1L0tA+6tLTU1dW1SxeHwfmgU1NTo6KioqOjp0yZMnXq1Bs3bujmvGVlZX379u3yo8jISLVLT+D8+uuvKhXp79IHnZqaunnz5m+\\\\\\\\\\\\\\\\fby5csaymNkzJo1688\\\\\\\\\\\\\\\\0xNTd27d++bN28OHDiwYcOGbo9qF7fdqEk+V3miqr1CB0ISH+ImqkhmD2JPl1QqVcH+KmWp6MCCHjFihFgs7taCJr6C1lfPyWfPnvn7+3f5EY1G8\\\\\\\\f3z8rKCgkJUW\\\\\\\\wJ0+e+Pn5dWmey6NLBf3rr7+ePn06NDQ0KSlp6tTuk5h7D1Qq9cSJE6oe9WN5YgArZIC5z4mK75a5bTCX09iw90BcC1oSFxeXiopu\\\\\\\\lGxdTklB2QwGD1qQVdUVDg7O3fpg5a0oNlsdnNzc8+JoRWwnnV1dXX19fWZmZk6i2TocoUQ55NPPjl16pTag58+fXr27NkqHSK7SMjj8To7O62trZUPNIIopkXYPNRypKfpPwayhpS2KRtfa8QQVEFLhaP17du32woSDQ0Nyju5etrF0dzczGazjcMHnZSUlJWVtXr16i+++ILD4cj2rOshnj17pkBBBwUFZWdnqzeyUCjMysoaPny4SkeRyWSpP6c7d+6MHj0aACA70RD1YJBM8ltz6jprclueOTNc9S2O\\\\\\\\iGoi6Ourk6yQoWrq2tpaaniQ5TPUgE9b0F3dHQwGIxufdA6CMfWnEePHj148ABbCcjKyvL39+9pF8eFCxfOnz9fXl5ua2srbx8EQczNzblcLoul8lPw8ePHJ0+erGpFQxqNJmVB37hxY9GiRfhbFEV1UCWRyHC53GXLlpWXl\\\\\\\\v4+Ozfv1+xTxIDBeilqp9fVT8yrWyb\\\\\\\\NJ75tQp6c1ZrSJutP0sNlX6di4rK1uxYkVDQ8O4ceOU70hg0BDUgq6rq5M0h11dXbt9hGxqalJbQWslqxBFUfwGxvLIzc3NFbs4pOjp5Eb1wHzQycnJKSkpycnJZ8+e7ekzHj58eN++fQ8fPlS8W2Bg4OPHchtzyOPhw4cXLlxQo6mNlA+6sbHxzz\\\\\\\\\\\\\\\\xL3kdnZ27969U3VMIyM+Pj4qKurOnTteXl5JSUnKHPK0+Q+0vWPB1X6RYSvvxqCCE2mxTgsW9V3Z36yL+mirVq3asmXL3bt3q6ur09PTtS0+ESGuglbVgn748KGXl5eS40suEqIoGhwc\\\\\\\\ObNG\\\\\\\\VExblw4cKePXskt8guKylQ0CiKBgUFVVdXayiG1tG9D1ooFCqTQhIcHNytEpeirq5u+fLlp0+fVsa4k0IyDhpF0YULF27btg03maEbGgBQVlY2dOhQAMDQoUOVvBr1nbVuQkdqXyc3Zv9mwCWZ0FGh3JCt+vp6Pz8\\\\\\\\BEGUH9\\\\\\\\QIaiLo7a2VrKqpIuLi+LEhJKSkrq6OqwTqzJIJqpcvXqVx+Pdu3dPw4JbGRkZ3XaGlsoklOTKlStv3ryprKy0t7fXRAytk5SU9MMPP5w8eRJFUS8vL1kfdHNz85IlS\\\\\\\\B+fQ8fPsRSQNVDXuyzLMHBwaqmFC5dujQ+Pt7Ozk4NwSTjoA8ePDho0KAxY8bgn7q7uxcXF2PqqdcSGxu7ZMmSDz744Mcff\\\\\\\\ziiy94PJ6ZmVmrsAUFKFMmHgMVCEVNXH9m4LGmBH8RUpSV5ddsT7ZgIRS52QyTJ09esGBBaGhoYmLipUuXevjbEAKCKui6ujpJddltbaPdu3evXbtW+fHpdHpjYyP2+ttvvz116lRSUpJUt3lVuXfvXreKSWrxE\\\\\\\\y3rh6CIAkJCXFxcQQsWdCtD5rNZh85cgSvDrhw4UJNqnKXlJS4ubkps6etrW1NTY3yI587d87Ozm7UqFHqCYY\\\\\\\\D4nF4rNnz0plt7q5uT158kS9kY2GyMhIV1fXrKwsFEXPnTu3e\\\\\\\\fuafERwFFIRsiODJcYhzn4np1F5fXHzlEdbcU19UtWLs2bnDe6sN3N2t10qaLy3CtXrkxNTV25cqW\\\\\\\\v\\\\\\\\\\\\\\\\MmTO\\\\\\\\++47lVKNDBFiKeiGhoaamhovL6\\\\\\\\a2tphw4ZJfoQrMtmjKisr37x5g+WFKwnug05PT\\\\\\\\f39x82bJiGnbYbGhpIJFK3tUNlXRxmZmY8Hi8zM3PIkCEDBw4koIJWJg5aMsCRRqNpslZWVFTk4eGh5M7Ozs5v375Vxh\\\\\\\\S0tKyf\\\\\\\\\\\\\\\\+27dvqy0YhULBrASsSoxU2qq7u\\\\\\\\vFixfVHtxoGDhw4KtXryZPnrxq1aqGlvqlv849E3oVAHCwJJ4rbGJR\\\\\\\\vqdNF9Ot\\\\\\\\liPqWPJf+PZwLO69Ap44Hc9eD\\\\\\\\IScnZ+fOndHR0SUlJevXr9fBioh+IZYPevv27YcOHQIyLg4AgL29vTz\\\\\\\\7N27d6dPn67SiXAf9P379ydPngwAcHZ21qS8A4fDiYiIwGI28BxIWWTTbbBkwvPnzy9YsEDBd9QjOvZBFxYWKq+gg4KCsrKylNlz3759y5YtMzU1VVsw3IL++eefZ82aJfWpMsskvQQEQf7yd6EA\\\\\\\\PefWoyK\\\\\\\\n4DAEAQIBYDAFCxWKU\\\\\\\\cxKJhA0uFosl69AaKwSyoGtra7OysjA3rtQiIfjvDeDg4CB7YF5e3vjx41U6F25B43FaI0eOvHfvnuyNpyQcDicqKgp7yMVcb5InUuBUxRSK0wJxAAAfo0lEQVR0fn6+l5eXSCQioAXdrQ9auxQXFysfoTxs2LDLly9PmzZN8W719fW3bt366quvNBEM80F3dHS8evVKdrWDTqf3aG6qATF+\\\\\\\\Pjg4OBDhw5ZWFjMT4z9pujfJEByM+3HorABAFlZWU+fPh0zeJAw4WStsEPY2Oz05Wd\\\\\\\\+adRlP8kR9TENQvxJzG7Xs5ZsGDBtGnTLl26VFJScuTIEd19K1XIbXle01k9iDXEiqppezYC\\\\\\\\QXt379\\\\\\\\7dq12NpdY2Mjm82W\\\\\\\\FRBrkpubq7yZdcx8NuppaUFU9BhYWG\\\\\\\\\\\\\\\\\\\\\\\\67mqID8Pjx45CQEOwRmMfj4X4Mc3NzHo+n4EAmk1lQUODg4IAgiIODAwEVtI2Nzfr160+cOHHy5MkNGzb0dAdFlVwcgYGBjx496na3vXv3rlmzRkODC4viuHLlyqRJk7rcQcmiMUZPeHg4g8EYNmxYaWlpqOm4f7muXeK6Ktp+JgDgl19+2bt3r5WV1adbvtr4NvtiR93LUJ+psR\\\\\\\\V1tYCABp+vNDxugQhk9\\\\\\\\FHxHzuy42aWlpeefOnT179mRkZBCzUUtqzaXHzQ8YJMbh0j0NgjoNRyOEBb1y5cq3b99WVVVt37796NGjWPazlB\\\\\\\\T09Nzw4YNFy5c2LJli1QP2bq6OlUbiUpa0FhYhZ+fX05Ojnry8\\\\\\\\l8Op1Oo9GwtzweD3+UxrK9FaQ4slisa9euYauLVlZWDQ0N6snQc8TGxjY2NpqYmOBbkpOTe+50jY2Nysez02g0Op0ulZ8py71793bs2KGhYFQqNTMzs7q6Wl5dJMwhLq\\\\\\\\AUy+hoaGhurr61atXTCYzIiLixIkTCQkJ+Kfnzp07evSolZWVi4tLbGws5hRqaW29e\\\\\\\\fujBkzOksr7bcsBwCImls6XhWbBHRtdSEI4ujoqJuvowY5LX+u8dyKAAQAkM19quFo+reg6+vrCwoKkpKS0tPTEQTx9vbOy8uTXWUaP3787du3Q0NDpdbKuy2i1CWyLg4EQfr06aNSVABOZWWls7Mz\\\\\\\\lbKgla8cshisa5fv44paB10SlSD77\\\\\\\\\\\\\\\\3tzcPFmCHj2dqguMI0aMUFwJHqvNrXmOH51OLywsTE5Olvd36+bmVlxcrOFZDB3swTc1NbW1tfXly5dSRq6npyfWfCMjI8PS0jI\\\\\\\\P18kEmVmZnp6egIAEApFWFOPikQdr4sptoZam5RFYZe1FaEAfc3LtaVrGjKrfwXN4XDCw8MtLS0xR62Xl1d2draszkUQxNLS0sPDQ8oJUFBQgJWNVgncxcHn83FrNzQ0VD0vR21tLZaUjGkByVANyWzvLhcPsXIckj5NouloJpOps\\\\\\\\obNTU1CtK7uyQ8PFxxw53bt2+PHTtWM7kAAGD06NFZWVkKntW8vLxyc3M1P5Gh8KgpM7Ek\\\\\\\\lzliTYRH99IJpOPHz++atWqvn37jhgxQip0ddOmTdeuXRs1alRzc\\\\\\\\P58+c3bdo0ZsyYsLCwIUOGAACsFsQ0nLj4bkuiafB7VCd1YtWJwEeO82\\\\\\\\UJO8u3GRLd\\\\\\\\A2VzYzQx76d3FwOJwZM2bgb318fA4dOiTPSHFwcLhz547klry8PCmPhzJ0WYtj5MiRZ86c6XbFSRY85gTTrZKLhJIKuss0QhaLJRmzZWlpqVLOum6QfD7oUQoLCzFjSnlCQkK2bt2qYIdbt25t375dM7kAAIBEIin2Yvv6+h47dkzzExkExfyCR02Z81yWFfByz1Yen+eyFP9owoQJ8mpPslgsyUt04cIFyU+pjna2axf3kMA6w4Jq9anram2NpgULWsOC7k+ePBk8eDD+1tvbm8PhyLNTZAPRtKigAwICnj5Vx2eEO8FpNFpnZ6esDxp73aWC9vT0\\\\\\\\OCDD\\\\\\\\C3xFwn1BnFxcVKZqng0Ol0EomUn5\\\\\\\\\\\\\\\\9ddfy5aUQ1G0tLTU3d1dayLKx8vLKy8vTwcn0i7q3b9lbcWD2UPNyOb+rODaTsLFhhoNWrCgNSno3traampqKunQYLPZnZ2d8kIF7OzspNzEeXl5c+fOVVXmLoOiKBSKmZmZSp1ZMGprazEfBRazIc\\\\\\\\F0eVaVkBAgGQ2FKagVQ1KMRqys7PVKJU3duzYzz\\\\\\\\\\\\\\\\3MPD4\\\\\\\\z58\\\\\\\\PmzZP8KCcnx89PUXKaFjHQSDv17t9\\\\\\\\mPuerkiyptkU8HLdTFX2MUKURAsWtCaJDL\\\\\\\\\\\\\\\\\\\\\\\\rtUxiAAwNvbW56Clm3cWVZWplJvZgw8d1xq7WjEiBH3799XdTTcxYEtCSpwcSgONgC93oLmcDiyv4duWbt2bVpa2o4dO2Tzyq5fv65qjLwmEDPVSDHq3b\\\\\\\\2dKcPHD95wX3CpLCn23+Mb9+4cWNYWNjQoUOHDx8+evToSZMm1dWpFmrW8iun6stvqjbu493\\\\\\\\n8fZ9evXh4WFhYaGar2FNJHRggXdbSKDSCTicDj4xL979w6v1cDhcMaNGye1v7e3t5Jhc2KxmEKhqLdALxaL29raJKPHAAAjR45MTU2dOHGiSkPhaTXYip9UFAe+st\\\\\\\\S0tJtNSV7e\\\\\\\\tXr16pdHajoaCgwMPDQ42YHAwrKysmkykZRs3j8S5fvqx4CVG7+Pr6vnz5kmjlrhSj9v3rZuLpZvI\\\\\\\\CwZPnz599+4dh8P58ssvU1JS7t+\\\\\\\\n5aWtmfPnl27dikpjKillf\\\\\\\\whcP2L1AxWv3VftMQf4RMAgA8fPiwqamJw+E0NzdHRUX99ttvGn5rQ0ELCvr69etYnNPhw4ednZ2jo6OlIrH4fH5aWhpe7ayzsxPXvyNHjpS1mObNm6dgKd\\\\\\\\U1BQPvcjPz1cjhAMHD4LGCQwMVGNBCfdB4xa0pA8at6B5PJ4yFnTv+fFJcenSpaioKE1GmDNnzk8\\\\\\\\\\\\\\\\bR582bsbWJi4qefforHp+sALJpessod8dHk\\\\\\\\pWiqakJW0\\\\\\\\m8\\\\\\\\nYZXd2dm5qalJeGLStg2zBAgiCkBGSKQMIhYBMkxyZxWLhkvQGtKCg09PTr169WllZuXjx4pSUFNkdmEymZJrA4cOHcQv6\\\\\\\\fffl91fcs1QFswJgK31K1NATh4IgnC5XKl8RRMTEzVanOA16jCHhpQFLemDVlCtH6M3uzjS0tLi4uI0GSEiImLbtm0zZ87s169fU1NTSkpKRkaGtsRTBj8\\\\\\\\v19\\\\\\\\\\\\\\\\VWXZ9QcTe5fKby8vNauXdvY2Jifn9\\\\\\\\Q0LBly5b09HTJRJUuaRe3lfALben2VtQ+FFtrVChoOH4B7RRQ7G0QOk2Migv5r\\\\\\\\qFuO\\\\\\\\evZvP579+\\\\\\\\To6OlqT72tYaEFBV1VV\\\\\\\\fbbb+Hh4XPnzl29ejVeZ7mHcHBwqK6uxhQ0h8PRJENM1oLGULV3Eb4zpo5bW1txV4akBd3S0tKt60Z2FbSXUF1dbWZm1u0fmGKoVOrPP\\\\\\\\\\\\\\\\8ySefjBw58rfffouPj6dQdBpI2q9fP807P+gYbd2\\\\\\\\L168+OyzzyIjI5OTkzdv3vzPf\\\\\\\\4zOzs7Li5O8W++WdCYWLLTjxVwvebCaOuIAHaIzYp5HYVlCIVCc3MSo6IDJTscGX25gsbPTs21L3afO3fugAED1JPQENHCz\\\\\\\\fYsWM\\\\\\\\\\\\\\\\PBDYGBgTEyMqakpl8vVfEwF2Nvb4zZmaWmpq6v6nSW7DKvAqgyrVNMdTy3Bgur4fL6kgsYvSGtra7cxZLKroL2E9PR0VV3\\\\\\\\XdK\\\\\\\\f\\\\\\\\\\\\\\\\U1NT09PStW7eq7c5WGwqFIhKJDKs5obbu3+PHjx88eHDw4MEfffTRvn37pk+fHh4e3u1Rj5oz37eNCmQP7xC3HyrZHcAOAQhC7\\\\\\\\fXTV3WVmxPd5rh8AkAYOebjdNGzEKAwVxYraCFKA4PD4\\\\\\\\t27djts\\\\\\\\EiRN7OlYfdwKoVFVHFhRFu2w56urq2m0HcUna29vxlUbcgsYtQVtb28rKSuz1ixcvlImfQxBEB22liMa9e\\\\\\\\eUuZ+Vgc1mx8TE6F47Yzg7OxuWk0pb96+lpSVWsLesrEz5TCtTsnlDZx0AoEnQwCCbyHxq1iioBwB0ijtFQNjbtDMgQiahqjg4OGDpJJo4oMF\\\\\\\\fdBdKujS0tKgoCAlx6mtrcWDAs3NzSsqKiTD7PASH7a2tkpmYXh6epaUlGjYf8vgyM3NVb6lJJHBfj9ErubTQyxfvvyTTz5JSEgwNTU9ceKEkkeFWIT9WH5wV+FGMiDPdv4U24j1rHn+\\\\\\\\HlERISrj2f8mw0AgCl2H\\\\\\\\aQ5ETGIBU0FmrK4XBUanMlC5fLlXWQubq6vn79WvlBJGvpYR7nzs5OSfMtLCyMw+EMHjxYyXw2b2\\\\\\\\v3NzcXqWgq6urHR0dDcgtoABMQasRzW3oWFhYXLlyRdWjyAh5Yd8VUhsTEhIqKytjYmJ27NixZs2aDaHxWpLR8NB\\\\\\\\sSRVwXzQIpEoLy9Pk+UCOp1eV1cn64NWtTWGlIKWrV2HVfPhcDhK2vtYPT\\\\\\\\lBTACMjIyVOpYRmTc3Nx6ScPpnuPWrVtbt24NCQlZuXKlJl3KjADDU9BYHPR\\\\\\\\\\\\\\\\vOfyZMna2Jz0en0mpoaWReHm5ubSgq6pqZG0sXR2toqJZW\\\\\\\\v\\\\\\\\+zZ884HI6SOggqaIMG9r7SnMGDB586daqpqens2bOKg26NHsNT0AAAFEWPHDmiYcwsg8Gora2VVdAsFgvrGKAk9fX1uAWNJapI1Qslk8nm5uZPnjxR0sfaC02w7OxsYnbHUANVF5khssyYMePbb7\\\\\\\\t379\\\\\\\\uz033+fRvqItb3j5epBDLG48lVy9OaHuu5\\\\\\\\kdXjpaQxSQZPJ5DFjxsjqVpXAFHS3qX0KwOLhJPvbSkY9SxIaGuru7q6kvU8ikVAUJVpV6J6Dw+E4OTkZTQNQU1NT2SZnAoGg90yo5qxZs+batWvFb4vQIe1jeFFLXFedrTyOAl1fwNa7WSSWuf3W5abB7zVduKnjs2MY5F0RGxu7fPlyDQdhMBhdujiA0kb0hx9++Mcff0hGcZiZmcm6OAAAU6dOlaqyphiseZLy+xsujx8\\\\\\\\\\\\\\\\vLLL7FW7kbMzp07e7oTjTHR0dHh6enZirbYUOzKiyvMyOYsCrtdpGsbVlBTx\\\\\\\\DyBAAwfDyF7zTtLqgehhfFAQBYvFgLVb3pdLo8Cxp7Su32obuysnLnzp0UCgVX0CQSicfjyXYb8Pb2VqloNRbIobMy+Xqhra0tISHh5s2bFy5ckJc6bKDY2NhI\\\\\\\\m0DAN6+fdvS0qJGLwiDo6qqCu+OpDZDhgzZsG79QHf3Cqsy8lDhzdrLJIRsQjbVlpBKYhbi33DyEnPcCN4fz8yGDwEAdIo728Q8NkV3\\\\\\\\TQM0oLWCgwGg8\\\\\\\\nd5nOoOQ6D4PBMDc3z8rKktQvkkHQamP064RlZWVjx461s7O7ffu2SkmbBoHs76eqqurx48f6kkc3CASC6OjoFStWjB07VtWuHVLsWLF6Npfi\\\\\\\\rJix\\\\\\\\MwC7KZNdXmM9c12pJTeWgeLtZLYsVt7eyp48xGDH7GffRN0ddn3h77rmSXGNVR+3aDtKC1AoPBkKdJlVHQWF3\\\\\\\\DRs2pKenS\\\\\\\\pPOzs7taKg09PTNRyEsOTl5c2fP\\\\\\\\\\\\\\\\YsWO+vr76lqVHwH4\\\\\\\\gYGB+BasoptQKNRxbRBdcvPmzcDAwI0bN\\\\\\\\L5\\\\\\\\MjISDUaL+BwU273\\\\\\\\zKO6uLQ9vSl1f0yiw9GaFFOlaA62lId\\\\\\\\6qsmVZ7ZZXHFhqJduXd2ZetzwcydRFe0qstaHnLjMooaKwMiK+v79WrVyW3m5mZaa6gvby8tOLGIRpCoXD\\\\\\\\\\\\\\\\v1xcXFnzpwxVu0M5Px+\\\\\\\\Pz8Xr58qRd5dAOKopilop2EI2wQBAFEWlz9SyiA6GzJ12j\\\\\\\\z7uFRqNprqABAMHBwZLbzc3NNSzJBgAgkUjECf9MTU1NSkoikUgikYhEIi1ZskRV46i2tvbq1avXrl2rra2dNm1aeno63iTXKHF1db116xb+FqudFBISkpWV9d577+lRsB4lIiLi+PHjs2bNKisrW7dunSZDsaeMqTt8hmpvI3xXZ7N6obzd0E4B\\\\\\\\+FzhEo1CRyI1fXvUcb1mby38Gsrah8BKoi0jenp02H0XgWtwILGCtopPlxeIT0mk6m5BU0oNOk5CQDgcDjr1q2bO3duYmJiL6lQIZXrhOWaBgcH79271ygfjDCoVOrly5ffvn1raWmJN6xQcyhne\\\\\\\\uty0WNXIoVG8iLvxSL38UfNg0ahLZ38n5\\\\\\\\bLNqgSZnVIYAdogP8z2+iGdJlY4C6Dl6r4vDxMREXhA0gkg\\\\\\\\wiQmJkrtU1ZW1rdvX9ljjU9Ba9Jz8v79+1999VVqaurixYt7iXYGALDZbMkwzaqqKgcHh3\\\\\\\\84x8q1XgxUJycnDTUzhgImUzpYylXOwMgqK6l2tuyJo5iTxuPdgrE7bpo10snMXSpnUFvVtB0Ol2qnYrUp3hrFYFAsHbtWqmGzSUlJV2WptOKi4NQJCUlZWVlrV69+osvvuBwOLI96xTQ0tJy6dIlVbukGwF0Oh2vylJdXW1vb48gCJPJfPbsmX4FMxrIbJbg7Tu0UyDmtYlaWkl03TU20yW918VBp9MVpBG6uLhUVFRgJeUKCgra2trevHkjua5VU1PTZasIc3NzI7OgHz169ODBA8wHnZWV5e\\\\\\\\vr7yLo8uWZr2BMWPG3L59e+rUqeC\\\\\\\\FjQAICkpac6cOZMmTRIKhY6OjrNnz9a3mHpAWFPfnJyGdnSyIkfTPFywjfmt2Rn1aSyKxSS7GBZFrtkkCcnMhDV59Lv4wwiJZDknGhhFKURZeq+CVuDiAP8tiIEp6Ly8PA8Pj9zcXEkFjSBIl6vVTCZTK494xKFbHzSXy42Pj8edQi9evJBaOO2FREREJCYm4goaWxt0dna+efPmiRMnnJychg4dqm8Z9UNd4mmrudMQE5O6xNN2X8WRGPT6ztpr787Pc1lW21l9quLQUrcNSg5lGjTQNMhISrjIo\\\\\\\\cqaGdnZz8\\\\\\\\P3mfSgZy5OXlTZs2TTJzpK2tDe+iIoWPj48yVfkNCMwHPXDgQARB8vLyZH3QTCZzxowZeK9lkUhkxCF0SjJw4MCcnBzsdVVVFf6XRqPRjHidsFvQTgFCp9E8+gIA6J59he\\\\\\\\qaK5Ob9vL\\\\\\\\JgB1jQba5pNyrtf9C0jsei9Ctrf39\\\\\\\\f31\\\\\\\\ep3379r1z5w72Ojc39\\\\\\\\PPPz9w4AD+qbwVQgDAzJkztSun3klKSvrhhx9OnjwpFAp9fHxkfdAIggQEBOBvHz58KO\\\\\\\\fq1fh4+Pz8uVLX1\\\\\\\\fqqoqe3t7fYtDCBAaFYhR\\\\\\\\qMXJFOTjsIyy9lRAAA3U8\\\\\\\\Umov9zXyqO95a6HYJjvj03kVCxUha0OXl5cHBwZLVizRsVmtY7N27d\\\\\\\\369QEBAfn5+Tdu3Lh+\\\\\\\\bq+JTIMIiIisIxnyXqHEJuV8wRlVW3P821WzEWoVAAAi2Ix2\\\\\\\\nTJ80PWkUtnzh\\\\\\\\pjtRULThxMXqTfurv07oLK7Q3XlVASrorsHryYnFYgqFgqVIiUR\\\\\\\\JeD3KgWdm5sLAEhNTX38+DGHw4FV2ZRk3LhxmIIWi8XGnZijEiRzU\\\\\\\\b09y1nTqbY\\\\\\\\F3BxonRd4bj3PdtougkjaosqURb9mtAItlvW2mzcn7jTyo369INUEF3DYVCwco9l5SUYN4MDw8PvI5+Wlpa71kHKy0tvXLlCovFam9vr62tNbIYlZ6DyWQ6OTm9fPnSOHotGh9iHh\\\\\\\\7kyCzzVGBCtH9ugQqaLlggWV5eXk+Pj4AAC8vr\\\\\\\\z8fABAXl4emUzu37+\\\\\\\\vgXUEcePH+\\\\\\\\o6BgyZEhDQ8Ply5dXrJBu8QmRx8KFC\\\\\\\\ft26dJUwgIKhC05xeKGv6nPruoqaU9vxDt6JR3lKiJK28HVCDsyC8SNTSZ+HvzM582nUut2XvMLGyI9kXXBr13kbBbHB0dq6qqcnNzsVLOPj4+ubm5kyZN2rZt25o1eih+qC8CAwPxwmyLFi3SrzCGRVhY2NKlS0NCQvQtiKEibuW\\\\\\\\23mE4dOvubDcfOxws2EBAID27FdNF27SvTwaT122WbWAYi2dBtX2Z25zyi36APfGU5dt1y4iW\\\\\\\\xd0UHM49fEJ9F9PDuLys1HD7PbvLTjVZFZaCBeso5oQAUtFzc3t127dj158uTkyZMAAG9v7\\\\\\\\j4+Pb2dj6fP2QIQf9vIYQCQZA5c+ZwuVx9C2Ko8B8+Z44Zbv7PoahA8G7HEUxBc1MzbFcvJDHN+ANyeJxH7KnjpI7i3siwXbuYZMLguz\\\\\\\\j\\\\\\\\f6EFfnPvwd8lG32zxDmmOGoQPhuxyGz4YMZA\\\\\\\\+h06+kIlBBy2XZsmXZ2dkxMTFYukq\\\\\\\\fv3i4+MFAkFvjmOFqMq\\\\\\\\\\\\\\\\vUvPOcboiqICUNYXQsAELfwSbS\\\\\\\\emuQTBmiJi6JaSZq4pJMulhUJJnQRc0tJBOGqIlLMmX870cMQUU1AEDcykO6atZBNKCCloudnZ1Us4\\\\\\\\w8HB9CQMxUExNTY0ss1SXmIW8V\\\\\\\\fdz9X\\\\\\\\PgBEIquFM7CNFjMm1h05A8QoydzMZvknskdZfBhZf\\\\\\\\gMAIDMZvZZNkfyI9OggXWPs6u\\\\\\\\TgAisdXCD3TwFTQEKmgIBEJUSKQ+y6QrllDs+th\\\\\\\\\\\\\\\\bmCg6iOtvZb5DSVJpH6xH2sLel0AIzigEAgEIICFTQEAoEQFD24OKytrTdv3rxnzx58S25urhrB\\\\\\\\AKBoMue3IZ+FIqiWOQ1Bo\\\\\\\\H27Jli6qD6BE4v4oxvvnFaWhoqKys1DxtUr0L2xODiESifv36MRjq5zdqOr8oARg1ahQ8SsOjiAzxrx7xjzIILl68mJCQoOEgdXV106dP11wYrVznuLi4nJwczcdRG+jigEAgEIICFTQEAoEQFKigIRAIhKCQ\\\\\\\\\\\\\\\\3vf+tbBtDa2qpGcTh4lKFA\\\\\\\\KtH\\\\\\\\KMMAqFQyGazNewoRCaTeTye5tUUtHKduVzuoEGD9JhqhKD\\\\\\\\bSUHgUAgEEIBXRwQCARCUKCChkAgEIICFTQEAoEQFKigIRAIhKBABQ2BQCAERQ9hdi0tLXPnzo2JicnJyZkzZ86ZM2cYDIa7u\\\\\\\\uSJUt++eWXzs5Oe3v72bNnnz17ls1ma9j6r8tzWVlZffrpp5cvX0ZRtE+fPlo5V1FRUUxMTFpaWmtrq5OTEz6mhYVFl6+NuKUhnF\\\\\\\\jnl9JHj16FBERkZqa+vz5c39\\\\\\\\fzUuBT6DtbW1mlxVfBy1RSLoFOs4tby8vDwmJub9999HUXTOnDnFxcVisXj8+PFHjx69cuUKiqL79++Pj4+\\\\\\\\ffu2UCicMmVKT5wrISEhJSVFJBKNHz9eW+f68ssv7969i6JoZGSk5JjyXmtyLiID59e451eKX375BfsjRFFUjUshOYOaXFXJcdQWiZhTrGsXh7Oz8\\\\\\\\nz501MTAAAPj4+jx8\\\\\\\\fvXq1ePHjx89elRZWfnVV19FRkbm5+cPGjSITCaTSBqJJ+9cU6ZM2bp166RJk6KiorR1rg0bNoSHh1dWVqIoKjmmvNeanIvIwPk17vmVoqio6Keffho\\\\\\\\fvyBAwfUuBSSM6jJVZUcR22RiDnF+vwlLV26tKqq6pdffgkKCmptbW1vb1+wYMGKFStQFMWqU4pEop4416lTp5YtW5aYmHjp0iVtncvc3PzixYuLFy8+cuSI5JjyXmvjOxEdOL9Gz5w5c06fPp2Wlnbq1CmhUKjJpdDWVVVbJGJOsT4VNIfDmTBhwrp169hstoeHx\\\\\\\\Dhw93c3FpaWvr375+Xl4eiqBb\\\\\\\\piTPlZeXN3LkSE9Pz\\\\\\\\b29n79+mnlXKmpqffv309JSXF2dvby8sLHlPdaW9+LyMD5NXquX7+OtcQ1MTHx9vbW5FJo66qqLRIxp1g\\\\\\\\qd7R0dHJycllZWWrVq0ikUhr1661t7dfsmQJjUYbNWpUbGzs8uXLqVTqhx9+OHHiRK2fC0GQAwcOkEikoKCgmJgYrZxr4cKFFRUV2EPW999\\\\\\\\j48ZFBTU5WvNvxeRgfNr3POLk5WVlZCQwOPxoqKiJk+erN6lwGawtrZWw6uKjaO2SMScYliLAwKBQAhKb3kWg0AgEIMDKmgIBAIhKFBBQyAQCEGBChoCgUAIClTQEAgEQlCggoZAIBCCAhU0BAKBEBSooCEQCISgQAUNgUAgBAUqaAgEAiEoUEFDIBAIQYEKGgKBQAhKL1XQixcvvnHjBgCAz+eHhITweDwFO\\\\\\\\P5fF3JBdEOcH6Nj6SkpNDQUOx1Xl4egiC9oe42Rd8C6IedO3dOmTJl7Nixe\\\\\\\\fuXbVqVWNjY0xMDJ1O\\\\\\\\+CDD0aNGrVy5UoymRwVFfX27dvMzMxRo0Z9\\\\\\\\vnn+hYZogJwfo2S5ubmyspKR0fHixcv+vr6AgCKiormzZtHIpE+++yzwMBA\\\\\\\\LWLi0tiYmJ7e\\\\\\\\v+\\\\\\\\ftJJNKiRYuw2Z81a5a+v4Rq9N5yoz\\\\\\\\++GNubm5+fv7Vq1fXrFkTGxs7ePDgMWPG7Nmzh81mu7i4zJgxIywsjE6nL126VN\\\\\\\\CQlQGzq+RkZSUVFlZaWtrGxcX9\\\\\\\\HHH3d0dJw9e3blypWzZ88eMmRIeHh4QEAA\\\\\\\\jokJGTmzJlWVlYdHR3Hjh3DZ\\\\\\\\\\\\\\\\27dv6\\\\\\\\h6q0UstaADA3Llzg4KCjh07BgAoLy8\\\\\\\\ceLEf\\\\\\\\7zn8GDB9NotHXr1pmamorFYgBAYGCgviWFqAOcX+Nj6NChZ86cmThxooeHR15eHgCgvLx80KBBJBKJxWKVlpbirxcuXLh69WoKhbJv3z7J2RcKhRSKISm9XuqDBgAgCOLu7u7u7g4A8PDwiImJ2bNnj6ur64EDB3bt2vXtt99iNzCVStW3pBB1gPNrfJBIJBsbmyNHjkyfPh3b4uTklJOTg6JoU1OTi4sL\\\\\\\\vrFixfnz59ft27d0aNHJWffsLQz6M0WtCRxcXFz5851cXGJiIiIjIzctm2bqalpZ2dnSUmJvkWDaAE4v0ZDdHT0okWLdu3ahb1dsWLFggULqFTqsmXLAgMD8dfm5uYLFy4kk8nLly+3t7fHZ1+\\\\\\\\wqtB7\\\\\\\\VBQyAQCMHpvS4OCAQCIThQQUMgEAhBgQoaAoFACApU0BAIBEJQoIKGQCAQggIVNAQCgRAUqKAhEAiEoEAFDYFAIAQFKmgIBAIhKFBBQyAQCEGBChoCgUAIyv8DnklWHVk++PUAAAAASUVORK5CYII=', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\")\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose, dat$Wolf)\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\nplot(dat$Wolf ~ dat$Year, type = \"l\")\\nplot(dat$Moose ~ dat$Year,  type = \"l\")\\nplot( Wolf~Moose, data=dat, col=rep( c(1,2,3), times=c(22,16,15)))\\nlegend(\"topright\", col=c(1,2,3), \\n       legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"),\\n       bty=\"n\",\\n       pch=\"o\")\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Let $X_{1}, \\\\dots, X_{n}$ be independent and identically distributed (iid) exponential random variables with parameter $\\\\lambda > 0$, i.e. $X_{1}, \\\\dots, X_{n} \\\\underset{iid}{\\\\sim} Exp(\\\\lambda)$. Assume $\\\\lambda = 2$ for the following. \\\\\\nSample $n = 100$ random numbers from $Exp(\\\\lambda)$. Visualize the data with a histogram and superimpose the theoretical density. You have to get one plot at the end.\\n\\n**Do not change the name of the function**\\n', 'answer': 'png(file=\"solution.png\")\\nset.seed(12)\\nn <- 100\\n\\n# Sample the data\\nhist( rexp(n, rate = 2) , probability = TRUE, main = \"\") # Histogram of the sampled data with a superimposed theoretical density. \\n\\n# Using curve() function plot the theroretical function. For more info: ?curve()\\ncurve(dexp(x, rate = 2), add = TRUE)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(12)\\nn <- 100\\n\\nartificial <- rexp(n, rate = 2)\\nhist(artificial, probability = TRUE, main = \"\")\\ncurve(dexp(x, rate = 2), col = \"red\", add = TRUE) # theoretical density\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'On www.isleroyalewolf.org/data/data/home.html the file isleroyale graph data 28Dec2011.xlsx contains population data from wolves and moose. The information in this file is extracted and saved in the file 01wolvesmoose.csv.Download and read the file 01wolvesmoose.csv from the STA120 course page.\\n\\nCreate a boxplot containing both, Moose and Wolf data. \\nCreate a QQ-plot for Moose and a QQ-plot for Wolf.\\nCreate a plot of Wolf on Year and of Moose on Year.\\nCreate a plot of Wolf on Moose, with colors 1:3.\\nYou should get 6 plots. Use par( mfrow=c(2,3)) to plot them in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': '# Open a PNG file for plotting\\npng(file=\"solution.png\")\\n\\n# Read the data\\ndat <- read.csv(\"resource/wolvesmoose.csv\", header=TRUE)\\n\\n# Set up a 2x3 grid of plots\\npar(mfrow = c(2,3))\\n\\n# Boxplot\\nboxplot(dat$Moose , dat$Wolf)\\n\\n# QQ-plots for Moose and Wolves\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\n\\n# Line Plot for Wolf\\nplot(dat$Year, dat$Wolf, type = \"l\")\\n\\n# Line Plot for Moose\\nplot(dat$Year, dat$Moose, type = \"l\")\\n\\n# Scatter Plot with legend\\nplot(Wolf ~ Moose, data=dat, col=rep(c(1,2,3), times=c(sum(dat$Year <= 1980), sum(dat$Year >= 1981 & dat$Year <= 1996), sum(dat$Year >= 1997))))\\nlegend(\"topright\", col=c(1,2,3), \\n    legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"), \\n    bty=\"n\", \\n    pch=\"o\")\\n\\n# Save the plots and close the PNG file\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\")\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose, dat$Wolf)\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\nplot(dat$Wolf ~ dat$Year, type = \"l\")\\nplot(dat$Moose ~ dat$Year,  type = \"l\")\\nplot( Wolf~Moose, data=dat, col=rep( c(1,2,3), times=c(22,16,15)))\\nlegend(\"topright\", col=c(1,2,3), \\n       legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"),\\n       bty=\"n\",\\n       pch=\"o\")\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Use the the R help function to find out the purpose of the function demo() and have a look at the list of available demos. The demo of the function persp() utilizes the volcano data to illustrate basic three-dimensional plotting. Call the demo and have a look at the plots. Do that in your own environment and afterwards just press \"Submit\".', 'answer': '# Student solution.\\r\\ndemo(persp)', 'rubrics': [], 'modelSolution': 'demo(persp) \\n\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'As in last exercise, the distribution is:\\n$$\\nf(\\\\kappa \\\\mid \\\\alpha,\\\\beta) =\\n    \\\\begin{cases}\\n        \\\\frac{\\\\beta^{\\\\alpha}}{\\\\Gamma(\\\\alpha)} \\\\kappa^{\\\\alpha-1} \\\\exp(-\\\\beta \\\\kappa), & \\\\text{if $\\\\kappa > 0$},\\\\\\\\\\n      0, & \\\\text{otherwise},\\n\\\\end{cases}\\n$$\\nIn the previous task you have seen how the {hyper-parameters} $\\\\alpha > 0$, $\\\\beta > 0$ affect the shape of the function.\\nWrite a few words about how you thinkt the gamma distribution is related to the exponential distribution.  \\n\\n*Note: You can enter your text inside the \"...\" part. Access will say there is a point, but we will look at the text separately.*', 'answer': 'text_response <- \"When alpha is set to 1, the Gamma distribution is reduced to the exponential distribution.\\nThe gamma distribution is more flexible than the exponential distribution and can model the sum of multiple exponential random variables, therefore it generalizes the exponential distribution.\"\\n\\nsol <- list(text_response = text_response)\\n', 'rubrics': [], 'modelSolution': 'text_response <- \"If we choose alpha=1, the kappa term before the exp() disappears, as does the fraction of beta and the gamma function. Therefore the exponential distribution is a special case of the gamma distribution.\"\\n\\nsol <- list(text_response = text_response)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true*x + rnorm(length(x), mean=0, sd=2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)    \\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean)*(y-y.mean)) / (sum((x-x.mean)^2))\\nbeta0.hat <- y.mean - beta1.hat*x.mean\\ny.fitted <- beta0.hat + beta1.hat*x \\nresiduals <- y - y.fitted\\nSS <- sum( residuals^2 )\\n\\nn <- length(x)\\nsigma.e <- sqrt(SS / n-2)\\nbeta0.se <- sigma.e * sqrt(1 / n + x.mean^2 / sum((x - x.mean)^2))\\nbeta1.se <- sigma.e / sqrt(sum((x - x.mean)^2))\\n\\nalpha <- 0.05\\ncritical_t <- qt(0.975, df = n-2)\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * critical_t * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * critical_t * beta1.se\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt(abs(t0), df = n-2 , lower.tail = FALSE ) \\np.value1 <- 2 * pt(abs(t1), df = n-2 , lower.tail = FALSE )\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For each of the three district sizes, fit a simple linear model using salary as the response variable and experience as the predictor.   \\nIs there an effect of experience? How can we compare the results?\\n', 'answer': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\nfit1 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize == 1)\\nsummary(fit1)\\nfit2 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize == 2)\\nsummary(fit2)\\nfit3 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize == 3)\\nsummary(fit3)\\nplot(mydata$experience, mydata$salary, xlab = \"Experience\", ylab = \"Salary\", \\n     col = c(\"black\", \"red\", \"green\")[mydata$districtSize], main = \"Salary against experience\")\\n\\t \\nlegend(\"bottomright\", legend = c(\"districtSize 1\", \"districtSize 2\", \"districtSize 3\"), pch = 1, \\n\\t   col = c(\"black\", \"red\", \"green\"), bty = \"n\")\\nabline(fit1, col = \"black\")\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\nmydata <- read.table(\"resource/10salary.txt\", header = TRUE, sep = \",\")\\n\\nfit1 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==1)\\nsummary(fit1)\\nfit2 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==2)\\nsummary(fit2)\\nfit3 <- lm(salary ~ experience, data = mydata, subset = mydata$districtSize==3)\\nsummary(fit3)\\nplot(mydata$experience, mydata$salary, xlab = \"Experience\", ylab = \"Salary\", \\n     col = mydata$districtSize, main = \"Salary against experience\")\\nlegend(\"bottomright\", legend = c(\"districtSize 1\", \"districtSize 2\", \\n                                 \"districtSize 3\"), pch = 1, \\n       col = c(\"black\", \"red\", \"green\"), bty = \"n\")\\nabline(fit1, col = \"black\")\\nabline(fit2, col = \"red\")\\nabline(fit3, col = \"green\")\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Use ```predict()``` to add a ```confidence``` and a ```prediction``` interval to the scatterplot. What is the difference? \\nHint: The meanings of ```confidence``` and ```prediction``` here are based on the **R** function ```predict()```. \\nUse the help of this function to understand their behavior.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  # use the following code as a base:\\n  set.seed(5)         ## for reproducible simulations \\n  beta0.true <- 1     ## true parameters, intercept\\n  beta1.true <- 2     ## and slope\\n  ## observed x values:\\n  x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n         8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n  ## simulation of y values:\\n  y <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n  \\n  data <- data.frame(x = x, y = y)   \\n  \\n  \\n  # start here to calculate your solution for the problem:\\n  x.mean <- mean(x)\\n  y.mean <- mean(y)\\n  beta1.hat <- sum((x - x.mean) * (y - y.mean))/sum((x - x.mean)^2)\\n  beta0.hat <- y.mean - beta1.hat * x.mean\\n  y.fitted <- beta0.hat + beta1.hat * x\\n  mod <- fitted(mod)\\n  \\n  xx <- seq(0, 10, by = 0.01) # Sequence from 0 to 10 with 0.01 step.\\n  p.confidence <- predict( mod , newdata = data.frame(x = xx) , interval = \" confidence \")\\n  p.prediction <- predict( mod , newdata = data.frame(x = xx) , interval = \" prediction\")\\n  \\n  plot(x, y)\\n  abline(a = beta0.hat , b = beta1.hat , col = \"red\")\\n  points(x , y.fitted , col = \"red\", pch = 2) # Add fitted points\\n  lines(xx, p.confidence[, 2] , col = \"blue\", lty = 2) # Add upper CI\\n  lines(xx, p.confidence[, 3] , col = \"blue\", lty = 2) # Add lower CI\\n  lines(xx, p.prediction[,2], col = \"green\", lty = 3) # Add upper Prediction\\n  lines(xx, p.prediction[,3], col = \"green\", lty = 3) # Add lower Prediction\\n  \\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\n# use the following code as a base:\\n set.seed(5)         ## for reproducible simulations \\n beta0.true <- 1     ## true parameters, intercept\\n beta1.true <- 2     ## and slope\\n ## observed x values:\\n x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n        8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n ## simulation of y values:\\n y <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n \\n data <- data.frame(x = x, y = y)   \\n \\n \\n # start here to calculate your solution for the problem:\\n x.mean <- mean(x)\\n y.mean <- mean(y)\\n beta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\n beta0.hat <- y.mean - beta1.hat * x.mean\\n y.fitted <- beta0.hat + beta1.hat * x\\n mod <- lm(y ~ x, data = data)\\n \\n xx <- seq(0, 10, by = 0.01)\\n p.confidence <- predict(mod, newdata = data.frame(x = xx), interval = \"confidence\")\\n p.prediction <- predict(mod, newdata = data.frame(x = xx), interval = \"prediction\")\\n \\n plot(x, y)\\n abline(a = beta0.hat, b = beta1.hat, col = \"red\")\\n points(x, y.fitted, col = \"red\", pch = 2)\\n lines(xx, p.confidence[,2], col = \"blue\", lty = 2)\\n lines(xx, p.confidence[,3], col = \"blue\", lty = 2)\\n lines(xx, p.prediction[,2], col = \"green\", lty = 3)\\n lines(xx, p.prediction[,3], col = \"green\", lty = 3)\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Calculate the fitted values $\\\\widehat{y_i}$ for the data in ```x```.\\nCreate a scatterplot of the data, and overlay these fitted values.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  # use the following code as a base:\\n  set.seed(5)         ## for reproducible simulations \\n  beta0.true <-1    ## true parameters, intercept\\n  beta1.true <-2    ## and slope\\n  ## observed x values:\\n  x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n        8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n  e_values <- rnorm(15, mean = 0, sd = 2)\\n\\n  ## simulation of y values:\\n  y <- beta0.true + (beta1.true*x) + e_values\\n\\n  pearson_cor <- cor(x, y, method = c(\"pearson\"))\\n  spearman_cor <-cor(x, y, method = c(\"spearman\"))\\n\\n\\n  x.mean <-mean(x)\\n  y.mean <- mean (y)\\n\\n  # Use formulas from the script\\n  sum_xy <- sum((x - x.mean) * (y - y.mean))\\n  sq_x <- sum((x - x.mean)^2)\\n  beta1.hat <- sum_xy/sq_x\\n  beta0.hat <- y.mean - beta1.hat* x.mean\\n\\n  y.fitted <- beta0.hat + beta1.hat*x # Make sure you choose right formula\\n  plot(x, y)\\n  # Abline your straight line with b_0 and b_1\\n  abline ( a = beta0.true, b = beta1.true , col = \"red\") \\n  # Add fitted points\\n  abline ( a=beta0.hat, b=beta1.hat, col = \"red\", pch = 2)\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(5)         ## for reproducible simulations \\n beta0.true <- 1     ## true parameters, intercept\\n beta1.true <- 2     ## and slope\\n ## observed x values:\\n x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n        8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n ## simulation of y values:\\n y <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n \\n # start here to calculate your solution for the problem:\\n x.mean <- mean(x)\\n y.mean <- mean(y)\\n beta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\n beta0.hat <- y.mean - beta1.hat * x.mean\\n \\n y.fitted <- beta0.hat + beta1.hat * x\\n plot(x, y)\\n abline(a = beta0.hat, b = beta1.hat, col = \"red\")\\n points(x, y.fitted, col = \"red\", pch = 2)\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(length(x), mean=0, sd = 2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean)) / sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x # Make sure you choose right formula\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- length(y)\\nsigma.e <- sqrt( SS / (n-2) ) \\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2/sum((x-x.mean)^2))\\nbeta1.se <- sigma.e/sqrt(sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt( 0.975, df = n-2 ) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt( 0.975, df = n-2 ) * beta1.se\\n\\nt0 <- beta0.hat/beta0.se\\nt1 <- beta1.hat/beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt (abs( t0 ), df = n-2 , lower.tail = FALSE ) \\np.value1 <- 2 * pt (abs( t1 ), df = n-2 , lower.tail = FALSE )\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this problem we investigate the effect of deviations of statistical assumptions on the $p$-value. For simplicity, we use the one-sample $t$-test.   \\nFor 10'000 times, sample $X_{1}, \\\\dots, X_{10} ~ \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$ with $\\\\mu = 0$ and $\\\\sigma^{2} = 1$.  \\nFor each sample perform a $t$-test for $H_{0}: \\\\mu = 0$ and store the $p$-value thereof. \\nPlot the 10'000 $p$-values in a histogram. What do you observe?    \\nFor $\\\\alpha = 0.05$, what is the observed Type I error of the sampled data in (a)?   \\nHint: The Type I error is the probability of rejecting the null hypothesis even though it is true (here, $\\\\alpha = 0.05$).    \\nIn this setting we know that the null hypothesis $H_{0}: \\\\mu = 0$ is true because we sample from a $\\\\mathcal{N}(0, 1)$ distribution.     \\nThe observed Type I error is then the proportion of the number of rejected null hypotheses.  \\n\", 'answer': 'set.seed(5)\\n\\npvals = c()\\n\\nfor (i in 1:1000) {\\n    ttest = t.test(rnorm(10, mean = 0, sd = 1), conf.level = 0.95)\\n    pvals = c(pvals, ttest$p.value)\\n}\\n\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\n\\nerr = sum(pvals < 0.05) / 1000\\n\\nsol <- list(type_I_error = err)\\n\\nprint(sol)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\nsamples <- matrix(rnorm(n*R), R, n) # R rows, n columns\\ngetPvalue <- function(x){\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\npvals <- apply(samples, 1, getPvalue) # apply one t-test for each row of \\'samples\\'\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\nerr <- 1/R * sum(pvals < 0.05)\\nsol <- list(type_I_error = err)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Fit a one-way ANOVA with log(OC) as response variable and Behandlung as explanatory variable. \\nHint: Use ```lm()``` and perform an ```anova()``` on the output. \\nDo not forget to check the model assumptions.\\n', 'answer': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nfit1lm <- lm(logOC ~ Behandlung, data = chem)\\nfit1lm_anova <- anova(fit1lm)\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot(fit1lm)\\nsol <- list(owANOVA = fit1lm_anova)', 'rubrics': [], 'modelSolution': 'chem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nfit1lm <- lm(logOC ~ Behandlung, data = chem)\\nfit1lm_anova <- anova(fit1lm)\\n# Check whether there are indications that the assumptions of a one-way ANOVA are violated.\\npar(mfrow = c(2, 2))\\nplot(fit1lm)\\nsol <- list(owANOVA = fit1lm_anova)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2) \\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean))/sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n  \\ny.fitted <- beta0.hat + beta1.hat * x # Make sure you choose right formula\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS/(n - 2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2/sum((x - x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1/sum((x - x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n - 2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n - 2) * beta1.se\\n\\nt0 <- beta0.hat/beta0.se\\nt1 <- beta1.hat/beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt(abs(t0), df = n - 2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n - 2, lower.tail = FALSE)\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We repeat the experiment with a different distribution. Same questions as in (a), but for     \\n- $X_{1}, \\\\dots, X_{10}$ from a $t$-distribution with 4 degrees of freedom and  $H_{0}: \\\\mu = 0$;     \\n- $X_{1}, \\\\dots, X_{10}$ from a chi-square distribution with 10 degrees of freedom and  $H_{0}: \\\\mu = 10$.     \\nAgain, plot the histograms of the $p$-values. What do you observe compared to (a)? What changes with the observed Type~I error?   \\n', 'answer': 'set.seed(5)\\nR <- 10000\\nn <- 10\\n\\nsamples_t <- matrix(rt(n * R, df = 4), R, n)\\npvals_t <- apply(samples_t, 1, function(x) {\\nt.test(x)$p.value\\n})\\n\\ntypeI_t <- (typeI_t <- 1/R * sum(pvals_t < 0.05))\\n\\nsamples_chi2 <- matrix(rchisq(n * R, df = 10), R, n)\\npvals_chi2 <- apply(samples_chi2, 1, function(x) {\\nt.test(x, mu = 10)$p.value\\n})\\n\\ntypeI_chi2 <- (typeI_chi2 <- 1/R * sum(pvals_chi2 < 0.05))\\n\\npar(mfrow = c(1, 2))\\nhist(pvals_t, main = \"t-distribution\", xlab = \"p-values\")\\nhist(pvals_chi2, main = \"chi-square distribution\", xlab = \"p-values\")\\nsol <- list(typeI_t = typeI_t, typeI_chi2=typeI_chi2)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\n# t-distribution\\n\\nsamples_t <- matrix(rt(n*R, df = 4), R, n) # samples from t-distribution\\npvals_t <- apply(samples_t, 1, function(x){t.test(x)$p.value})\\n(typeI_t <- 1/R * sum(pvals_t < 0.05)) # observed Type I error\\n\\n#chi-squared distribution\\nsamples_chi2 <- matrix(rchisq(n*R, df = 10), R, n) # samples from chi-square distribution\\npvals_chi2 <- apply(samples_chi2, 1, function(x){t.test(x, mu = 10)$p.value})\\n(typeI_chi2 <- 1/R * sum(pvals_chi2 < 0.05)) # observed Type I error\\n\\npar(mfrow = c(1, 2))\\nhist(pvals_t, main = \"t-distribution\", xlab = \"p-values\")\\nhist(pvals_chi2, main = \"chi-square distribution\", xlab = \"p-values\")\\n\\n\\nsol <- list(typeI_t = typeI_t, typeI_chi2=typeI_chi2)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We consider the data ```11chemosphere_OC.csv``` available on the course page. \\nThe data describes the octocrylene (OC) concentration sampled from 12 wastewater treatment plants in Switzerland.\\n Further variables in the dataset are: Behandlung (treatment of the wastewater), Monat (month when the sample was collected), Einwohner (number of inhabitant connected to the plant), \\n Produktion (sludge production (metric tons of dry matter per year), everything that doesn't enter the water system after treatment).\\n\\nOctocrylene is an organic UV filter and is used in sunscreens and as additive in cosmetics for daily usage.\\nThe substance is classified as irritant and dangerous for the environment (EU classification of dangerous substances).\\n\\nDescribe the data. Do a visual inspection to check for differences between the treatment types and between the months of data acquirement. \\nUse an appropriate plot function to do so. Describe your results. \\nHint: Also try the function ```table()```.\\n\", 'answer': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"UZH/24FS/Statistik/DatasetsStatistik/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log10(chem$OC)\\nhead(chem$logOC)\\nstr( chem )\\ntable( chem [, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot( logOC ~ Behandlung , data = chem) #behandlung\\nboxplot( logOC ~ Monat , data = chem) #monat\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\n\\nchem$logOC <- log(chem$OC)\\nhead(chem)\\nstr(chem)\\ntable(chem[, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot(logOC ~ Behandlung, data = chem)\\nboxplot(logOC ~ Monat, data = chem)\\n\\ndev.off()\\t', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The ```data 10stackloss.txt``` is available on the course page. \\nIt represents the production of nitric acid in the process of oxidizing ammonia. \\nThe response variable, stack loss, is the percentage of the ingoing ammonia that escapes unabsorbed. \\nKey process variables are the airflow, the cooling water temperature (in degrees C), and the acid concentration (in percent).\\n\\nConstruct a regression model that relates the three predictors to the \\nresponse, stack loss. Check the adequacy of the model.\\n\\nHints:  \\n- Look at the data outliers\\n- Try to find an *\"optimal\"* model. Exclude predictors that do not improve the model fit. \\n- Use model diagnostics, use $t$-, $F$-tests and (adjusted) $R^2$ values to compare different models.\\n- Which data points have a (too) strong influence on the model fit?  (```influence.measures()```)\\n- Are the predictors correlated? In case of a high correlation, what are possible implications?\\n', 'answer': 'mydata <- read.table(\"resource/stackloss.txt\", header = TRUE, sep = \",\")\\nstr( mydata )\\n\\npar(mfrow = c(1, 4))\\nboxplot( mydata$Air , xlab = \"Airflow\")\\nboxplot( mydata$Temp , xlab = \"Temp\")\\nboxplot( mydata$Acid. , xlab = \"Acid.\")\\nboxplot( mydata$Stkloss , xlab = \"Stackloss\")\\n\\n# Be aware that you don\\'t see how many outliers there are if they have the exact same value. \\n# Boxplots give you an idea about the value range of outliers. \\n# You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs( mydata , gap = 0, col = c(...>70)+1)\\n\\nfit_full <- lm(mydata$Stkloss ~ mydata$Air + mydata$Temp + mydata$Acid.)\\nsummary( fit_full )\\npar(mfrow = c(2, 2))\\nplot( fit_full )\\n\\n### Multicollinearity\\nprint( cor( mydata[c(\"Air\", \"Temp\", \"Acid.\")] ))\\n\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif( fit_full )\\n\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep( fit_full )\\n\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, \\n#i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures(fit_full )\\n\\n#Let us consider a smaller (nested) model, without the non-significant predictor:\\nfit_nested <-lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\n\\n#Below, fill out whether multicollinearity exists (Yes or No), which predictor can be removed (capital first letter), and the optimal model formula (lm(...))\\nsol <- list(Multicollinearity_exists = \" No \", predictor_that_can_be_removed = \" Acid \", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata) )\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.table(\"resource/stackloss.txt\", header = TRUE, sep = \",\")\\nstr(mydata)\\npar(mfrow = c(1, 4))\\nboxplot(mydata$Air, xlab = \"Airflow\")\\nboxplot(mydata$Temp, xlab = \"Temp\")\\nboxplot(mydata$Acid., xlab = \"Acid.\")\\nboxplot(mydata$Stkloss, xlab = \"Stackloss\")\\n#Be aware that you don\\'t see how many outliers there are if they have the exact same value. Boxplots give you an idea about the value range of outliers. You can make them visible with pairs plots (for instance outliers from the variable Air in red).\\npairs(mydata, gap = 0, col = c(mydata$Air>70)+1)\\nfit_full <- lm(Stkloss ~ ., data = mydata)\\nsummary(fit_full)\\npar(mfrow = c(2, 2))\\nplot(fit_full)\\n### Multicollinearity\\nprint(cor(mydata[c(\"Air\", \"Temp\", \"Acid.\")]))\\n# Looking at correlations alone is NOT sufficient to detecting multicollinearity\\nlibrary(car)\\nvif(fit_full)\\n#Looking at step() we see that which predictor we can remove from our model.\\nstep(fit_full)\\n#To investigate the effect of leaving out one observations, we use so-called leave-out-one diagnostics, i.e. what would happen to our estimates if we deleted exactly one row from our dataset?\\ninfluence.measures(fit_full)\\n#Let us consider a smaller (nested) model, without the non-significant predictor. We have:\\nfit_nested <- lm(Stkloss ~ Air + Temp, data = mydata)\\nsummary(fit_nested)\\nsol <- list(Multicollinearity_exists = \"No\", predictor_that_can_be_removed = \"Acid\", optimal_model = lm(Stkloss ~ Air + Temp, data = mydata))\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Fit a linear model without intercept (i.e. force $\\\\beta_0$ to be zero).\\nAdd the corresponding regression line to the scatterplot.\\nDiscuss if the model fits the data *better*.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  # use the following code as a base:\\n  set.seed(5)         ## for reproducible simulations \\n  beta0.true <- 1     ## true parameters, intercept\\n  beta1.true <- 2     ## and slope\\n  ## observed x values:\\n  x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n         8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n  ## simulation of y values:\\n  y <- beta0.true + beta1.true * x + rnorm(15, mean = 0, sd = 2)\\n  \\n  data <- data.frame(x = x, y = y)   \\n  \\n  \\n  # start here to calculate your solution for the problem:\\n  mod <- lm(y ~ x, data = data) # Basic LM\\n  mod2 <- lm(y ~ 0 + x) # b_0 = 0 LM\\n  par(mfrow = c(1, 1))\\n  plot(data)\\n  abline(mod , col = \"red\") # fit with intercept\\n  abline(mod2 , lty = 2) # fit without intercept\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(5)         ## for reproducible simulations \\n beta0.true <- 1     ## true parameters, intercept\\n beta1.true <- 2     ## and slope\\n ## observed x values:\\n x <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n        8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n ## simulation of y values:\\n y <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n \\n data <- data.frame(x = x, y = y)   \\n \\n \\n # start here to calculate your solution for the problem:\\n mod <- lm(y ~ x, data = data)\\n mod2 <- lm(y ~ 0 + x, data = data)\\n par(mfrow = c(1, 1))\\n plot(data)\\n abline(a = coef(mod)[1], b = coef(mod)[2], col = \"red\") # fit with intercept\\n abline(a = 0, b = coef(mod2)[1], lty = 2) # fit without intercept\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We repeat the experiment with a different distribution. Same questions as in (a), but for     \\n- $X_{1}, \\\\dots, X_{10}$ from a $t$-distribution with 4 degrees of freedom and  $H_{0}: \\\\mu = 0$;     \\n- $X_{1}, \\\\dots, X_{10}$ from a chi-square distribution with 10 degrees of freedom and  $H_{0}: \\\\mu = 10$.     \\nAgain, plot the histograms of the $p$-values. What do you observe compared to (a)? What changes with the observed Type~I error?   \\n', 'answer': 'set.seed(5)\\nn <- 10\\nrepetitions <- 10000\\n# t-distribution\\nsample_t <- matrix(rt(n*repetitions, df = 4), nrow = n, ncol = repetitions)\\npvals_t <- numeric(repetitions)\\nfor (j in 1:repetitions){\\n  pvals_t[j] <- t.test(sample_t[,j])$p.value\\n}\\n\\ntypeI_t <- length(which(pvals_t < 0.05)) / length(pvals_t)\\n\\n#chi-squared distribution\\nsample_chi2 <- matrix(rchisq(10*10000, df = 10), nrow = 10, ncol = 10000)\\npvals_chi2 <- numeric(10000)\\nfor (j in 1:10000){\\n  pvals_chi2[j] <- t.test(sample_chi2[,j])$p.value\\n}\\ntypeI_chi2 <- length(which(pvals_chi2 < 0.05)) / length(pvals_chi2)\\n\\npar(mfrow = c(1, 2))\\nhist(pvals_t, main = \"t-distribution\", xlab = \"p-values\")\\nhist(pvals_chi2, main = \"chi-square distribution\", xlab = \"p-values\")\\n\\n\\nsol <- list(typeI_t = typeI_t, typeI_chi2=typeI_chi2)\\n', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\n# t-distribution\\n\\nsamples_t <- matrix(rt(n*R, df = 4), R, n) # samples from t-distribution\\npvals_t <- apply(samples_t, 1, function(x){t.test(x)$p.value})\\n(typeI_t <- 1/R * sum(pvals_t < 0.05)) # observed Type I error\\n\\n#chi-squared distribution\\nsamples_chi2 <- matrix(rchisq(n*R, df = 10), R, n) # samples from chi-square distribution\\npvals_chi2 <- apply(samples_chi2, 1, function(x){t.test(x, mu = 10)$p.value})\\n(typeI_chi2 <- 1/R * sum(pvals_chi2 < 0.05)) # observed Type I error\\n\\npar(mfrow = c(1, 2))\\nhist(pvals_t, main = \"t-distribution\", xlab = \"p-values\")\\nhist(pvals_chi2, main = \"chi-square distribution\", xlab = \"p-values\")\\n\\n\\nsol <- list(typeI_t = typeI_t, typeI_chi2=typeI_chi2)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We consider the data ```11chemosphere_OC.csv``` available on the course page. \\nThe data describes the octocrylene (OC) concentration sampled from 12 wastewater treatment plants in Switzerland.\\n Further variables in the dataset are: Behandlung (treatment of the wastewater), Monat (month when the sample was collected), Einwohner (number of inhabitant connected to the plant), \\n Produktion (sludge production (metric tons of dry matter per year), everything that doesn't enter the water system after treatment).\\n\\nOctocrylene is an organic UV filter and is used in sunscreens and as additive in cosmetics for daily usage.\\nThe substance is classified as irritant and dangerous for the environment (EU classification of dangerous substances).\\n\\nDescribe the data. Do a visual inspection to check for differences between the treatment types and between the months of data acquirement. \\nUse an appropriate plot function to do so. Describe your results. \\nHint: Also try the function ```table()```.\\n\", 'answer': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nhead(chem$logOC)\\nstr( chem )\\ntable( chem [, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot( logOC ~ Behandlung , data = chem) #behandlung\\nboxplot( logOC ~ Monat , data = chem) #monat\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\n\\nchem$logOC <- log(chem$OC)\\nhead(chem)\\nstr(chem)\\ntable(chem[, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot(logOC ~ Behandlung, data = chem)\\nboxplot(logOC ~ Monat, data = chem)\\n\\ndev.off()\\t', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In a simple linear regression, the data are assumed to follow $Y_i = \\\\beta_0 + \\\\beta_1 x_i  + \\\\varepsilon_i$ with $\\\\varepsilon_i \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(0, \\\\sigma^2)$, $i = 1, \\\\dots, n$. \\nWe simulate $n = 15$ data points from that model with $\\\\beta_0 = 1$, $\\\\beta_1 = 2$, $\\\\sigma = 2$ and the following values for $x_i$.\\n\\nPlot the simulated data in a scatter plot in your Rstudio. Calculate the Pearson correlation coefficient and the Spearman's rank correlation coefficient. Why do they agree well? \\n\\nEstimate the linear regression coefficients $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ using the formulas from the script. \\n\\n*PS* -  The same code will repeat multiple time during this exercise. We recommend you to copy your final code and save it somewhere for the next exercise.\\n\", 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2    ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true+ beta1.true*x+rnorm(15,0,2)\\ndat <- data.frame(x = x, y = y)\\nplot(dat)\\n\\npearson_cor <- cor(x , y , method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\n# Use formulas from the script\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean))/sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor, \\n     Spearman_correlation_coefficients = spearman_cor,\\n\\t beta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'rubrics': [], 'modelSolution': 'set.seed(5)         \\nbeta0.true <- 1     \\nbeta1.true <- 2     \\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nplot(data)\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor,\\n            Spearman_correlation_coefficients = spearman_cor,\\n\\t\\t\\tbeta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Under the null hypothesis, we are allowed to permute the observations (all $y$-values) while keeping the group assignments fix. Keeping this in mind, we will now manually construct a permutation test to detect a potential shift. Write an R function ```perm_test()``` that implements a two-sample permutation test and returns the $p$-value. Your function should execute the following steps.\\n\\n1. Compute the test statistic $t_\\\\text{obs} = \\\\displaystyle \\\\widetilde y_A - \\\\widetilde y_B$, where $\\\\,\\\\widetilde{\\\\cdot}\\\\,$ denotes the empirical median. For the grading, make sure your group $y_A$ contains the measurements taken at ```12-26 Weeks``` , and the group $y_B$ contains the measurements taken ```At term```.\\n2. Then repeat many times (e.g. $R = 1000$) \\n    - Randomly assign all the values of ```pd``` to two groups $x_A$ and $x_B$ of the same size as $y_A$ and $y_B$. \\n    - Store the test statistic $t_\\\\text{sim}  = \\\\widetilde x_A - \\\\widetilde x_B $. \\n3. Return the two-sided $p$-value, i.e. the number of permuted test statistics $t_\\\\text{sim}$ which are smaller or equal than $-\\\\vert t_\\\\text{obs} \\\\vert$ or larger or equal than $\\\\vert t_\\\\text{obs} \\\\vert$ divided by the total number of permutations (in our case $R = 1000$).\\n\\n**Important for the access grading**: The path bug has been fixed, if you want to run your script, the path can remain ```read.csv(\"resource/07water_transfer.txt\")```.\\nYou do not have to change the dots anymore for running and submission.\\n', 'answer': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y)\\n  # Store the data without the group labels ( try using c() )\\n  all.data <- c(x, y)           \\n  tsim <- array(0, R)           # Preallocation of R-amount of values\\n  for(i in 1:R ){\\n    index <- sample(x, length(x), replace = FALSE) # random permutation\\n    medianxA <- median(all.data[index]) # Sample median of group A\\n    medianxB <- median(all.data[-index]) # Sample median of group B\\n    tsim[i] <- medianxA - medianxB  # Difference for the current iteration\\n  }\\n  # Sample p-value. Proportion of \"some\" values and amount of iterations  \\n  return( sum ( abs(tsim) >= abs( tobs ))/ R)  \\n}\\n\\n# We test our function:\\nyA <- mydata$pd[mydata$age== \"12-26 Weeks\"]  # Split the data such that you have one factor per group\\nyB <- mydata$pd[mydata$age== \"At term\"] # Split the data such that you have one factor per group\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y) \\n  all.data <- c(x, y)           # Store the data without the group labels\\n  tsim <- array(0, R)           # Preallocation\\n  for(i in 1:R){\\n    index <- sample(1:length(all.data), length(x), replace = F) # random permutation\\n    medianxA <- median( all.data[ index]) # Sample mean of group A\\n    medianxB <- median( all.data[-index]) # Sample mean of group B\\n    tsim[i] <- medianxA - medianxB  # Difference for the current iteration\\n  }\\n  return(sum( abs(tsim) >= abs(tobs))/ R) # Sample p-value \\n}\\n\\n# We test our function:\\nyA <- mydata[mydata$age == \"12-26 Weeks\", 1]\\nyB <- mydata[mydata$age == \"At term\", 1]\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Under the null hypothesis, we are allowed to permute the observations (all $y$-values) while keeping the group assignments fix. Keeping this in mind, we will now manually construct a permutation test to detect a potential shift. Write an R function ```perm_test()``` that implements a two-sample permutation test and returns the $p$-value. Your function should execute the following steps.\\n\\n1. Compute the test statistic $t_\\\\text{obs} = \\\\displaystyle \\\\widetilde y_A - \\\\widetilde y_B$, where $\\\\,\\\\widetilde{\\\\cdot}\\\\,$ denotes the empirical median. For the grading, make sure your group $y_A$ contains the measurements taken at ```12-26 Weeks``` , and the group $y_B$ contains the measurements taken ```At term```.\\n2. Then repeat many times (e.g. $R = 1000$) \\n    - Randomly assign all the values of ```pd``` to two groups $x_A$ and $x_B$ of the same size as $y_A$ and $y_B$. \\n    - Store the test statistic $t_\\\\text{sim}  = \\\\widetilde x_A - \\\\widetilde x_B $. \\n3. Return the two-sided $p$-value, i.e. the number of permuted test statistics $t_\\\\text{sim}$ which are smaller or equal than $-\\\\vert t_\\\\text{obs} \\\\vert$ or larger or equal than $\\\\vert t_\\\\text{obs} \\\\vert$ divided by the total number of permutations (in our case $R = 1000$).\\n\\n**Important for the access grading**: The path bug has been fixed, if you want to run your script, the path can remain ```read.csv(\"resource/07water_transfer.txt\")```.\\nYou do not have to change the dots anymore for running and submission.\\n', 'answer': 'mydata <- read.csv(\"./resource/07water_transfer.txt\")\\n\\n# Define the perm_test function\\nperm_test <- function(x, y) {\\n  R <- 1000\\n  \\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y)\\n  \\n  # Store the data without the group labels\\n  all.data <- c(x, y)\\n  \\n  tsim <- array(0, R) # Preallocation of R-amount of values\\n  \\n  for (i in 1:R) {\\n    index <- sample(1:length(all.data), length(x), replace = FALSE) # random permutation\\n    \\n    # Sample median of group A and group B\\n    medianxA <- median(all.data[index])\\n    medianxB <- median(all.data[-index])\\n    \\n    # Difference for the current iteration\\n    tsim[i] <- medianxA - medianxB\\n  }\\n  \\n  # Sample p-value. Proportion of \"some\" values and amount of iterations\\n  return(sum(abs(tsim) >= abs(tobs))/ R)\\n}\\n\\n# We test our function:\\nyA <- mydata$pd[mydata$age == \"At term\",1]  # Split the data such that you have one factor per group\\nyB <- mydata$pd[mydata$age == \"12-26 Weeks\",1] # Split the data such that you have one factor per group\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)\\n\\n\\n', 'rubrics': [], 'modelSolution': 'mydata <- read.csv(\"resource/07water_transfer.txt\")\\n\\nperm_test <- function(x, y){\\n  R <- 1000\\n  # Store the \"original\" observed median difference\\n  tobs <- median(x) - median(y) \\n  all.data <- c(x, y)           # Store the data without the group labels\\n  tsim <- array(0, R)           # Preallocation\\n  for(i in 1:R){\\n    index <- sample(1:length(all.data), length(x), replace = F) # random permutation\\n    medianxA <- median( all.data[ index]) # Sample mean of group A\\n    medianxB <- median( all.data[-index]) # Sample mean of group B\\n    tsim[i] <- medianxA - medianxB  # Difference for the current iteration\\n  }\\n  return(sum( abs(tsim) >= abs(tobs))/ R) # Sample p-value \\n}\\n\\n# We test our function:\\nyA <- mydata[mydata$age == \"12-26 Weeks\", 1]\\nyB <- mydata[mydata$age == \"At term\", 1]\\n\\nset.seed(14)\\npermtest <- perm_test(yA, yB)\\n\\nsol <- list(permtest = permtest)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': '(Extra Points)\\nA random variable $X$ has a Laplace distribution with parameters $\\\\mu \\\\in \\\\mathbb{R}$ and $\\\\lambda > 0$ if its density is of the form \\n$$f_X(x) = \\\\frac{1}{2 \\\\lambda} \\\\exp \\\\left(-\\\\frac{|x-\\\\mu|}{\\\\lambda} \\\\right)$$.\\n\\nDraw 1000 realizations of a Laplace distribution with parameters $\\\\mu = 0$ and $\\\\lambda = 1$ with a rejection sampling approach.\\\\\\nHint: For the proposal density you can use the density of the $t$-distribution with 1 degree of freedom.\\n', 'answer': 'png(file=\"solution.png\")\\n\\nset.seed(14)\\nn.sim <- 1000 \\n\\nfstar <- function(x) {\\n  ifelse( x >= 0 , exp(-x) , exp(x)  )\\n}\\n\\nx <- seq(-5, 5, length.out = 100)\\nplot( x , fstar(x) , type = \"l\", ylim = c(0, 1.2))\\nlines( x , 3.5*dt( x, df = 1 ), col = \"red\")\\n\\nm <- 3.5\\n\\nf_Z <- function(x) {\\n  dt( x , df = 1 )\\n}\\n \\nresult <- rep(NA, n.sim)\\nsample <- rep(NA, n.sim)\\n\\nfor (i in 1:n.sim){\\n  sample[i] <- rt( 1 , df = 1 )\\n  u <- runif( 1 ) \\n  if ( u < fstar(sample[i])/(m*f_Z(sample[i]))  ) \\n\\tresult[i] <- sample[i]\\n}\\n\\nresult <- result[!is.na(result)]\\nhist(sample, xlab = \"y\", main = \"\", col = \"white\")\\nhist(result, add = TRUE, col = \"darkblue\") # not a nice plot\\n\\n# we remove the smallest and the largest values to get a better plot\\nsample <- sample[ sample >= min(result) & sample <= max(result) ]\\nhist(sample, xlab = \"y\", main = \"\", col = \"white\")\\nhist(result, add = TRUE, col = \"darkblue\")\\n\\nrequire(ExtDist)\\nplot( x , dLaplace( x , mu = 0 , b = 1 ), type = \"l\")\\nlines(density(result), col = \"red\")\\nlegend(\"topright\", legend = c(\"truth\", \"smoothed empirical\"),\\n\\t   lty = 1, col = c(\"black\", \"red\"))\\n\\t   \\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\n\\nset.seed(14)\\nn.sim <- 1000 \\nfstar <- function(x) {\\n  ifelse(x >= 0, exp(-x), exp(x))\\n}\\nx <- seq(-5, 5, length.out = 100)\\nplot(x, fstar(x), type = \"l\", ylim = c(0, 1.2))\\nlines(x, 3.5*dt(x, df = 1), col = \"red\")\\nm <- 3.5\\nf_Z <- function(x) {\\n  dt(x, df = 1)\\n}\\nresult <- rep(NA, n.sim)\\nsample <- rep(NA, n.sim)\\nfor (i in 1:n.sim){\\n  sample[i] <- rt(1, df = 1)\\n  u <- runif(1) \\n  if (u < fstar(sample[i])/(m*f_Z(sample[i]))) \\n    result[i] <- sample[i]\\n}\\nresult <- result[!is.na(result)]\\nhist(sample, xlab = \"y\", main = \"\", col = \"white\")\\nhist(result, add = TRUE, col = \"darkblue\") # not a nice plot\\n# we remove the smallest and the largest values to get a better plot\\nsample <- sample[sample >= min(result) & sample <= max(result)]\\nhist(sample, xlab = \"y\", main = \"\", col = \"white\")\\nhist(result, add = TRUE, col = \"darkblue\")\\nrequire(ExtDist)\\nplot(x, dLaplace(x, mu = 0, b = 1), type = \"l\")\\nlines(density(result), col = \"red\")\\nlegend(\"topright\", legend = c(\"truth\", \"smoothed empirical\"),\\n       lty = 1, col = c(\"black\", \"red\"))\\n\\t   \\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'On www.isleroyalewolf.org/data/data/home.html the file isleroyale graph data 28Dec2011.xlsx contains population data from wolves and moose. The information in this file is extracted and saved in the file 01wolvesmoose.csv.Download and read the file 01wolvesmoose.csv from the STA120 course page.\\n\\nCreate a boxplot containing both, Moose and Wolf data. \\nCreate a QQ-plot for Moose and a QQ-plot for Wolf.\\nCreate a plot of Wolf on Year and of Moose on Year.\\nCreate a plot of Wolf on Moose, with colors 1:3.\\nYou should get 6 plots. Use par( mfrow=c(2,3)) to plot them in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': 'png(file= \"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\", header=TRUE)\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose,dat$Wolf )\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)# add QQ-line here\\n\\nqqnorm(dat$Wolf , main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)# add QQ-line here\\nplot(Wolf ~ Year , data = dat, type = \\'l\\' ) # What type should this plot be for nice line?\\nplot(Moose ~ Year , data = dat, type = \\'l\\' ) # What type should this plot be for nice line?\\n# How many times should the colors repeat so that the legend makes sense?\\nplot(Wolf~Moose, data=dat, col=rep( c(1,2,3), times=c( 1 , 1 , 1 ))) \\nlegend(\"topright\", col=c(1,2,3), \\n    legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"), \\n    bty=\"n\", \\n    pch=\"o\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\")\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose, dat$Wolf)\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\nplot(dat$Wolf ~ dat$Year, type = \"l\")\\nplot(dat$Moose ~ dat$Year,  type = \"l\")\\nplot( Wolf~Moose, data=dat, col=rep( c(1,2,3), times=c(22,16,15)))\\nlegend(\"topright\", col=c(1,2,3), \\n       legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"),\\n       bty=\"n\",\\n       pch=\"o\")\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany. \\\\\\nLoad the data and take a look at its help page using ?Oral. Also have look at str() of the Oral data.  \\nCompute summary statistics for all variables in the dataset.  \\nWhich of the $544$ regions has the highest number of expected counts E?  \\nAssume that the standardized mortality ratio $Z_{i} = Y_{i} / E_{i}$ is normally distributed, i.e., $Z_{1}, \\\\dots, Z_{544} \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$. \\nEstimate $\\\\mu$ and give a 95\\\\% (exact) confidence interval (CI). \\n\\nSave all results in the given list. \\\\\\nHint: The standardized mortality ratio is stored in the column SMR of the dataset Oral.\\n\\n', 'answer': 'require(spam)\\ndata(Oral)\\n\\nsmry <- summary(Oral)\\nmaximum <- max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- var(Oral$SMR)\\nS <- sqrt(S2)\\nci <- mean_SMR + c(-1, 1) * qnorm(0.975) * sqrt(S2/n)\\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'rubrics': [], 'modelSolution': 'require(spam)\\ndata(Oral)\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- 1/(n-1) * sum((Oral$SMR - mean(Oral$SMR))^2)  \\nS <- sqrt(S2) \\nci <-  mean_SMR + c(-1, 1) * qt(0.975, n-1, lower = TRUE) * S/sqrt(n) \\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany.\\nSimulate a 95\\\\% confidence interval for the sample mean of the variable SRM based on the following bootstrap scheme (sampling with replacement):\\nRepeat $10'000$ times\\n    - Sample $544$ observations $Z_{i}$ with replacement\\\\\\n    - Calculate and store the mean of these sampled observations\\\\\\nConstruct the confidence interval by taking the 2.5\\\\% and the 97.5\\\\% quantiles of the stored means.\\n\", 'answer': 'require(spam)\\ndata(Oral)\\n\\nn <- 544\\nset.seed(3)\\n\\n# Room for creativity!\\nboot_means <- replicate(10000, {\\n  sampled_indices <- sample(1:n, replace = TRUE)\\n  mean(Oral$q[sampled_indices])\\n})\\n\\nsol <- quantile(boot_means, c(0.025, 0.975))', 'rubrics': [], 'modelSolution': 'require(spam) \\ndata(Oral) \\nn <- 544\\nmybootstrap <- function(n.replications){ \\n temporary <- array(0, dim = n.replications) # Preallocation is always advisable! \\n for(i in 1:n.replications){ \\n   temporary[i] = mean(sample(Oral$SMR, size = n, replace = T)) \\n } \\n return(as.numeric(temporary)) \\n} \\nset.seed(3) \\nsim.mean2 <- mybootstrap(10000) \\nsol <- quantile(sim.mean2, c(0.025, 0.975)) ', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In the following settings, calculate the probabilities and quantiles $q_1$ and $q_2$.\\n\\n$$\\nX\\\\sim \\\\mathcal{N}(2,16): \\n$$\\n$$\\n\\\\qquad P_1 = P(X<4), P_2 = P(0\\\\leq X\\\\leq 4), P(X> Q_1)=0.95, P(X< -Q_2)=0.05.\\n$$\\nYou can use the following two R commands: pnorm(a) and qnorm(b) for specific values a and b.\\n**Do not change the solution list at the bottom**\\n', 'answer': 'png(file= \"solution.png\")\\nP1 <- pnorm(4,2,sqrt(16))\\nP2 <- pnorm(4,2,sqrt(16))-pnorm(0,2,sqrt(16))\\nQ1 <- qnorm(0.95,2,sqrt(16),lower.tail=FALSE)\\nQ2 <- qnorm(0.05,2,sqrt(16))\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'rubrics': [], 'modelSolution': 'P1 <- pnorm(4, 2, sqrt(16))\\nP2 <- pnorm(4, 2, sqrt(16)) - pnorm(0, 2, sqrt(16))\\nQ1 <- qnorm(0.95, 2, sqrt(16), lower.tail=FALSE)\\nQ2 <- -qnorm(0.05, 2, sqrt(16))\\n\\nsol <- list(\"Results\" = c(P1, P2, Q1, Q2))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'For the control treatment and the family treatment, perform an individual paired  Wilcoxon signed rank test to compare the weight before and after the treatment.\\n', 'answer': 'require(MASS)\\nmyAnorexia <- anorexia[anorexia$Treat == \"Cont\"| anorexia$Treat == \"FT\",] # Same split as in previous exercise.\\nmyAnorexia <- droplevels(myAnorexia)\\n\\naCont <- myAnorexia[ myAnorexia$Treat == \"Cont\" ,] # Choose only Treat = \"Cont\"\\nwilcox_cont <- wilcox.test( aCont$Prewt , aCont$Postwt, paired = TRUE, exact = FALSE) #Prewt VS Postwt\\n\\naFT <- myAnorexia[myAnorexia$Treat == \"FT\",] # Choose only Treat = \"FT\"\\nwilcox_FT <- wilcox.test( aFT$Prewt , aFT$Postwt , paired = TRUE , exact = FALSE) #Prewt VS Postwt\\n\\nsol <- list(wilcox_cont = wilcox_cont$p.value, wilcox_FT = wilcox_FT$p.value)', 'rubrics': [], 'modelSolution': 'require(MASS)\\nmyAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\nmyAnorexia <- droplevels(myAnorexia)\\n\\naCont <- myAnorexia[myAnorexia$Treat == \"Cont\",]\\nwilcox_cont <- wilcox.test(aCont$Prewt, aCont$Postwt, paired = TRUE, exact = FALSE)\\n\\naFT <- myAnorexia[myAnorexia$Treat == \"FT\",]\\nwilcox_FT <- wilcox.test(aFT$Prewt, aFT$Postwt, paired = TRUE, exact = FALSE)\\n\\nsol <- list(wilcox_cont = wilcox_cont$p.value, wilcox_FT = wilcox_FT$p.value)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Consider the distribution from task 1 and its plot:\\n$$     \\n     \\\\quad \\\\mu = \\\\begin{pmatrix}\\\\,1\\\\,\\\\\\\\ 2\\\\end{pmatrix},\\n     \\\\quad \\\\Sigma = \\\\begin{pmatrix}1 & 1\\\\\\\\1 & 2\\\\end{pmatrix}.\\n$$\\n\\nMark the values that can be seen as a realization of $Y \\\\mid \\\\{Z \\\\in [3,4] \\\\}$ in red. \\nAdd also 100 points from the conditional distribution $Y \\\\mid \\\\{Z = 3.5 \\\\}$ to the plot. Are the realizations of $Y \\\\mid \\\\{Z \\\\in [3,4] \\\\}$ a good approximation of $Y \\\\mid \\\\{Z = 3.5 \\\\}$? \\\\\\nHint: Use the formula (8.28) to compute the distribution of $Y \\\\mid \\\\{Z = 3.5 \\\\}$.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  require(mvtnorm)\\nset.seed(14)\\nmu <- c(1,2)\\nsigma <- array(c(1,1,1,2), c(2,2))\\nres <- rmvnorm(500, mu, sigma)\\nprint(res)\\n# from (b)\\npar(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\nplot(res, xlab = \"y\", ylab = \"z\", pch = 20,\\n     xlim = c(-3, 7), ylim = c(-3, 7))\\n\\n# exercise now\\n# Make sure you choose a right operator instead of \"%%%\".\\npoints(res[which(res[,2] >3 & res[,2]< 4),1],res[which(res[,2] >3 & res[,2]< 4),2], col = \"red\", pch = 20)\\nz <- 3.5\\nmu.constr <- 1 + 1*0.5*(3.5-2) # Use formula from the lecture.\\nsigma.constr <- 1 - 0.5 # Use formula from the lecture.\\ny.constr <- rnorm(100, mu.constr, sigma.constr) # Generating 100 points with new mu and sigma\\npoints(y.constr, rep(z, 100), col = \"blue\", pch = 20)\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nrequire(mvtnorm)\\n set.seed(14)\\n mu <- c(1, 2)\\n sigma <- matrix(c(1, 1, 1, 2), ncol = 2)\\n res <- rmvnorm(n = 500, mean = mu, sigma = sigma)\\n \\n #from (b)\\n par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n plot(res, xlab = \"y\", ylab = \"z\", pch = 20,\\n      xlim = c(-3, 7), ylim = c(-3, 7))\\n \\n #exercise now\\n points(res[res[,2] > 3 & res[,2] < 4,], col = \"red\", pch = 20)\\n z <- 3.5\\n mu.constr <- mu[1] + sigma[1,2] * (1 / sigma[2,2]) * (z - mu[2])\\n sigma.constr <- sigma[1,1] - sigma[1,2] *(1 / sigma[2,2]) * sigma[2,1]\\n y.constr <- rnorm(100, mu.constr, sqrt(sigma.constr))\\n points(y.constr, rep(z, 100), col = \"blue\", pch = 20)\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin. The dataset anorexia in the package MASS gives the weight in pounds of 72 females before and after a treatment, consisting of control, cognitive behavioral treatment and family treatment. \\\\\\nIn this exercise we only want to compare the control treatment (Cont) with the family treatment (FT). \\\\\\nVisualize the weight difference before and after the control treatment and the family treatment in a boxplot.\\n\\n*Do not change the plot functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  require(MASS)\\n  # Try to replace \"%%%\" with with proper operator, to get % right output.\\n  # This might help: https://www.statmethods.net/management/operators.html\\n  myAnorexia <- anorexia[ anorexia$Treat == \\'Cont\\' | anorexia$Treat == \\'FT\\', ] # Make sure you choose proper groups. KOMMA IST HIER ZENTRAL\\n  myAnorexia <- droplevels(myAnorexia)\\n  myAnorexia\\n  # Calculate the difference between Postwt and Prewt: \\n  anorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt\\n  boxplot( anorexiaDiff ~ myAnorexia$Treat, \\n          xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nrequire(MASS)\\n myAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\n myAnorexia <- droplevels(myAnorexia)\\n anorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt\\n boxplot(anorexiaDiff ~ myAnorexia$Treat, \\n         xlab = \"Treatment\", ylab = \"Weight difference\")\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Use the the R help function to find out the purpose of the function demo() and have a look at the list of available demos. The demo of the function persp() utilizes the volcano data to illustrate basic three-dimensional plotting. Call the demo and have a look at the plots. Do that in your own environment and afterwards just press \"Submit\".', 'answer': '# Student solution.\\r\\n?demo\\r\\ndemo(persp)', 'rubrics': [], 'modelSolution': 'demo(persp) \\n\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this problem we investigate the effect of deviations of statistical assumptions on the $p$-value. For simplicity, we use the one-sample $t$-test.   \\nFor 10'000 times, sample $X_{1}, \\\\dots, X_{10} ~ \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$ with $\\\\mu = 0$ and $\\\\sigma^{2} = 1$.  \\nFor each sample perform a $t$-test for $H_{0}: \\\\mu = 0$ and store the $p$-value thereof. \\nPlot the 10'000 $p$-values in a histogram. What do you observe?    \\nFor $\\\\alpha = 0.05$, what is the observed Type I error of the sampled data in (a)?   \\nHint: The Type I error is the probability of rejecting the null hypothesis even though it is true (here, $\\\\alpha = 0.05$).    \\nIn this setting we know that the null hypothesis $H_{0}: \\\\mu = 0$ is true because we sample from a $\\\\mathcal{N}(0, 1)$ distribution.     \\nThe observed Type I error is then the proportion of the number of rejected null hypotheses.  \\n\", 'answer': 'set.seed(5)\\nn = 10\\nR = 10000\\nsample = matrix(rnorm(n*R),R,n)\\ngetP = function(x){\\n  pval = t.test(x)$p.value\\n  return(pval)\\n}\\npvals = apply(sample, 1, getP)\\n\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\n\\nerr = 1/R*sum(pvals<0.05)\\n\\nsol <- list(type_I_error = err)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\nsamples <- matrix(rnorm(n*R), R, n) # R rows, n columns\\ngetPvalue <- function(x){\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\npvals <- apply(samples, 1, getPvalue) # apply one t-test for each row of \\'samples\\'\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\nerr <- 1/R * sum(pvals < 0.05)\\nsol <- list(type_I_error = err)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this problem we investigate the effect of deviations of statistical assumptions on the $p$-value. For simplicity, we use the one-sample $t$-test.   \\nFor 10'000 times, sample $X_{1}, \\\\dots, X_{10} ~ \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$ with $\\\\mu = 0$ and $\\\\sigma^{2} = 1$.  \\nFor each sample perform a $t$-test for $H_{0}: \\\\mu = 0$ and store the $p$-value thereof. \\nPlot the 10'000 $p$-values in a histogram. What do you observe?    \\nFor $\\\\alpha = 0.05$, what is the observed Type I error of the sampled data in (a)?   \\nHint: The Type I error is the probability of rejecting the null hypothesis even though it is true (here, $\\\\alpha = 0.05$).    \\nIn this setting we know that the null hypothesis $H_{0}: \\\\mu = 0$ is true because we sample from a $\\\\mathcal{N}(0, 1)$ distribution.     \\nThe observed Type I error is then the proportion of the number of rejected null hypotheses.  \\n\", 'answer': 'set.seed(5)\\nrepeats <- 10000\\npvals <- numeric(repeats)\\n\\n\\n\\nfor (i in 1:repeats) {\\n  norm_sample <- rnorm(n=10)\\n  tt <- t.test(norm_sample)\\n  pvals[i] <- tt$p.value\\n}\\n\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\n\\n\\n\\nsol <- list(type_I_error = err)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\nsamples <- matrix(rnorm(n*R), R, n) # R rows, n columns\\ngetPvalue <- function(x){\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\npvals <- apply(samples, 1, getPvalue) # apply one t-test for each row of \\'samples\\'\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\nerr <- 1/R * sum(pvals < 0.05)\\nsol <- list(type_I_error = err)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin.  \\nThe dataset anorexia in the package MASS gives the weight (in pounds) of 29 females before and after a cognitive behavioral treatment (CBT).  \\nTest whether the treatment was effective.\\nTo do this, return as a solution the p-value of the t.test, the 95 percent confidence interval of the difference between post and pre treatment, and the alternative hypothesis.\\nTo obtain the right difference (direction), make sure to use the pre-treatment weight first, and then the post-treatment weight.\\nYou can assume that the variances are equal, i.e. use the setting ``` var.equal=TRUE```.\\n', 'answer': 'require(MASS)\\ndata(\"anorexia\")\\ncbtanorexia <- anorexia[anorexia$Treat==\"CBT\",]\\ntt <- t.test(cbtanorexia$Prewt,cbtanorexia$Postwt,paired=TRUE)\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'rubrics': [], 'modelSolution': 'require(MASS)\\ndata(anorexia)\\n\\nanorexiaCBT <- subset(anorexia, Treat == \"CBT\")\\ntt <- t.test(anorexiaCBT$Prewt, anorexiaCBT$Postwt, paired = TRUE)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'The dataset Oral is available in the R package spam and contains oral cavity cancer counts for $544$ districts in Germany. \\\\\\nLoad the data and take a look at its help page using ?Oral. Also have look at str() of the Oral data.  \\nCompute summary statistics for all variables in the dataset.  \\nWhich of the $544$ regions has the highest number of expected counts E?  \\nAssume that the standardized mortality ratio $Z_{i} = Y_{i} / E_{i}$ is normally distributed, i.e., $Z_{1}, \\\\dots, Z_{544} \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$. \\nEstimate $\\\\mu$ and give a 95\\\\% (exact) confidence interval (CI). \\n\\nSave all results in the given list. \\\\\\nHint: The standardized mortality ratio is stored in the column SMR of the dataset Oral.\\n\\n', 'answer': 'require( spam )\\ndata( Oral )\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$SMR)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- var(Oral$SMR)\\nS <- sqrt(S2)\\nci <- mean(Oral$SMR) + c(-1, 1) * S * 1.97\\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'rubrics': [], 'modelSolution': 'require(spam)\\ndata(Oral)\\n\\n\\nsmry <- summary(Oral)\\nmaximum <- which.max(Oral$E)\\n\\nmean_SMR <- mean(Oral$SMR)\\nn <- 544 \\nS2 <- 1/(n-1) * sum((Oral$SMR - mean(Oral$SMR))^2)  \\nS <- sqrt(S2) \\nci <-  mean_SMR + c(-1, 1) * qt(0.975, n-1, lower = TRUE) * S/sqrt(n) \\n\\n\\nsol <- list(smry, maximum, mean_SMR, ci)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Plot the density of $X$ (as defined in the previous task) in R.  \\nHint: You can use the function ```image.plot()``` from the R package fields.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  mu <- c(1,2)\\n  sigma <- matrix(c(1,1,1,2), nrow=2)\\n  \\n  require(fields)\\n  require(mvtnorm)\\n  par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n  y <- seq(-2,4,length.out=100) # sequence 100 numbers from -2 to 4\\n  z <- seq(-2,6,length.out=100) # sequence 100 numbers from -2 to 6\\n  grid <- expand.grid(x=y, y=z) # use expand.grid() in a proper way\\n  # Simulate density of N(mu, sigma):\\n  densgrid <- dmvnorm( grid , mean = mu , sigma = sigma ) \\n  jdensity <- array(densgrid, c(100, 100))\\n  image.plot(y, z, jdensity, col = tim.colors())\\ndev.off()', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nmu <- c(1, 2)\\n sigma <- matrix(c(1, 1, 1, 2), ncol = 2)\\n require(mvtnorm)\\n require(fields)\\n par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n y <- seq(-2, 4, length.out = 100)\\n z <- seq(-2, 6, length.out = 100)\\n grid <- expand.grid(y, z)\\n densgrid <- dmvnorm(grid, mean = mu, sigma = sigma)\\n jdensity <- array(densgrid, c(100, 100))\\n image.plot(y, z, jdensity, col = tim.colors())\\n dev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this problem we investigate the effect of deviations of statistical assumptions on the $p$-value. For simplicity, we use the one-sample $t$-test.   \\nFor 10'000 times, sample $X_{1}, \\\\dots, X_{10} ~ \\\\mathcal{N}(\\\\mu, \\\\sigma^{2})$ with $\\\\mu = 0$ and $\\\\sigma^{2} = 1$.  \\nFor each sample perform a $t$-test for $H_{0}: \\\\mu = 0$ and store the $p$-value thereof. \\nPlot the 10'000 $p$-values in a histogram. What do you observe?    \\nFor $\\\\alpha = 0.05$, what is the observed Type I error of the sampled data in (a)?   \\nHint: The Type I error is the probability of rejecting the null hypothesis even though it is true (here, $\\\\alpha = 0.05$).    \\nIn this setting we know that the null hypothesis $H_{0}: \\\\mu = 0$ is true because we sample from a $\\\\mathcal{N}(0, 1)$ distribution.     \\nThe observed Type I error is then the proportion of the number of rejected null hypotheses.  \\n\", 'answer': 'set.seed(5)\\n\\npvals = c()\\nfor(i in 1:10000){\\n  x = rnorm(10)\\n  tt = t.test(x)\\n  pvals = c(pvals, tt$p.val)\\n}\\n\\n\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\n\\nerr = length(pvals[pvals<0.05]) / length(pvals)\\n\\n\\nsol <- list(type_I_error = err)', 'rubrics': [], 'modelSolution': 'set.seed(5)\\nR <- 10000\\nn <- 10\\nsamples <- matrix(rnorm(n*R), R, n) # R rows, n columns\\ngetPvalue <- function(x){\\n  pval <- t.test(x)$p.value\\n  return(pval)\\n}\\npvals <- apply(samples, 1, getPvalue) # apply one t-test for each row of \\'samples\\'\\nhist(pvals, main = \"Histogram of p-values\", xlab = \"p-values\")\\nerr <- 1/R * sum(pvals < 0.05)\\nsol <- list(type_I_error = err)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Perform a Wilcoxon-Mann-Whitney tests to compare the control treatment with with the family treatment. Interpret your result.\\n\\n', 'answer': 'require(MASS)\\nmyAnorexia <- anorexia[ anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ] # Same split as in previous exercise.\\nmyAnorexia <- droplevels(myAnorexia)\\nanorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt  # Difference as in previous exercise.\\n\\nwilcox <- wilcox.test ( anorexiaDiff ~ myAnorexia$Treat , exact = FALSE)\\n\\nsol <- list(wilcox = wilcox$p.value)\\n', 'rubrics': [], 'modelSolution': 'require(MASS)\\nmyAnorexia <- anorexia[anorexia$Treat == \"Cont\" | anorexia$Treat == \"FT\", ]\\nmyAnorexia <- droplevels(myAnorexia)\\nanorexiaDiff <- myAnorexia$Postwt - myAnorexia$Prewt\\n\\nwilcox <- wilcox.test(anorexiaDiff ~ myAnorexia$Treat, exact = FALSE)\\n\\nsol <- list(wilcox = wilcox$p.value)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We assume $X\\\\sim\\\\mathcal{U}(0,8)$. Simulate $n=10,50,10000$ random numbers and visualize the histogram as well as a QQ-plot thereof. Superimpose a smoothed density to the histograms (with lines(density(...)) ). \\\\\\nUse par(mfrow = c(3, 2)) to visualize the graphs in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': 'png(file=\"solution.png\")\\nset.seed(1)\\ntheta <- 8\\nn <- c( 10 , 50 , 1000 )\\npar(mfrow = c(3, 2))\\nmybreaks = 4\\nfor ( i in 1:length(n) ) {\\n  x <- seq(0, 8, n[i])\\n  runif_vals = runif(n[i], 0, theta)\\n  hist(runif_vals[runif_vals >= 0 & runif_vals <= 8], breaks = mybreaks, prob = TRUE, main=\"Histogram of x\", xlab=\"x\")\\n  mybreaks = 2*mybreaks\\n  # Add density Lines with color \"red\"\\n  lines(density(runif_vals), col=\"red\")\\n  \\n  # QQ-Plot using 500 probability points (ppoints)\\n  qqplot( ppoints(500) , runif_vals, xlab=\"qunit(ppoints(500))\")\\n}\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': ' png(file=\"solution.png\")\\nset.seed(1)\\n theta <- 8\\n n <- c(10, 50, 10000)\\n \\n par(mfrow = c(3, 2))\\n for (k in 1:length(n)) {\\n   x <- runif(n[k], 0, theta)\\n   hist(x, prob = TRUE)\\n   lines(density(x), col = \"red\")\\n   qqplot(qunif(ppoints(500)), x)\\n }\\n dev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Anorexia is an eating disorder that is characterized by low weight, food restriction, fear of gaining weight and a strong desire to be thin.  \\nThe dataset anorexia in the package MASS gives the weight (in pounds) of 29 females before and after a cognitive behavioral treatment (CBT).  \\nTest whether the treatment was effective.\\nTo do this, return as a solution the p-value of the t.test, the 95 percent confidence interval of the difference between post and pre treatment, and the alternative hypothesis.\\nTo obtain the right difference (direction), make sure to use the pre-treatment weight first, and then the post-treatment weight.\\nYou can assume that the variances are equal, i.e. use the setting ``` var.equal=TRUE```.\\n', 'answer': 'require(MASS)\\ndata(anorexia)\\n\\n\\ntt <- anorexia[which(anorexia$Treat == \"CBT\"), ]\\nt <- with(tt, t.test(Prewt, Postwt, paired = TRUE))\\n\\np_value <- t$p.value\\nci <- t$conf.int\\nalt_hyp <- t$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)\\nsol', 'rubrics': [], 'modelSolution': 'require(MASS)\\ndata(anorexia)\\n\\nanorexiaCBT <- subset(anorexia, Treat == \"CBT\")\\ntt <- t.test(anorexiaCBT$Prewt, anorexiaCBT$Postwt, paired = TRUE)\\n\\np_value <- tt$p.value\\nci <- tt$conf.int\\nalt_hyp <- tt$alternative\\n\\nsol <- list(p_value = p_value, ci=ci, alt_hyp=alt_hyp)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We choose the following gamma prior density for the parameter $\\\\kappa$:\\n$$\\nf(\\\\kappa \\\\mid \\\\alpha,\\\\beta) =\\n    \\\\begin{cases}\\n        \\\\frac{\\\\beta^{\\\\alpha}}{\\\\Gamma(\\\\alpha)} \\\\kappa^{\\\\alpha-1} \\\\exp(-\\\\beta \\\\kappa), & \\\\text{if $\\\\kappa > 0$},\\\\\\\\\\n      0, & \\\\text{otherwise},\\n\\\\end{cases}\\n$$\\nfor fixed {hyper-parameters} $\\\\alpha > 0$, $\\\\beta > 0$, i.e. $\\\\kappa \\\\sim \\\\mathcal{G}am(\\\\alpha, \\\\beta)$. How does this distribution relate to the exponential distribution?\\n\\nPlot four densities for $(\\\\alpha, \\\\beta)$ = (1,1), (1,2), (2,1) and (2,2). How can a certain choice of $\\\\alpha, \\\\beta$ be interpreted with respect to our ''beliefs'' on $\\\\kappa$?\\n\", 'answer': 'png(file=\"solution.png\")\\n\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1,1,2,2)  # shape\\nbeta <- c(1,2,1,2)  # rate\\nplot(grid, dgamma(grid,alpha,beta),\\n      type = \"l\", lwd = 2, col = 2,\\n      xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 1:length(alpha)){\\n  lines( grid, dgamma( grid , shape = alpha[i], rate =  beta[i]),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(16)\\ngrid <- seq(0, 5, l = 200)\\nalpha <- c(1, 1, 2, 2)  # shape\\nbeta <- c(1, 2, 1, 2)  # rate\\nplot(grid, dgamma(grid, shape = alpha[1], rate = beta[1]),\\n     type = \"l\", lwd = 2, col = 2,\\n     xlab = expression(tau), ylab = \"pdf\", ylim = c(0, 2))\\nfor(i in 2:4){\\n  lines(grid, dgamma(grid, shape = alpha[i], rate = beta[i]),\\n        lwd = 2, col = i+1)\\n}\\nlegend(\"topright\",\\n       legend = paste0(\"(alpha,beta)=(\", paste0(alpha,\",\",beta),\")\"),\\n       lwd = 2, col = 2:5)\\n\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Suppose that among $n=95$ Swiss males, eight are red-green colour blind. We are interested in estimating the proportion $p$ of people suffering from such disease among the male population.  \\n\\nCompute a 95\\\\% Wilson confidence interval and compare it to the confidence intervals obtained in (d).  \\nHint: Use the formula for the CI given in equation 6.11 in the script and define your own R function for calculating the CI.\\n', 'answer': 'n <- 95\\nx <- 8\\n\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  \\n  CI <- binom.wilson(x, n, 100-alpha)\\n\\n  return(CI)\\n}\\n\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'rubrics': [], 'modelSolution': 'n <- 95\\nx <- 8\\nWilsonCI <- function(x, n, alpha = 0.05) {\\n  p_hat <- x/n\\n  q <- qnorm(1-alpha/2)\\n  CI <- 1/(1 + (q^2)/n) * (p_hat + q^2/(2*n) + \\n                             c(-1, 1) * q * sqrt( p_hat*(1-p_hat)/n + q^2/(4*n^2) ))\\n  return(CI)\\n}\\nCI <- WilsonCI(x, n)\\nsol <- list(CI = CI)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'On www.isleroyalewolf.org/data/data/home.html the file isleroyale graph data 28Dec2011.xlsx contains population data from wolves and moose. The information in this file is extracted and saved in the file 01wolvesmoose.csv.Download and read the file 01wolvesmoose.csv from the STA120 course page.\\n\\nCreate a boxplot containing both, Moose and Wolf data. \\nCreate a QQ-plot for Moose and a QQ-plot for Wolf.\\nCreate a plot of Wolf on Year and of Moose on Year.\\nCreate a plot of Wolf on Moose, with colors 1:3.\\nYou should get 6 plots. Use par( mfrow=c(2,3)) to plot them in one image.\\n\\n**Do not change the png() and dev.off() functions**\\n', 'answer': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\", header=TRUE)\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose,dat$Wolf)\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\nplot(Wolf ~ Year, data = dat, type = \"b\") # What type should this plot be for nice line?\\nplot(Moose ~ Year,data = dat, type = \"b\") # What type should this plot be for nice line?\\n# How many times should the colors repeat so that the legend makes sense?\\nplot(Wolf ~ Moose, data=dat, col=rep( c(1,2,3), times=c(22,16,15))) \\nlegend(\"topright\", col=c(1,2,3), \\n    legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"), \\n    bty=\"n\", \\n    pch=\"o\")\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\ndat <- read.csv(\"resource/wolvesmoose.csv\")\\npar(mfrow = c(2,3))\\nboxplot(dat$Moose, dat$Wolf)\\nqqnorm(dat$Moose, main=\"QQ-plot Moose\")\\nqqline(dat$Moose)\\nqqnorm(dat$Wolf, main=\"QQ-plot of Wolves\")\\nqqline(dat$Wolf)\\nplot(dat$Wolf ~ dat$Year, type = \"l\")\\nplot(dat$Moose ~ dat$Year,  type = \"l\")\\nplot( Wolf~Moose, data=dat, col=rep( c(1,2,3), times=c(22,16,15)))\\nlegend(\"topright\", col=c(1,2,3), \\n       legend=c(\"1959-1980\",\"1981-1996\",\"1997-2011\"),\\n       bty=\"n\",\\n       pch=\"o\")\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Give an empirical 95\\\\% confidence interval for $\\\\beta_0$ and $\\\\beta_1$. \\n(The degree of freedom is the number of observations minus the number of parameters in the model.)\\n\\nCalculate the values of the $t$ statistic for $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ and the corresponding two-sided $p$-values.\\n', 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(15, 0, 2)\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x - x.mean) * (y - y.mean)) / sum((x - x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals ^2)\\n\\nn <- length(x)\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x - x.mean)^2))\\nbeta1.se <- sigma.e / sqrt( sum((x - x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt( 0.975 df = n-2 ) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt( 0.975 df = n-2 ) * beta1.se\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\n# Think about why abs() here:\\np.value0 <- 2 * pt (abs( t0 ), df = n-2 , lower.tail = F ) \\np.value1 <- 2 * pt (abs( t1 ), df = n-2 , lower.tail = F )\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'rubrics': [], 'modelSolution': 'set.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1     ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\n\\n# start here to calculate your solution for the problem:\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\ny.fitted <- beta0.hat + beta1.hat * x\\nresiduals <- y - y.fitted\\nSS <- sum(residuals^2)\\n\\nn <- 15\\nsigma.e <- sqrt(SS / (n-2))\\nbeta0.se <- sigma.e * sqrt(1/n + x.mean^2 / sum((x-x.mean)^2))\\nbeta1.se <- sigma.e * sqrt(1 / sum((x-x.mean)^2))\\n\\n\\nbeta0.ci <- beta0.hat + c(-1, 1) * qt(0.975, df = n-2) * beta0.se\\nbeta1.ci <- beta1.hat + c(-1, 1) * qt(0.975, df = n-2) * beta1.se\\n\\n\\nt0 <- beta0.hat / beta0.se\\nt1 <- beta1.hat / beta1.se\\np.value0 <- 2 * pt(abs(t0), df = n-2, lower.tail = FALSE)\\np.value1 <- 2 * pt(abs(t1), df = n-2, lower.tail = FALSE)\\n\\n\\nsol <- list(beta0_ci = beta0.ci, beta1_ci = beta1.ci,\\nt0 = t0, t1 = t1, pvalue0 = p.value0, pvalue1 = p.value1)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Let $X$ be a random vector with bivariate normal distribution, i.e. $X = (Y,Z) \\\\sim \\\\mathcal{N}_{2}(\\\\mu,\\\\Sigma)$ with\\n$$     \\n     \\\\quad \\\\mu = \\\\begin{pmatrix}\\\\,1\\\\,\\\\\\\\ 2\\\\end{pmatrix},\\n     \\\\quad \\\\Sigma = \\\\begin{pmatrix}1 & 1\\\\\\\\1 & 2\\\\end{pmatrix}.\\n$$\\nConsider $n$ iid random vectors $X_1, \\\\dots, X_n$ with the distribution of $X$.\\n\\nSimulate $n=500$ iid realizations from $\\\\mathcal{N}_2(\\\\mu,\\\\Sigma)$ using the function ```rmvnorm()``` from the R package ```mvtnorm```. \\nDraw a scatter plot of the results and interpret the figure.\\n\\n*Do not change the plotting functions*\\n', 'answer': 'png(file=\"solution.png\")\\n  par(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\n  require(mvtnorm)\\n  set.seed(14)\\n  mu <- c(1,2)\\n  sigma <- matrix(c(1,1,1,2), nrow=2)\\n  simulated <- rmvnorm(500, mean = mu, sigma = sigma) \\n  plot( simulated , xlab = \"y\", ylab = \"z\", pch = 20,\\n       xlim = c(-3, 7), ylim = c(-3, 7))\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\npar(mai = c(0.8, 0.8, 0.1, 0.1)) # to have a proper aspect ratio\\nrequire(mvtnorm)\\nset.seed(14)\\nmu <- c(1, 2)\\nsigma <- matrix(c(1, 1, 1, 2), ncol = 2)\\nsimulated <- rmvnorm(n = 500, mean = mu, sigma = sigma) \\nplot(simulated, xlab = \"y\", ylab = \"z\", pch = 20,\\n  xlim = c(-3, 7), ylim = c(-3, 7))\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"We consider the data ```11chemosphere_OC.csv``` available on the course page. \\nThe data describes the octocrylene (OC) concentration sampled from 12 wastewater treatment plants in Switzerland.\\n Further variables in the dataset are: Behandlung (treatment of the wastewater), Monat (month when the sample was collected), Einwohner (number of inhabitant connected to the plant), \\n Produktion (sludge production (metric tons of dry matter per year), everything that doesn't enter the water system after treatment).\\n\\nOctocrylene is an organic UV filter and is used in sunscreens and as additive in cosmetics for daily usage.\\nThe substance is classified as irritant and dangerous for the environment (EU classification of dangerous substances).\\n\\nDescribe the data. Do a visual inspection to check for differences between the treatment types and between the months of data acquirement. \\nUse an appropriate plot function to do so. Describe your results. \\nHint: Also try the function ```table()```.\\n\", 'answer': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\nchem$logOC <- log(chem$OC)\\nhead( chem )\\nstr( chem )\\ntable( chem[, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot( OC ~ Behandlung , data = chem) #behandlung\\nboxplot( OC ~ Monat , data = chem) #monat\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file=\"solution.png\")\\nset.seed(26)\\nchem <- read.table(\"resource/11chemosphere_OC.csv\", header = TRUE, sep = \",\")\\n\\nchem$logOC <- log(chem$OC)\\nhead(chem)\\nstr(chem)\\ntable(chem[, c(\"Monat\", \"Behandlung\")]) # Design of the experiment!\\n## Boxplots with the two factors\\npar(mfrow = c(1, 2))\\nboxplot(logOC ~ Behandlung, data = chem)\\nboxplot(logOC ~ Monat, data = chem)\\n\\ndev.off()\\t', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In a simple linear regression, the data are assumed to follow $Y_i = \\\\beta_0 + \\\\beta_1 x_i  + \\\\varepsilon_i$ with $\\\\varepsilon_i \\\\underset{iid}{\\\\sim} \\\\mathcal{N}(0, \\\\sigma^2)$, $i = 1, \\\\dots, n$. \\nWe simulate $n = 15$ data points from that model with $\\\\beta_0 = 1$, $\\\\beta_1 = 2$, $\\\\sigma = 2$ and the following values for $x_i$.\\n\\nPlot the simulated data in a scatter plot in your Rstudio. Calculate the Pearson correlation coefficient and the Spearman's rank correlation coefficient. Why do they agree well? \\n\\nEstimate the linear regression coefficients $\\\\widehat{\\\\beta_0}$ and $\\\\widehat{\\\\beta_1}$ using the formulas from the script. \\n\\n*PS* -  The same code will repeat multiple time during this exercise. We recommend you to copy your final code and save it somewhere for the next exercise.\\n\", 'answer': '# use the following code as a base:\\nset.seed(5)         ## for reproducible simulations \\nbeta0.true <- 1    ## true parameters, intercept\\nbeta1.true <- 2     ## and slope\\n## observed x values:\\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\n## simulation of y values:\\ny <- x+rnorm(15,0,2)\\n\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\n# Use formulas from the script\\nbeta1.hat <- (x - x.mean)*(y - y.mean)/(x - x.mean)^2\\nbeta0.hat <- y.mean - beta1.hat*x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor, \\n     Spearman_correlation_coefficients = spearman_cor,\\n\\t beta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'rubrics': [], 'modelSolution': 'set.seed(5)         \\nbeta0.true <- 1     \\nbeta1.true <- 2     \\nx <- c(2.9, 6.7, 8.0, 3.1, 2.0, 4.1, 2.2, 8.9,\\n       8.1, 7.9, 5.7, 1.6, 6.6, 3.0, 6.3) \\ny <- beta0.true + beta1.true * x + rnorm(n = 15, mean = 0, sd = 2)\\n\\ndata <- data.frame(x = x, y = y)   \\n\\nplot(data)\\npearson_cor <- cor(x, y, method = \"pearson\")\\nspearman_cor <- cor(x, y, method = \"spearman\")\\n\\nx.mean <- mean(x)\\ny.mean <- mean(y)\\n\\nbeta1.hat <- sum((x-x.mean) * (y-y.mean)) / sum((x-x.mean)^2)\\nbeta0.hat <- y.mean - beta1.hat * x.mean\\n\\nsol <- list(Pearson_correlation_coefficients = pearson_cor,\\n            Spearman_correlation_coefficients = spearman_cor,\\n\\t\\t\\tbeta1_hat = beta1.hat, beta0_hat = beta0.hat)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "Statistics Set: Average Accuracy with added solutions: 72.00%\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:23:36.718015Z",
     "start_time": "2025-01-05T11:22:41.153282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mat_tracker, mat_accuracy, mat_logs = parallel_evaluate(evaluation_data_mat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True)\n",
    "print(f\"Maths Set: Average Accuracy with added solutions: {mat_accuracy:.2%}\")"
   ],
   "id": "c54b0ab0d7b821b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating batch...\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b398378ca3354a2b81c324c28103e4b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8de5d971ebc4bfdbeea1889f665f42c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "603dacad861e43e1887ef63739f95753"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "966e9b79085245e8b6be8ace417107f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': \"The sum of two independent normally distributed random variables is another normally distributed random variable. We will visualize this with some normally distributed samples. To this end, generate two samples, each with size $3000$, of the form\\n\\n* $X\\\\sim N(65, 30)$,\\n\\n* $Y\\\\sim N(35, 11)$,\\n\\nwhere (unlike in R!) the second parameter we list is the variance, i.e. $N(\\\\mu, \\\\sigma^2)$.\\nAdd these two samples to generate a single sample $V$. To check if $V$ is also normally distributed, use a quantile-quantile-plot and a histogram. Don't forget to write down what you conclude!\\n\\nTip: Do you still remember the functions $hist()$, $qqnorm()$, and $qqline()$?\\n\\n\", 'answer': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean = 65, sd = sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean = 35, sd = sqrt(11))\\nV <- X+Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(X, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"Die Summe von zwei unabhängigen normalverteilten Zufallsvariablen ist tatsächlich eine weitere Zufallsvariable ist, wie sowohl das QQ-Diagramm als auch das Histogramm zeigen.\"\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"The sample V=X+Y seems to still follow a theoretical\\n  normal distribution. The points are overall distributed along the line\\n  of the theoretical quantiles. We also note that the expectations add up,\\n  i.e. E[V] = E[X] + E[Y]. (In fact the variances also add up, but this is\\n  not so obvious from the plot.)\"\\n\\t\\ndev.off()\\n\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Vergleichen Sie die Histogramme der vier stetigen Variablen miteinander. Plotten Sie die Histogramme; verwenden Sie überall den gleichen Abschnitt der $x$-Achse. Kommentieren Sie das Resultat und vergleichen Sie es mit dem Boxplot.\\n\\nTipps:\\nMit R Markdown können Sie mehrere Plots in einem Codeabschnitt generieren. Verwenden Sie die Hilfe für die Funktion $hist()$ und das Argument $xlim$;\\n\\n$hist(..., xlim ...)$.\\n', 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\n\\nhist(iris$Sepal.Length, main=\"Sepal.Length\", xlab=\"Sepal.Length\", xlim=c(0, 8))\\nhist(iris$Sepal.Width, main=\"Sepal.Width\", xlab=\"Sepal.Width\", xlim=c(0, 8))\\nhist(iris$Petal.Length, main=\"Petal.Length\", xlab=\"Petal.Length\", xlim=c(0, 8))\\nhist(iris$Petal.Width, main=\"Petal.Width\", xlab=\"Petal.Width\", xlim=c(0, 8))\\n\\ntext_response <- \"The results of the histograms are consistent with the results of the boxplot.\"\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\nhist(iris[,1], main=\"\", xlab=\"Variable 1\", xlim=c(0, 8))\\nhist(iris[,2], main=\"\", xlab=\"Variable 2\", xlim=c(0, 8))\\nhist(iris[,3], main=\"\", xlab=\"Variable 3\", xlim=c(0, 8))\\nhist(iris[,4], main=\"\", xlab=\"Variable 4\", xlim=c(0, 8))\\n\\ntext_response <- \"Variables 1 and 2 (sepal length and sepal width) each have a unimodal distribution (they form a single \\'heap\\' so to speak). Variables 3 and 4 are bimodal! This difference was not obvious from the boxplots.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nAre the events A and B stochastically independent? Justify your answer by comparing $P[A \\\\cap B]$ with $P[A] \\\\cdot P[B]$.\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[dat$ht >=170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[dat$size >=8, ]) / nrow(dat)\\nprob_A_prob_B <- prob_A * prob_B\\n\\nprob_A_and_B <- nrow(dat[dat$ht >= 170 & dat$size >= 8, ]) / nrow(dat)\\n\\nsol <- list( pApB = prob_A_prob_B, pAandB = prob_A_and_B, \\n    A_und_B_sind = \"abhängig\" # falsche Antwort hier löschen\\n    )\\n\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_prob_B <- prob_A * prob_B\\n\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nsol <- list( pApB = prob_A_prob_B, pAandB = prob_A_and_B, \\n    A_und_B_sind = \"abhängig\"\\n    )\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Which are the 'ht' for shoe sizes in the range $[5,6.5]$ (corresponding to EU shoe sizes 36-39)? And how many are there?\\n\", 'answer': 'dat<-read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header = TRUE)\\nht<-dat$ht\\nsize<- dat$size\\nsize_565<-ht[size>=5 & size <=6.5]\\n\\nsol <- list(ht = size_565, anzahl = length(size_565))\\nsol', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsize <- dat$size\\nht <- dat$ht\\nsize_565 <- ht[size>=5 & size<=6.5]\\nsol <- list(ht = size_565, anzahl = length(size_565))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"What are the names of the three categories of the variable 'Species'?\\nUse the function $summary()$.\\n\", 'answer': 'data(iris)\\nsummary(iris$Species)\\ntext_response <- \"setosa, versicolor, virgincia\"', 'rubrics': [], 'modelSolution': 'data(iris)\\nsummary(iris$Species)\\ntext_response <- \"setosa, versicolor, virginica\"', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Which are the 'ht' for shoe sizes in the range $[5,6.5]$ (corresponding to EU shoe sizes 36-39)? And how many are there?\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\nht <- dat[dat$size>=5 & dat$size<=6.5, ]\\nsize <- ht$ht\\nsize_565 <- length(size)\\n\\nsol <- list(ht = size, anzahl = size_565)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsize <- dat$size\\nht <- dat$ht\\nsize_565 <- ht[size>=5 & size<=6.5]\\nsol <- list(ht = size_565, anzahl = length(size_565))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Heidi and Peter are curious how many buttercups grow on the alp. They take 10 samples by marking out 10 different 1m$^2$ areas of land, and counting the buttercups in each one:\\n\\n580, 331, 493, 525, 420, 522, 468, 594, 347, 586.\\n\\nAssume that the number of buttercups per square meter is normally distributed (i.e. we are using a continuous distribution to model a discrete one) and that the samples are independent of each other.\\n\\nCompute a 99\\\\% confidence interval for the expectation $\\\\mu$. Give the estimated variance as well.\\n', 'answer': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nxquer <- mean(counts)\\nsigma <- sd(counts)\\nvarianz <- var(counts)\\n\\nt <- qt(0.995, df = n-1)\\nCI <- c(xquer - t * sigma/ sqrt(n), xquer + t * sigma/ sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\n\\n', 'rubrics': [], 'modelSolution': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nxquer <- mean(counts)\\nsigma <- sd(counts)\\nvarianz <- sigma^2\\n\\nt <- qt(0.995,n-1)\\nCI <- c(xquer - t*sigma/sqrt(n), xquer + t*sigma/sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Practice assigning a value, or multiple values, to $objects$ in R. \\nCreate a variable '$z$' with value 5 and a vector '$s$' containing the integers -2 to 5. \\nMultiply '$z$' with '$s$' and check the result.\\nAccess the '$z$'-th entry of '$s$'.\\n\\nHint: Sequences of numbers can be created with a '$:$', for example, '$1:4$' results in a vector $(1, 2, 3, 4)$. Alternatively the function '$seq()$' may be used, see the help for details.\\n\", 'answer': 'z <- 5\\ns <- c(-2:5)\\nmlt <- z*s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\n\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)\\nprint (sol)', 'rubrics': [], 'modelSolution': 'z <- 5\\ns <- -2:5 # oder: s <- seq(-2,5)\\nmlt <- z*s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Calculate $P[|X-E(X)|>2\\\\sigma]$ for a normally distributed random variable $X\\\\sim N(24,24)$ by simplifying the expression first in such a way that you can finish the computation in R.\\n', 'answer': 'mu <- 24\\nsigma <- sqrt(24)\\n\\nupper <- mu + 2*sigma\\nlower <- mu - 2*sigma\\nP <- 1 - (pnorm(upper,mu,sigma) - pnorm(lower,mu,sigma))\\n\\nsol <- list(Wahrscheinlichkeit\\xa0=\\xa0P)\\n\\n', 'rubrics': [], 'modelSolution': '# first, note that E[X] = mu. I\\'ll use s in place of sigma here simply\\n# because it\\'s easier to type...\\n\\n# With complementary probability:\\n# P[ |X - E[X]| > 2s ] = 1 - P[ |X - E[X]| < 2s ]\\n#                      = 1 - P[ -2s < X - mu < 2s ]\\n#                      = 1 - P[ mu-2s < X < mu+2s ]\\n#                      = 1 - ( P[ X < mu+2s ] - P[ X < mu-2s ] )\\n#                      = 1 - (   \"upper\"      -    \"lower\"     )\\n# If you reached this in a different way, it\\'s also ok of course!\\n\\nmu <- 24\\nsigma <- sqrt(24)\\n\\nupper <- pnorm(mu + 2*sigma, mean=mu, sd=sigma)\\nlower <- pnorm(mu - 2*sigma, mean=mu, sd=sigma)\\nP <- 1 - (upper - lower)\\n\\nsol <- list(Wahrscheinlichkeit = P)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Return all shoe sizes from the 'shoe' dataset for an 'ht' greater than $190$. To do this, apply an appropriate condition to the column 'size'.\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nht <- dat$ht\\nsize_190 <- dat$size[dat$ht>190]\\n\\nsol <- list(Schuhgroessen = size_190)\\nsol', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nht <- dat$ht\\nsize_190 <- dat$size[ht>190]\\nsol <- list(Schuhgroessen = size_190)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nCompute the conditional probability $P[A|B]$ directly as follows: Start by making a data frame of all the rows which satisfy the condition B, and save this as $b$. Then within this reduced sample space, compute the probability $P[A]$.\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[dat$size>=8,]\\nprob_A_given_B <- nrow(dat[dat$ht>=170,]) / nrow(b) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )\\nprint(sol)\\n\\n\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[ dat$size >= 8, ]\\nprob_A_given_B <- nrow( b[b$ht >= 170 , ] ) / nrow(b) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'As you did in Worksheet 1, load the dataset \\'shoe.dat\\' from the internet. This contains the height, weight, and shoe size of 403 American students:\\n\\n$dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)$\\n\\nConsider the random experiment \"a person is randomly chosen from the shoe-dataset\" along with the events\\n\\n$A:$ ``The person\\'s height is $\\\\geq 170$ cm\\'\\'\\n\\n$B:$ ``The person\\'s shoe size is $\\\\geq 8$\\'\\' (corresponds to EU shoe size ~41)\\n\\nCompute $P[A]$, $P[B]$, and $P[A \\\\cap B]$ by applying suitable conditions to the columns \\'dat\\\\$size\\' and \\'dat\\\\$ht\\'.\\n\\nTip: Use the function $nrow()$ to find the number of rows in a data frame. You can combine this cleverly with some applied conditions, e.g. \\'nrow(v[v\\\\$ht>0 , ])\\' gives the number of entries (rows) in the dataset $v$ which satisfy the condition \\'v\\\\$ht > 0\\'. (The empty argument after the comma would be the column.)\\n\\n', 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht>=170 , ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[dat$size>=8,])/nrow(dat)\\nprob_A_and_B <- nrow(dat[dat$ht>=170 & dat$size>=8,])/nrow(dat)\\n\\nsol <- list( pA = prob_A, pB = prob_B, pAandB = prob_A_and_B )\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nsol <- list( pA = prob_A, pB = prob_B, pAandB = prob_A_and_B )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this exercise we will use various samples generated from random variables. If you calculate statistical key figures in R from these samples, you will get the sample variance $s^2$ instead of the theoretical variance $V[X]$ of the distribution, and the sample mean $\\\\overline{x}$ instead of the theoretical mean $E[X]$. The corresponding functions are $var()$ resp. $mean()$.\\n\\nGenerate two samples of size $n_X=400$ and $n_Y=400$ from normally distributed random variables $X\\\\sim\\\\mathcal{N}(\\\\mu, 9)$ and $Y\\\\sim\\\\mathcal{N}(\\\\mu/3, 4)$. Use $\\\\mu=57$.\\n\\nNow compute mean$(aX+bY)$ for $a=-4$ and $b=3$ and compare your result with $a\\\\cdot$mean$(X)+b\\\\cdot$mean$(Y)$. \\n\\nTip: Recall that normally distributed random samples can be generated using $rnorm()$.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu,sd=sqrt(9)) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400,mean=mu/3,sd=sqrt(4))\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X+b+Y)\\nmean_x_y <- a*mean(X)+b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\nsol', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu, sd=3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean=mu/3, sd=2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We\\'ve gotten to know the plot functions $boxplot()$ and $hist()$ in earlier exercises. The generic function to display data as well as functions graphically is $plot()$. It creates a scatterplot of two vectors, which represent the x- and y-coordinates respectively of the points to plot.\\n\\nA plot is only informative if the axes are labeled accordingly! This can be done with the arguments $xlab$ and $ylab$. It\\'s also often helpful to add a title; you can do this by using the argument $main$.\\n\\nThe way a function is represented can be determined with the argument $type$. Often, the data are plotted with points ($type=\"p\"$) or with lines ($type=\"l\"$). You can find a complete list of values for $type$ with the command $?plot$; some examples are also there.\\nYou can also use color in your plots by directly setting the argument $col$, e.g. $col=\"red\"$. You can find a list of all possible values with $?colors$.\\n\\nThere are many other arguments which modify the way plots are displayed. You can get an overview over all these arguments with $?par$ or with $help.search(\"par\")$. \\n\\nHere is an example on the right: have some fun with this code, play around with all the options. Change the colors, line types, title, add some axis descriptions...  Or are these two curves a bit blocky-looking to you? Then take a larger number of points, i.e. in line 2 reduce the step length to get a smoother approximation.\\n\\nWhen you\\'re through, choose \"Reset\" at the far right (to restore the original code) and then simply do \"Submit\".\\n', 'answer': 'png(file = \"solution.png\")\\nx <- seq(0, 1.5, 0.3)  # x-Werte zwischen 0 und 1.5 (in Schritten der Länge 0.3)\\ny <- x^2 # Zugehörige y-Werte für die Quadratfunktion\\n# Plotte x gegen y als gepunktete (lty=\"dotted\") Linie (type=\"l\")\\nplot(x, y, lty=\"dotted\", type=\"l\",main=\"Zwei Potenzfunktionen\") \\n# Füge Wurzelfunktion als schokoladefarbene gestrichelte (\"dashed\") Kurve hinzu\\nz<-sqrt(x)\\nlines(x,z,lty=\"dashed\",col=\"chocolate3\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nx <- seq(0, 1.5, 0.3)  # x-Werte zwischen 0 und 1.5 (in Schritten der Länge 0.3)\\ny <- x^2 # Zugehörige y-Werte für die Quadratfunktion\\n# Plotte x gegen y als gepunktete (lty=\"dotted\") Linie (type=\"l\")\\nplot(x, y, lty=\"dotted\", type=\"l\",main=\"Zwei Potenzfunktionen\") \\n# Füge Wurzelfunktion als schokoladefarbene gestrichelte (\"dashed\") Kurve hinzu\\nz<-sqrt(x)\\nlines(x,z,lty=\"dashed\",col=\"chocolate3\")\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the video ``Creature-Cast: the Central Limit Theorem'' on YouTube \\n( [https://www.youtube.com/watch?v=jvoxEYmQHNM](https://www.youtube.com/watch?v=jvoxEYmQHNM) ).\\n\\nWe will reproduce both examples from this video and plot the corresponding density functions for different sample sizes. Please note that in the lecture we looked at the sum of i.i.d. random variables and saw how this sum approaches a normally distributed variable for increasing $n$. The same is true for the arithmetic mean $\\\\overline{X}$ - after all, to find the mean you first consider a sum and then divide by $n$.\\n\\nPlot the histogram of the weight distribution of the rabbits, with reasonable labels for the data. Add a density function to your histogram - please do this for all the histograms in this worksheet!\\n\\nTip: \\nFollow these steps:\\n\\n- Generate a sample from the population of all rabbits in R: \\n\\n$set.seed(24)$\\n\\n$rabbits <- rnorm(100000, mean=5.25, sd=1.625)$\\n\\nIn this way, you create an object called 'rabbits' with the weights in kg of 100,000 rabbits (we assume the weights to be normally distributed). The command $set.seed()$ ensures that we all get the same data set.\\n \\n- In order to better see the shape of the histogram, it's customary to add the graph of a density estimation to the plot. This can be done in R without much additional effort:\\n\\n$hist(???, freq=FALSE)$\\n\\n$lines(density(???, bw=1/3), col=..., lwd=...)$\\n\\nHere we use $bw=1/3$ for a nice-looking curve. You can read more about the meaning of this argument in the online help in RStudio, just type $?density$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(100000, mean = 5.25, sd = 1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density(rabbits, bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n\\n# Anmerkung:\\n# Wir merken, dass die angenommene Normalverteilung nicht ganz realistisch ist, \\n# denn einige wenige Kaninchen müssten negative Gewichte haben. Um eine physikalisch\\n# sinnvollere Verteilung zu erzeugen, könnten wir zum Beispiel den Befehl \\n# \\'rabbits[rabbits<1] <- 1\\' verwenden - alle Kaninchen, die laut Normalverteilung \\n# weniger als 1kg haben sollen, werden auf 1kg aufgerundet. Die daraus resultierende \\n# Verteilung wäre zwar nicht mehr normalverteilt - aber dafür bestimmt etwas \\n# realistischer! Der Aufgabenstellung zufolge werden wir hier doch bei einer \\n# Normalverteilung bleiben.\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(100000, mean=5.25, sd=1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density(rabbits, bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Determine the range of the second variable in the dataset ’iris’. Check if the two values\\ncorrespond to the minimum and maximum.\\n', 'answer': 'data(iris)\\n\\nwerteber <- range(iris$Sepal.Width)\\nminimum <- min(iris$Sepal.Width)\\nmaximum <- max(iris$Sepal.Width)\\n\\nsol <- list(Wertebereich = werteber, \\n    Minimum = minimum, \\n    Maximum = maximum, Werte = \"stimmen überein\")\\nsol', 'rubrics': [], 'modelSolution': 'data(iris)\\nwerteber <- range(iris[,2])\\nminimum <- min(iris[,2])\\nmaximum <- max(iris[,2])\\nsol <- list(Wertebereich = werteber, Minimum = minimum, Maximum = maximum, Werte = \"stimmen überein\")', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Return all shoe sizes from the 'shoe' dataset for an 'ht' greater than $190$. To do this, apply an appropriate condition to the column 'size'.\\n\\n\", 'answer': 'dat <- read.table(\"https://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nht <- dat[, 1]\\n\\nsize_190 <- dat$size[dat$ht>190]\\n\\nsol <- list(Schuhgroessen = size_190)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nht <- dat$ht\\nsize_190 <- dat$size[ht>190]\\nsol <- list(Schuhgroessen = size_190)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The sum of two independent normally distributed random variables is another normally distributed random variable. We will visualize this with some normally distributed samples. To this end, generate two samples, each with size $3000$, of the form\\n\\n* $X\\\\sim N(65, 30)$,\\n\\n* $Y\\\\sim N(35, 11)$,\\n\\nwhere (unlike in R!) the second parameter we list is the variance, i.e. $N(\\\\mu, \\\\sigma^2)$.\\nAdd these two samples to generate a single sample $V$. To check if $V$ is also normally distributed, use a quantile-quantile-plot and a histogram. Don't forget to write down what you conclude!\\n\\nTip: Do you still remember the functions $hist()$, $qqnorm()$, and $qqline()$?\\n\\n\", 'answer': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\nn <- 3000\\nX <- rnorm(3000, mean = 65, sd = sqrt (30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean = 35, sd = sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(X, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"Das Histogramm sieht immernoch normalverteilt aus\"\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"The sample V=X+Y seems to still follow a theoretical\\n  normal distribution. The points are overall distributed along the line\\n  of the theoretical quantiles. We also note that the expectations add up,\\n  i.e. E[V] = E[X] + E[Y]. (In fact the variances also add up, but this is\\n  not so obvious from the plot.)\"\\n\\t\\ndev.off()\\n\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Start with the code of the previous task. Now let's accentuate the 43rd iris flower by marking it differently on your scatterplot. Use the color 'magenta', give the point a square shape (the argument $pch=15$), and draw it in a slightly larger size than the others (the argument $cex=1.5$), in order to make this point stand out. Add this marking to the legend as well, with the label '43-te'.\\n\\nTip: As before, use the function $points()$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\tdata(iris)\\n\\n\\tn <- 43\\n\\tplot(\\n\\t\\tiris$Sepal.Width, \\n\\t\\tiris$Petal.Width, \\n\\t\\txlab=\"Breite Kelchblatt [mm]\",\\n\\t\\tylab=\"Breite Blütenblatt [mm]\",\\n\\t\\tmain=\"Breite der Irisblumenblätter\", \\n\\t\\tcol=iris$Species, \\n\\t\\tpch=16\\n\\t)\\n\\tpoints(\\n\\t\\tiris$Sepal.Width[n], \\n\\t\\tiris$Petal.Width[n], \\n\\t\\tcol= \"magenta\", \\n\\t\\tcex= 1.5, \\n\\t\\tpch= 15\\n\\t)\\n\\tlegend(\"topright\", legend=c(levels(iris$Species), \"43-te\"), \\n     col=c(1:3, \"magenta\"), pch=c(16,16,16,15 ))\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\nn <- 43\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n     ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", \\n     col=iris$Species, pch=16)\\npoints(iris$Sepal.Width[n], iris$Petal.Width[n], col=\"magenta\", cex=1.5, pch=15)\\nlegend(\"topright\", legend=c(levels(iris$Species), \"43-te\"), \\n     col=c(1:3, \"magenta\"), pch=c(16,16,16,15))\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In order to obtain a robust measure for the mean of sepal length, we want to calculate the 'trimmed mean', i.e. excluding 10% of the observations on each end of the value range. What do you notice when you compare this result with the original mean?\\n\\nTip: Check the help for the function $mean()$ and the argument $trim$, something like this:\\n\\n$mean(..., trim=...)$.\\n\", 'answer': 'data(iris)\\n\\nmean_trimmed <-mean(iris$Sepal.Length)\\nprint(mean_trimmed)\\nmean_original <-mean(iris$Sepal.Length)\\nprint(mean_original)\\ntext_response <- \"Der gestutzte Mittelwert und der originale Mittelwert unterscheiden sich nicht\"\\n\\nsol <- list(gestutzter_Mittelwert = mean_trimmed, Mittelwert = mean_original)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'data(iris)\\nmean_trimmed <- mean(iris$Sepal.Length, trim=0.1) # trimmed\\nmean_original <- mean(iris$Sepal.Length) # original\\ntext_response <- \"The trimmed mean is a little lower than the original mean. It looks like there are more outliers on the upper side than on the lower side, these would have the effect of shifting the untrimmed mean higher.\"\\nsol <- list(gestutzter_Mittelwert = mean_trimmed, Mittelwert = mean_original)\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Plot the boxplot of all continuous variables.\\n\\nNow access the 73-rd line in the 'iris' dataset and compare those values with the boxplot. Does the\\n73-rd iris flower have relatively long or short sepals, relatively wide or narrow ones?\\n\\nTips: The first four variables from the dataset 'iris' can be accessed by $iris[, 1 : 4]$.\\n\\nAfter you have created the boxplot, in the same code chunk you can use the function $points()$ to\\ndraw some additional points. With the argument $pch = 17$ these points are displayed as triangles.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- iris[1:4]\\nboxplot(n, main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, n[73, 1:4], pch=17)\\n\\nsol <- list(Length = \"gross\"/\"klein\", # falsche Antwort hier löschen!\\n            Width = \"breit\"/\"schmal\" # falsche Antwort hier löschen!\\n)\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- 73\\nboxplot(iris[,1:4], main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, iris[n,1:4], pch=17)\\n\\nsol <- list(Length = \"gross\", Width = \"schmal\")\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Plot the boxplot of all continuous variables.\\n\\nNow access the 73-rd line in the 'iris' dataset and compare those values with the boxplot. Does the\\n73-rd iris flower have relatively long or short sepals, relatively wide or narrow ones?\\n\\nTips: The first four variables from the dataset 'iris' can be accessed by $iris[, 1 : 4]$.\\n\\nAfter you have created the boxplot, in the same code chunk you can use the function $points()$ to\\ndraw some additional points. With the argument $pch = 17$ these points are displayed as triangles.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- 73\\nboxplot(iris, main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, n, pch=17)\\n\\nsol <- list(Length = \"gross\", # falsche Antwort hier löschen!\\n    Width = \"schmal\" # falsche Antwort hier löschen!\\n    )\\n    \\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- 73\\nboxplot(iris[,1:4], main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, iris[n,1:4], pch=17)\\n\\nsol <- list(Length = \"gross\", Width = \"schmal\")\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Create some random samples of sizes $n=\\\\{10, 1000, 100\\\\,000\\\\}$ from a random variable $X\\\\sim \\\\mathcal{N}(60, 9)$ and plot each sample in a histogram. As you do, reduce the bin width successively, from $2$ to $1$ to $0.5$. What do you observe?\\n\\n\\nTip: To make a histogram with a fixed bin width, use the function $hist()$ with the argument $breaks=...$. You will need to create a vector of the desired breakpoints between bins, e.g. from $\\\\mu - 6 \\\\sigma$ to $\\\\mu + 6\\\\sigma$ in steps of the desired bin width:\\n\\n$hist(..., freq=FALSE, breaks = seq(..., ..., ...) )$\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean = mu, sd = sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean = mu, sd = sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean = mu, sd = sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"Je kleiner die Klassenbreite und je mehr Daten vorhanden, desto ähnlicher ist die Verteilung einer Normalverteilung\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"The larger the sample, the more closely the histogram resembles\\n      the density function f_X(x) from Task 1.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Start with the code of the previous task. Now let\\'s color the points of the scatterplot according to the variable $species$. Color the species \\'setosa\\' with the color code 1, \\'versicolor\\' with color code 2, and \\'virginica\\' with the color code 3. In the upper right corner of the graph, introduce a legend with the same order of species. Comment on the resulting plot.\\n \\nTips: You can also just assign a factor to the argument $col=$, e.g. with \\'col=iris\\\\$Species\\'. Then R will simply assign color codes 1, 2, 3, $\\\\dots$ to the factor levels.\\n\\nUse the function $legend()$ to give your plot a suitable legend:\\n$legend(\"topright\", legend=..., col=..., pch=16)$\\n\\nTake care that the colors and species in the legend match those in the plot!\\n', 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\nplot(\\n\\tiris$Sepal.Width, \\n\\tiris$Petal.Width, \\n\\txlab=\"Breite Kelchblatt [mm]\", \\n\\tylab=\"Breite Blütenblatt [mm]\", \\n\\tmain=\"Breite der Irisblumeblätter\", \\n\\tcol=iris$Species,\\n\\tpch=\"16\")\\n\\t\\n\\tlegend(\"topright\", legend=levels(iris$Species), col=1:3, pch=16)\\ntext_response <- \"Die Spezie Setosa hat breite Kelchblätter und schmale Blütenblätter. Die anderen zwei Spezien haben breite Blütenblätter und eher schmale Kelchblätter, wobei die Spezie Virginica noch breitere Blütenblätter als die Spezie versicolor hat.\"\\ndev.off()\\ntext_response', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(\"iris\")\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n     ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", \\n     col=iris$Species, pch=16)\\nlegend(\"topright\", legend=levels(iris$Species), col=1:3, pch=16)\\ntext_response <- \"The flowers of I. setosa have wide sepals and narrow petals. The other group\\n     consists of the two species versicolor and virginica; these are similar but there is a tendency\\n     for I. versicolor to have narrower petals.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The sum of two independent normally distributed random variables is another normally distributed random variable. We will visualize this with some normally distributed samples. To this end, generate two samples, each with size $3000$, of the form\\n\\n* $X\\\\sim N(65, 30)$,\\n\\n* $Y\\\\sim N(35, 11)$,\\n\\nwhere (unlike in R!) the second parameter we list is the variance, i.e. $N(\\\\mu, \\\\sigma^2)$.\\nAdd these two samples to generate a single sample $V$. To check if $V$ is also normally distributed, use a quantile-quantile-plot and a histogram. Don't forget to write down what you conclude!\\n\\nTip: Do you still remember the functions $hist()$, $qqnorm()$, and $qqline()$?\\n\\n\", 'answer': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X+Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(X, prob=TRUE, col=\"orange\")\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"The sample V=X+Y seems to still follow a theoretical\\n  normal distribution. The points are overall distributed along the line\\n  of the theoretical quantiles. We also note that the expectations add up,\\n  i.e. E[V] = E[X] + E[Y]. (In fact the variances also add up, but this is\\n  not so obvious from the plot.)\"\\n\\t\\ndev.off()\\n\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Practice assigning a value, or multiple values, to $objects$ in R. \\nCreate a variable '$z$' with value 5 and a vector '$s$' containing the integers -2 to 5. \\nMultiply '$z$' with '$s$' and check the result.\\nAccess the '$z$'-th entry of '$s$'.\\n\\nHint: Sequences of numbers can be created with a '$:$', for example, '$1:4$' results in a vector $(1, 2, 3, 4)$. Alternatively the function '$seq()$' may be used, see the help for details.\\n\", 'answer': 'z <- 5\\ns <- -2:5\\nmlt <- z * s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\n\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'z <- 5\\ns <- -2:5 # oder: s <- seq(-2,5)\\nmlt <- z*s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Now let's turn to the example with the dragons.\\n\\nThis example shows that even when we start with really distributions (uniform distribution in the lecture, or bimodal in this exercise), thanks to the CLT a normal distribution emerges in the end.\\n\\nWe generate a bimodal population of the different dragons according to the following: create a random vector $D_1$ of length 50,000 with $D_1\\\\sim N(5,2)$-distribution, which describes the wingspan of the dragon subpopulation 'Draconis breves pinnae', and another random vector $D_2\\\\sim N(14, 10)$ with the same length, which describes the subpopulation 'D. lata quadrupes'. \\nWe combine the two vectors into a single longer one with the function $c()$.\\n\\nPlot the bimodal population of dragon wingspans. Label your plot as shown and once again add an estimated density function.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\t\\nD_1 <- rnorm(50000,mean=5,sd=sqrt(2))\\nD_2 <- rnorm(50000,mean=14,sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\t\\nhist(\\n\\tdragons, \\n\\tmain=\"Flügelspannweite\", \\n\\tcol=\"lightgreen\",\\n\\txlab=\"Flügelspannweite [m]\", \\n\\tfreq=FALSE\\n)\\nlines(density(dragons, bw=2), col=\"red\", lwd=2)\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\t\\nD_1 <- rnorm(50000, mean=5, sd=sqrt(2))\\nD_2 <- rnorm(50000, mean=14, sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\t\\nhist(\\n\\tdragons, \\n\\tmain=\"Flügelspannweite\", \\n\\tcol=\"lightgreen\",\\n\\txlab=\"Flügelspannweite [m]\", \\n\\tfreq=FALSE\\n)\\nlines(density(dragons, bw=2), col=\"red\", lwd=2)\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Peter is not happy with this interval from part 1, he says it\\'s too broad. \"Can\\'t we get a closer estimate of the true expectation - say, an interval of length 80?\" \"Yes,\" answers Heidi, \"but with lower confidence.\"\\n\\nCompute the confidence level for this new interval with its prescribed length.\\nOur $t$-table does not have enough entries, so use R to solve this.\\n\\nHere again are the sample numbers:\\n\\n580, 331, 493, 525, 420, 522, 468, 594, 347, 586.\\n\\n', 'answer': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\n\\nCV_t <- 40*sqrt(n)/(sd(counts))\\nalpha_half <- 1-pt(CV_t,n-1)\\nconf <- 1- 2*alpha_half\\n\\nsol <- list(Konfidenzlevel = conf)\\nsol', 'rubrics': [], 'modelSolution': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nCV_t <- 40*sqrt(n)/(sd(counts))\\nalpha_half <- 1-pt(CV_t, n-1)\\nconf <- 1 - 2*alpha_half\\n\\nsol <- list(Konfidenzlevel = conf)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'As you did in Worksheet 1, load the dataset \\'shoe.dat\\' from the internet. This contains the height, weight, and shoe size of 403 American students:\\n\\n$dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)$\\n\\nConsider the random experiment \"a person is randomly chosen from the shoe-dataset\" along with the events\\n\\n$A:$ ``The person\\'s height is $\\\\geq 170$ cm\\'\\'\\n\\n$B:$ ``The person\\'s shoe size is $\\\\geq 8$\\'\\' (corresponds to EU shoe size ~41)\\n\\nCompute $P[A]$, $P[B]$, and $P[A \\\\cap B]$ by applying suitable conditions to the columns \\'dat\\\\$size\\' and \\'dat\\\\$ht\\'.\\n\\nTip: Use the function $nrow()$ to find the number of rows in a data frame. You can combine this cleverly with some applied conditions, e.g. \\'nrow(v[v\\\\$ht>0 , ])\\' gives the number of entries (rows) in the dataset $v$ which satisfy the condition \\'v\\\\$ht > 0\\'. (The empty argument after the comma would be the column.)\\n\\n', 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[dat$ht>=170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[dat$size>=8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[dat$ht>=170 & dat$size>=8, ]) / nrow(dat)\\n\\nsol <- list( pA = prob_A, pB = prob_B, pAandB = prob_A_and_B )\\n\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nsol <- list( pA = prob_A, pB = prob_B, pAandB = prob_A_and_B )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Similarly, check the 2nd remark to lemma 5.4, i.e. $sd[aY]=|a|\\\\cdot sd[Y]$, for the random variable $Y$ from part 1.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nY <- rnorm(400, mean = mu/3, sd = sqrt(4)) # rnorm braucht SD, nicht Varianz!\\na <- -4\\nb <- 3\\n\\nsd1 <- sd(a*Y)\\nsd2 <- abs(a)*sd(Y)\\n\\nsol <- list(linke_Seite_der_Gleichung = sd1, rechte_Seite_der_Gleichung = sd2)\\nsol', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nY <- rnorm(400, mean=mu/3, sd=2) # rnorm braucht SD, nicht Varianz!\\na <- -4\\nb <- 3\\n\\nsd1 <- sd(a*Y)\\nsd2 <- abs(a)*sd(Y)\\n\\nsol <- list(linke_Seite_der_Gleichung = sd1, rechte_Seite_der_Gleichung = sd2)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nPlot the cumulative distribution function of $X$. Since cumulative distribution functions are defined from $-\\\\infty$ to $\\\\infty$, please indicate this by making a plot which shows 2 units to the left and right of the relevant domain.\\n\\nTips: Here you will need the functions $cumsum(...)$, $stepfun(...)$, $plot(...)$, and $points(...)$; take the opening example (Exercise 1) as a starting point. For $plot(...)$ use the argument $pch=16$ for solid points and $verticals=FALSE$ for a plot without vertical lines at the jumps; the argument $pch=1$ to the command $points(...)$ will give empty points.\\n', 'answer': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- ...(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- stepfun(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\n\\nWhat is the value of $a$? Compute it here in R.\\n\\nTip: go to R Studio and do $?sum$ to read the online help about $sum(...)$.\\n', 'answer': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1-sum(p, NA, na.rm = TRUE) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\nsol <- list(Wert = a)\\nsol\", 'rubrics': [], 'modelSolution': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1 - sum(p, na.rm=TRUE) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\nsol <- list(Wert = a)\\n\", 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this collection of exercises we use R to examine some important distributions. With the command $?Distributions$ you can get an overview of the distributions which are included in the R package 'stats'. It includes all the distributions discussed in the lecture; binomial (incl. Bernoulli), $\\\\chi^2$-, exponential distribution, etc.\\nIn the first four tasks we will take a closer look at a few of these distributions (see also the lecture notes, pp.100-112).\\n\\nTip: Always pay attention to the parameters! In particular the normal and geometric distributions are parametrised differently in R than in the lecture.\\n\\n\\nPlot the probability function of the following discrete distribution:\\n\\n* Geometric distribution, $X\\\\sim Ge(\\\\frac{1}{3})$,\\n\\nEx.: Number of attempts until the first success, with success probability $p=\\\\frac{1}{3}$; \\n    \\nTip: This distribution is defined differently in R: namely as the number of $\\\\it failures$ $\\\\it before$ the first success. So you will need to shift the graph: instead of $(x, \\\\texttt{dgeom(x, ...)})$ you should plot the points $(x+1, \\\\texttt{dgeom(x, ...)})$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\n## Geometrische Verteilung\\nx <- 0:10 # Anzahl Misserfolge (nicht Versuche)\\np <- 1/3\\ny <- (1-p)^(x) * p\\nplot(\\n\\tx+1, # x+1 sodass wir die Anzahl Versuche plotten\\n\\ty, \\n\\ttype=\"h\", \\n\\tlwd=5, \\n\\txlab=\"Anzahl Versuche\", \\n\\tylab=\"P[X=x]\",\\n\\tmain=\"Geometrisch, X~Ge(1/3)\", \\n\\tcol=\"green4\"\\n\\t)\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=1/p, lwd=2) # Erwartungswert (Anzahl Versuche)\\n\\nv <- 1/p\\n\\n# Erwartungswert +/- Standardabweichung (auch Anzahl Versuche):\\nabline(v=c(v - sqrt((1-p)/p^2), v + sqrt((1-p)/p^2)) , lty=2) \\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Geometrische Verteilung\\nx <- 0:10 # Anzahl Misserfolge (nicht Versuche)\\np <- 1/3\\ny <- dgeom(x, prob=p)\\nplot(x+1, y, type=\"h\", lwd=5, xlab=\"Anzahl Versuche\", ylab=\"P[X=x]\", \\n\\tmain=\"Geometrisch, X~Ge(1/3)\", col=\"green4\")\\n# x+1 sodass wir die Anzahl Versuche plotten\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=1/p, lwd=2) # Erwartungswert (Anzahl Versuche)\\n\\n# Erwartungswert +/- Standardabweichung (auch Anzahl Versuche):\\nabline(v=c(1/p-sqrt((1-p)/p^2), 1/p+sqrt((1-p)/p^2)), lty=2) \\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Vergleichen Sie die Histogramme der vier stetigen Variablen miteinander. Plotten Sie die Histogramme; verwenden Sie überall den gleichen Abschnitt der $x$-Achse. Kommentieren Sie das Resultat und vergleichen Sie es mit dem Boxplot.\\n\\nTipps:\\nMit R Markdown können Sie mehrere Plots in einem Codeabschnitt generieren. Verwenden Sie die Hilfe für die Funktion $hist()$ und das Argument $xlim$;\\n\\n$hist(..., xlim ...)$.\\n', 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\n\\nhist(iris[,1], main=NULL, xlab=\"Variable 1\", xlim=c(0, 8))\\nhist(iris[,2], main=\"\", xlab=\"Variable 2\", xlim=c(0, 8))\\nhist(iris[,3], main=\"\", xlab=\"Variable 3\", xlim=c(0, 8))\\nhist(iris[,4], main=\"\", xlab=\"Variable 4\", xlim=c(0, 8))\\n\\ntext_response <- \"Variables 1 and 2 (sepal length and sepal width) each have a unimodal distribution (they form a single \\'heap\\' so to speak). Variables 3 and 4 are bimodal! This difference was not obvious from the boxplots.\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\nhist(iris[,1], main=\"\", xlab=\"Variable 1\", xlim=c(0, 8))\\nhist(iris[,2], main=\"\", xlab=\"Variable 2\", xlim=c(0, 8))\\nhist(iris[,3], main=\"\", xlab=\"Variable 3\", xlim=c(0, 8))\\nhist(iris[,4], main=\"\", xlab=\"Variable 4\", xlim=c(0, 8))\\n\\ntext_response <- \"Variables 1 and 2 (sepal length and sepal width) each have a unimodal distribution (they form a single \\'heap\\' so to speak). Variables 3 and 4 are bimodal! This difference was not obvious from the boxplots.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Load the dataset \\'shoe.dat\\' from the internet and save it under the name $dat$. It contains the height (in cm), weight (in kg), and shoe size (US) of American students.\\n\\nHave a look at a summary of its contents.\\n  \\nTip: Use the functions $read.table()$ to read in the data and $summary()$ to look at it. The function $read.table()$ saves a table of data from a file into a data frame, which can be more easily analysed in R. The function $summary()$ returns a summary of the data. More information can be found in the R help!\\n\\nThe dataset is available at http://stat.ethz.ch/Teaching/Datasets/shoe.dat, but can be directly loaded in R:\\n\\n$dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)$\\n', 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\"\\n                  ,header=TRUE)\\nsmry <- summary(dat)\\n\\nsol <- list(Zusammenfassung = smry)', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsmry <- summary(dat)\\nsol <- list(Zusammenfassung = smry)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this collection of exercises we use R to examine some important distributions. With the command $?Distributions$ you can get an overview of the distributions which are included in the R package 'stats'. It includes all the distributions discussed in the lecture; binomial (incl. Bernoulli), $\\\\chi^2$-, exponential distribution, etc.\\nIn the first four tasks we will take a closer look at a few of these distributions (see also the lecture notes, pp.100-112).\\n\\nTip: Always pay attention to the parameters! In particular the normal and geometric distributions are parametrised differently in R than in the lecture.\\n\\n\\nPlot the probability function of the following discrete distribution:\\n\\n* Geometric distribution, $X\\\\sim Ge(\\\\frac{1}{3})$,\\n\\nEx.: Number of attempts until the first success, with success probability $p=\\\\frac{1}{3}$; \\n    \\nTip: This distribution is defined differently in R: namely as the number of $\\\\it failures$ $\\\\it before$ the first success. So you will need to shift the graph: instead of $(x, \\\\texttt{dgeom(x, ...)})$ you should plot the points $(x+1, \\\\texttt{dgeom(x, ...)})$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\n# Define the range of failures (not trials) and the probability of success\\nx <- 0:10\\np <- 1/3\\n\\n# Calculate the probability of experiencing x failures before the first success\\ny <- dgeom(x, p)\\n\\n# Plot the probability distribution of the number of trials (x+1) to get the first success\\nplot(x+1, y,\\n     type=\"h\", # Use \\'h\\' for histogram-like vertical lines\\n     lwd=5, # Set the line width\\n     xlab=\"Anzahl Versuche\", # Label for the x-axis\\n     ylab=\"P[X=x]\", # Label for the y-axis\\n     main=\"Geometrisch, X~Ge(1/3)\", # Main title\\n     col=\"green4\" # Color of the lines\\n)\\n\\n# Add axis labels for the x-axis\\naxis(1, at=x+1, labels=x+1)\\n\\n# Add a horizontal line at y=0\\nabline(h=0, lty=3)\\n\\n# Add a vertical line at the expected number of trials (1/p)\\nabline(v=1/p, lwd=2, col=\"blue\")\\n\\n# Add vertical lines for the expected number of trials +/- standard deviation\\n# The standard deviation for a geometric distribution is sqrt((1-p)/p^2)\\nsd <- sqrt((1-p)/p^2)\\nabline(v=c(1/p - sd, 1/p + sd), lty=2, col=\"red\")\\n\\ndev.off() # Close the PNG device', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Geometrische Verteilung\\nx <- 0:10 # Anzahl Misserfolge (nicht Versuche)\\np <- 1/3\\ny <- dgeom(x, prob=p)\\nplot(x+1, y, type=\"h\", lwd=5, xlab=\"Anzahl Versuche\", ylab=\"P[X=x]\", \\n\\tmain=\"Geometrisch, X~Ge(1/3)\", col=\"green4\")\\n# x+1 sodass wir die Anzahl Versuche plotten\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=1/p, lwd=2) # Erwartungswert (Anzahl Versuche)\\n\\n# Erwartungswert +/- Standardabweichung (auch Anzahl Versuche):\\nabline(v=c(1/p-sqrt((1-p)/p^2), 1/p+sqrt((1-p)/p^2)), lty=2) \\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this exercise we will use various samples generated from random variables. If you calculate statistical key figures in R from these samples, you will get the sample variance $s^2$ instead of the theoretical variance $V[X]$ of the distribution, and the sample mean $\\\\overline{x}$ instead of the theoretical mean $E[X]$. The corresponding functions are $var()$ resp. $mean()$.\\n\\nGenerate two samples of size $n_X=400$ and $n_Y=400$ from normally distributed random variables $X\\\\sim\\\\mathcal{N}(\\\\mu, 9)$ and $Y\\\\sim\\\\mathcal{N}(\\\\mu/3, 4)$. Use $\\\\mu=57$.\\n\\nNow compute mean$(aX+bY)$ for $a=-4$ and $b=3$ and compare your result with $a\\\\cdot$mean$(X)+b\\\\cdot$mean$(Y)$. \\n\\nTip: Recall that normally distributed random samples can be generated using $rnorm()$.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean = mu, sd = sqrt(9)) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean = mu, sd = sqrt(3.4))\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n\\nsol\\n', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu, sd=3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean=mu/3, sd=2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\nsol', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nNow compute the conditional probability $P[A|B]$ indirectly, with the help of the formula for conditional probability. Does the result match that of Exercise 2?\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[dat$ht>=170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[dat$size>=8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[dat$ht>=170 & dat$size>=8, ]) / nrow(dat)\\n\\nprob_A_given_B <- prob_A_and_B / prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n             Resultat = \"stimmt überein\")\\n\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nprob_A_given_B <- prob_A_and_B / prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n    Resultat = \"stimmt überein\"\\n    )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this exercise we will use various samples generated from random variables. If you calculate statistical key figures in R from these samples, you will get the sample variance $s^2$ instead of the theoretical variance $V[X]$ of the distribution, and the sample mean $\\\\overline{x}$ instead of the theoretical mean $E[X]$. The corresponding functions are $var()$ resp. $mean()$.\\n\\nGenerate two samples of size $n_X=400$ and $n_Y=400$ from normally distributed random variables $X\\\\sim\\\\mathcal{N}(\\\\mu, 9)$ and $Y\\\\sim\\\\mathcal{N}(\\\\mu/3, 4)$. Use $\\\\mu=57$.\\n\\nNow compute mean$(aX+bY)$ for $a=-4$ and $b=3$ and compare your result with $a\\\\cdot$mean$(X)+b\\\\cdot$mean$(Y)$. \\n\\nTip: Recall that normally distributed random samples can be generated using $rnorm()$.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean = mu, sd = 3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean =mu/3, sd = 2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu, sd=3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean=mu/3, sd=2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Practice assigning a value, or multiple values, to $objects$ in R. \\nCreate a variable '$z$' with value 5 and a vector '$s$' containing the integers -2 to 5. \\nMultiply '$z$' with '$s$' and check the result.\\nAccess the '$z$'-th entry of '$s$'.\\n\\nHint: Sequences of numbers can be created with a '$:$', for example, '$1:4$' results in a vector $(1, 2, 3, 4)$. Alternatively the function '$seq()$' may be used, see the help for details.\\n\", 'answer': 'z <- 5\\ns <- (-2:5) \\nmlt <- s*z # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\n\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'z <- 5\\ns <- -2:5 # oder: s <- seq(-2,5)\\nmlt <- z*s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nNow compute the conditional probability $P[A|B]$ indirectly, with the help of the formula for conditional probability. Does the result match that of Exercise 2?\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht>=170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size>=8, ]) / nrow(dat) \\nprob_A_and_B <- (prob_A * prob_B)/nrow(dat)\\nprob_A_given_B <- prob_A_and_B/prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n    Resultat = \"stimmt überein\" \\n    )\\n    print(sol)', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nprob_A_given_B <- prob_A_and_B / prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n    Resultat = \"stimmt überein\"\\n    )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Create some random samples of sizes $n=\\\\{10, 1000, 100\\\\,000\\\\}$ from a random variable $X\\\\sim \\\\mathcal{N}(60, 9)$ and plot each sample in a histogram. As you do, reduce the bin width successively, from $2$ to $1$ to $0.5$. What do you observe?\\n\\n\\nTip: To make a histogram with a fixed bin width, use the function $hist()$ with the argument $breaks=...$. You will need to create a vector of the desired breakpoints between bins, e.g. from $\\\\mu - 6 \\\\sigma$ to $\\\\mu + 6\\\\sigma$ in steps of the desired bin width:\\n\\n$hist(..., freq=FALSE, breaks = seq(..., ..., ...) )$\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean = mu, sd = sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean = mu, sd = sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean = mu, sd = sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"Mit der Zunahme von Stichproben und der Verkleinerung der Klassenbreite, ähnelt die Verteilung immer mehr einer Normalverteilung. \"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"The larger the sample, the more closely the histogram resembles\\n      the density function f_X(x) from Task 1.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'And now plot the density function of this continuous distribution:\\n\\n* Uniform distribution, $X\\\\sim U[0, 3]$.\\n\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Uniforme Verteilung\\na <- 0\\nb <- 3\\nx <- seq(a, b, 0.1)\\nplot(\\n\\tx, \\n\\tdunif(x, min=a, max=b) , \\n\\ttype=\"s\", \\n\\tlwd=5, \\n\\txlab=\"x\", \\n\\tylab=\"f(x)\", \\n\\txaxt=\"n\",image\\\\\\\\png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3da1iU17n\\\\\\\\8TUww4yWAQZFMdYd5aT1QLWCJaIclBTMjoLV1NTmamJokFyaeGibnZQabOo2TbqzY3KlaSJJtcGd3RxMRI0pNlUUqpKDJwxhohGFpDgUAWVGGBDm\\\\\\\\2L+m0tHM6LAmvXE7+fVzPKZdd8w8nO5eFjoXC6XAACox8\\\\\\\\XDQAAro6ABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKg0QeGDRum0+n27NnTPZKamqrT6V5++WUvr+rs7NTpdDqdzv30o48+io6ONhgM3l\\\\\\\\V595\\\\\\\\\\\\\\\\313G6Wlpe6R1atX63S68PDw8+fPe3mhl4\\\\\\\\63Llzuv\\\\\\\\zhz\\\\\\\\8oTftuefU6XS33357b+aBFhHQUMWzzz574sSJxMTE8ePHy6w7a9asO++8UwiRn58vhKivr3\\\\\\\\mmWeEEP\\\\\\\\1X\\\\\\\\8VFBTUm5nDw8PXrFnz\\\\\\\\e9\\\\\\\\Xwjxz3\\\\\\\\+86677ho2bFhkZOQDDzzgcDiuvP7AgQMpKSnBwcHDhg376U9\\\\\\\\eubMGSFEdnb2ihUretMGtIuAhs\\\\\\\\4+\\\\\\\\u3tbW1tbW5nzY1NQkhli9fnpiYKLmTZ599NiAgYPfu3SUlJWvWrLHb7dOmTbvnnnt6OW14eHheXl5cXNzFixdnzpz59ttvjx49OiQk5JVXXrn77rs9Lq6rq8vIyCgtLf3ud787cODAwsLCBQsWCCHuueeeJUuW9LITaBQBjf7V0NAQHR09ZcqULVu2TJgwISgoKDMz81\\\\\\\\\\\\\\\\+pcQwuFwmEymkJAQIcSkSZP++te\\\\\\\\CiHmzp37m9\\\\\\\\8Rghht9tXrFgRExNjNpsnT568ceNG94Q2m02n04WFhe3fvz8uLm7z5s01NTXR0dEzZ85ct27dt7\\\\\\\\97ZEjRz7\\\\\\\\\\\\\\\\PMHDhyIi4szm80zZsw4ffq09yajoqJWrlwphFi2bNnLL7\\\\\\\\s7+\\\\\\\\fy30JD3v27KmqqpoxY0ZJSUl5efmIESPee++9L7\\\\\\\\88tJrdu3ade7cuQceeGDv3r0ff\\\\\\\\yxv79\\\\\\\\aWlp979euDkR0OhfnZ2dJ06cOHTo0N13363X61tbW7du3ZqXl+dx2e9+97vvfve7Qoif\\\\\\\\\\\\\\\\zn8+fPF0JkZmauW7fO6XSmpKRUVVUtWrTo+eef776+ra1twYIFx48fDwgI6OjoOHHixO7du3\\\\\\\\1q1+FhIScPn162bJlycnJdrtdp9Pt3r37kUceuWafeXl5t9xyy9GjR9vb2x966KHY2Ng+\\\\\\\\CTs379fCDFt2jQhhF6vT0hIcLlcBw4cuPSajIyMY8eOrV27tqWlZcuWLZ2dnUlJSSaTqQ\\\\\\\\bgOYQ0JDh4sWLxcXFhw4d2rBhgxCivLzc44L09PRhw4YJIaZPnz5u3Li9e\\\\\\\\fu2rXr1ltv\\\\\\\\fTTT7dt2\\\\\\\\b+++8LIZ544onu6+12+89\\\\\\\\\\\\\\\\vOzZ8\\\\\\\\Onj3bPeJyuY4ePXrs2DF3Dv7oRz+qqqp65513hBBHjx69ZoeBgYH33nuv+\\\\\\\\F9993X64\\\\\\\\4Mo2NjUII9\\\\\\\\8VhBDBwcHi\\\\\\\\7Z0ug0aNGjcuHGhoaGxsbH3339\\\\\\\\YGDga6+91rdtQHMIaMgQEhKSnJwshIiLixNCXLhwwfv17ki98847AwMDhRBJSUnDhg07e\\\\\\\\ZsXV2d+wKTybR48WK9Xt\\\\\\\\9khEjRkRFRQkhvv3tbwshUlNT3YNCiIsXL16zw8bGxoKCAvfjxx9\\\\\\\\\\\\\\\\NI\\\\\\\\stvtqampM2fO\\\\\\\\OSTT4QQzc3NV\\\\\\\\0Wnxcul+vSp+4bV\\\\\\\\z8rv7V9+yzz65evbq9vX3atGnebyPBNx4BjT7gvtvh0tiy2+3d40KI7iTtvqmuJy692B1n3VEbGBjo8d9\\\\\\\\f39\\\\\\\\L0+vKS8vr6Gh4d\\\\\\\\\\\\\\\\\\\\\\\\d\\\\\\\\NZvPWrVvfe++97j\\\\\\\\KycmZNWtWe3t7ampqUVFRbGzsli1bRA8+6m6hoaHikiWz+4H7H49uFRUVRUVFJ0+ezMrKys\\\\\\\\Pz8zMrK2tLSkpua6PAt8wBDT6gHv7+M9\\\\\\\\\\\\\\\\nN7e7sQ4sMPPzxy5IgQYuLEiTc2oftOu+3bt7vjr6ys7KuvvrJYLB6hdl1cLpfNZrPZbB7rWSHEJ598sn79er1ev27dul\\\\\\\\84hdCiGXLljmdTiFEW1vb1q1bc3Nzt23bNn\\\\\\\\+\\\\\\\\Pvvv3\\\\\\\\UqFFz5869ro\\\\\\\\6tttuE0Ls3r3b5XK1trbu27fPz89vzJgxl7a0c+fOrKysxx57zF3UvQvEHvTNzgX02pEjR9xRYjabR4wY4V75\\\\\\\\uQnP3G5XO6beQcPHuy+sqqqSggRFRXlcrnc602TyeT+o4yMDCHEli1b3E\\\\\\\\dWyIRERFz5851b3Q899xzV07ocrlOnDghhBg5cqT7qfsOto0bN3qUa2hocP+db2houLT5rq4u963KixcvdrlcLS0tYWFhQognnnjihj\\\\\\\\q5uZmIcTEiRPdV3Z0dIwZM0YIERsbGxERIYS46667PFqqqalxL70jIyMtFosQYsyYMa2trd0fYFpa2o2+P9AqVtDoA7Gxsfv27ZszZ47ZbD579uy4ceOefvrpV155pTdzbtu27eGHH9bpdDt37oyOjt64cePDDz\\\\\\\\cVw1f6k9\\\\\\\\+lN5ebnJZFq1apUQIjAw0H2TyZNPPnnq1CkvL+z5R63X6z\\\\\\\\44IN58+bV19dfuHDh\\\\\\\\vvvf\\\\\\\\XVVz2uGTFixN\\\\\\\\\\\\\\\\\\\\\\\\vcZM2Y0NDSYTKaFCxfu3LmTFfRNTue64r97wDfYrbfeeuzYMbPZ3K9Vzp07FxISMnHixEOHDvW+pS+++CIqKiotLe1vf\\\\\\\\tbn7YJ1bGCxk3kk08+cblc\\\\\\\\Z3O3Ww221NPPXXw4MHetPS\\\\\\\\\\\\\\\\\\\\\\\\u\\\\\\\\L730Uj90Bw3QX\\\\\\\\sS4Buhubl5xYoV\\\\\\\\\\\\\\\\M\\\\\\\\\\\\\\\\yOtYl1d3aOPPhoYGPi9733vhltav34993LctNjiAABFscUBAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKEpjvzS2oaFh9+7dvu4CAP4\\\\\\\\Pz+\\\\\\\\OXPmGAyG\\\\\\\\phcYwG9a9euoqKi5ORkXzcCbTt48GBhYeGvfvWrsLAwX\\\\\\\\cCbXvttdcmTpwYGRnZH5NrLKCFEImJiTk5Ob7uAtr2+uuvv\\\\\\\\zyy3fddVdMTIyve4G2ffjhh\\\\\\\\03OXvQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKJ8ENCNjY0Oh0N+XQDQFhkBPXv27La2NiHE8ePH4+LiwsLCgoOD09PTz5w5I6E6AGiUjIDevn17Z2enECI3NzctLc3hcHz55ZeTJk1asmSJhOoAoFF6mcUOHjxYXFys1+vDw8PXrl0bHh4uszoAaIukPWibzSaEiIiIOH36tHukqqrKYDDIqQ4AWiQjoJOSkpKTk81m88mTJ93bGrt3705OTl65cqWE6gCgUTK2OPbs2SOEcDqd1dXV586dE0IYjcY33nhjxowZEqoDgEbJ24M2Go1jxoxxP9bpdKQzAHjnmx9U+cEPfuCTugCgITJW0MHBwe3t7ZeOtLW1DRgwQAjR2toqoQEA0CIZK+h9+\\\\\\\\ZNmDDhhz\\\\\\\\8YWVl5alTp06dOjVw4ED3AwnVAUCjZKygx40bt3\\\\\\\\\\\\\\\\\\\\\\\\t\\\\\\\\\\\\\\\\\\\\\\\\vdz5sz5wx\\\\\\\\+kJSU5OfnN3ToUO+v+vzzz48cOeIxuGvXrpCQkH7rFAAUIumbhP7+\\\\\\\\o8++mhmZmZ2dvbkyZN78pK2trampiaPwRMnTrj3RgDgG0\\\\\\\\qTxJ+5zvfKSsrW7duXVZW1jUvjo2NjY2N9Rj87LPP6urq+qc7AFCL1IAWQvj5+bl\\\\\\\\PqW5ubm8vDw9PV1yAwCgFT47D7qysrIn62gAuGn5LKCnTp3KPXYA4IXUgHa5XC0tLS6XS2ZRANAoGQHtdDrz8\\\\\\\\NjYmKMRmNQUFBAQEB0dPTq1as9fnoFAHApGQGdk5NTUVGxYcMGm83W0dFRX19fWFhotVpzc3MlVAcAjZJxF8eOHTtqa2tNJpP7qcViSUhIiI+Pj4iIkFAdADRKxgp6+PDhxcXFHoOlpaWDBg2SUB0ANErGCrqgoCAzM3PVqlVjx441m812u91qtdpstqKiIgnVAUCjZAR0fHx8TU1NSUlJdXV1U1OTxWLJzs5OSUnR62X\\\\\\\\mAwAaIikiNTr9WlpaXJqAcA3g89+UAUA4B0BDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRUgPa5XK1tLS4XC6ZRQFAo2QEtNPpzM\\\\\\\\Pj4mJMRqNQUFBAQEB0dHRq1evbm9vl1AdADRKRkDn5ORUVFRs2LDBZrN1dHTU19cXFhZardbc3FwJ1QFAo\\\\\\\\QSauzYsaO2ttZkMrmfWiyWhISE+Pj4iIgICdUBQKNkrKCHDx9eXFzsMVhaWjpo0CAJ1QFAo2SsoAsKCjIzM1etWjV27Fiz2Wy3261Wq81mKyoqklAdADRKRkDHx8fX1NSUlJRUV1c3NTVZLJbs7OyUlBS9XkZ1ANAoSRGp1+vT0tK6n+7fv590BgDvfPODKj\\\\\\\\4wQ98UhcANETGMjY4ONjjlue2trYBAwYIIVpbWyU0AABaJGMFvW\\\\\\\\fvgkTJvzwhz+srKw8derUqVOnBg4c6H4goToAaJSMgB43btz+\\\\\\\\fsnTJgwZ84cq9U6dOhQPz+\\\\\\\\oUOHDh06VEJ1ANAoSd+p8\\\\\\\\f3f\\\\\\\\TRRzMzM7OzsydPntyTl2zevPmll17yGPz888+joqL6oUEAUI7UWym+853vlJWVrVu3Lisr65oXz5s3b968eR6DK1asqKur65\\\\\\\\uAEAtsu918\\\\\\\\PzW7lypRCiubm5vLw8PT1dcgMAoBU+Ow+6srKyJ+toALhp+Sygp06dyj12AOAFB\\\\\\\\YDgKI4sB8AFMWB\\\\\\\\QCgKA7sBwBFcWA\\\\\\\\ACiKA\\\\\\\\sBQFEc2A8AivLNgf0AgGvy2Q+qAAC8I6ABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBF+SCgGxsbHQ6H\\\\\\\\LoAoC0yAnr27NltbW1CiOPHj8fFxYWFhQUHB6enp585c0ZCdQDQKBkBvX379s7OTiFEbm5uWlqaw+H48ssvJ02atGTJEgnVAUCj9DKLHTx4sLi4WK\\\\\\\\Xh4eHr127Njw8XGZ1ANAWSXvQNptNCBEREXH69Gn3SFVVlcFgkFMdALRIRkAnJSUlJyebzeaTJ0+6tzV2796dnJy8cuVKCdUBQKNkbHHs2bNHCOF0Oqurq8+dOyeEMBqNb7zxxowZMyRUBwCNkrcHbTQax4wZ4348ZcoUvV7q9jcAaI6MLY76+vrc3NykpKS8vLy6urpJkyaZTKbExMTq6moJ1QFAo2QEdHZ29ldfffXQQw\\\\\\\\V1dXFxcUtXLjw5MmTU6ZMWbp0qYTqAKBRMvYZysrKvvjii9DQ0JSUlDfffHP58uUGg+GJJ54YOXKkhOoAoFEyAtpsNjc2NoaGhg4ePLiwsNB9d11tba3RaPTyqq1bt27atMlj8PDhw\\\\\\\\\\\\\\\\2b\\\\\\\\\\\\\\\\Wj70CgDJkBHReXl5CQkJaWtpf\\\\\\\\vKXuXPnCiFefPHFp59+Ojs728urZs2aNX369CunOnv2bD\\\\\\\\2CgDKkBHQixcvTklJ+fDDD7tH\\\\\\\\P39161bl5WV5eVVBoPBYrF4DBqNRp1O1y9dAoBiJN3rNnr06NGjR3c\\\\\\\\Xbx4cXNzc3FxcXp6upwGAEBzfHYedGVlpfcVNADc5HwW0FOnTm1tbfVVdQBQn9SAdrlcLS0tLpdLZlEA0CgZAe10OvPz82NiYoxGY1BQUEBAQHR09OrVq9vb2yVUBwCNkhHQOTk5FRUVGzZssNlsHR0d9fX1hYWFVqs1NzdXQnUA0CgZd3Hs2LGjtrbWZDK5n1osloSEhPj4+IiICAnVAUCjZKyghw8fXlxc7DFYWlo6aNAgCdUBQKNkrKALCgoyMzNXrVo1duxYs9lst9utVqvNZisqKpJQHQA0yltAd3R0CCF6\\\\\\\\4up4uPja2pqSkpKqqurm5qaLBZLdnZ2SkoKR0IDgBeeEdnV1fXmm2++8cYb+\\\\\\\\btO3\\\\\\\\+vE6nCwwMnDp16oIFCxYsWODnd4NbInq9Pi0trdfdAsBN5LLAff3112fOnPnpp58+\\\\\\\\PDDH330kcPhcDgcn3zyyfLly6uqqmbOnPn666\\\\\\\\7qlEAuNlctoL29\\\\\\\\ffuXOnx57GiBEjRowYkZKS0tHR8c4778htDwBuXpetoBcsWGAwGLZv3+5xUWFhoRDCYDAsWLBAXmsAcHO7yp5yfn7+\\\\\\\\Pnzv\\\\\\\\rqKyHE0aNHp0+f\\\\\\\\sILL0hvDABudle5j+Kjjz5av379tGnTvv\\\\\\\\975eVla1Zs+bee++V3xm+jtMpLlzwdRMa53AIIcT586KpydetaFxQkPD393UT31xXCWg\\\\\\\\Pz\\\\\\\\3SfkNDQ2hoaFRUVGcka+OF18UK1YITjHpE\\\\\\\\Hxvu5A+0JDxVtviRkzfN3HN9RVAjo1NfXixYvbtm0bP3783r17Fy9eHB8fv3HjRum94Soee4x0hkIaG8WaNQR0f7nKHvRPf\\\\\\\\rTvXv3jh8\\\\\\\\XgiRlJR06NChqKgo6Y3h6viVuVANfyf7z2Ur6J07d95+++2LFi26dDAgIODXv\\\\\\\\61EMLlcn3wwQe333671AZxuS1bxFNPieZmX\\\\\\\\ehcTU1orxcZGQIs9nXrWjcrbeKvDxfN\\\\\\\\HNdVlAHz9+\\\\\\\\He\\\\\\\\+92cOXNSU1MjIyMDAwOFEHa7\\\\\\\\eTJk7t27dq2bdvcuXMJaN+KjBTr1\\\\\\\\u6Ce17\\\\\\\\XXxk5+I554TMTG+bgX4epdtcSxZsuT99983Go0PP\\\\\\\\zw4MGDw8PDw8PDBw8evHTp0oCAgB07dixdutRXjQLAzeayFXRDQ8PgwYN\\\\\\\\9KMfPfjgg11dXWfPnhVCDBo06IaP4AAA3LDLkvd73\\\\\\\\ve2bNnp0+f7nA4WltbBw4cOHDgwNbWVof7rlEAgESXraAXLVoUGRnZ0tISHh7ucV1LS4vErgAAl6+gf\\\\\\\\Ob3zQ3N991110tV\\\\\\\\BVfwBw07rK5vJf\\\\\\\\vIX+X0AADzw3T8AUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUVID2uVytbS0uFwumUUBQKNkBLTT6czPz4+JiTEajUFBQQEBAdHR0atXr25vb5dQHQA0SkZA5+TkVFRUbNiwwWazdXR01NfXFxYWWq3W3NxcCdUBQKP0Emrs2LGjtrbWZDK5n1osloSEhPj4+IiICAnVAUCjZKyghw8fXlxc7DFYWlo6aNAgCdUBQKNkrKALCgoyMzNXrVo1duxYs9lst9utVqvNZisqKpJQHQA0SkZAx8fH19TUlJSUVFdXNzU1WSyW7OzslJQUvV5GdQDQKEkRqdfr09LSup9evHiRdAYA72TsQdfX1+fm5iYlJeXl5dXV1U2aNMlkMiUmJlZXV0uoDgAaJSOgs7Ozv\\\\\\\\rqq4ceeqiuri4uLm7hwoUnT56cMmXK0qVLJVQHAI2Ssc9QVlb2xRdfhIaGpqSkvPnmm8uXLzcYDE888cTIkSMlVAcAjZIR0GazubGxMTQ0dPDgwYWFhQaDQQhRW1trNBq9vOrzzz8\\\\\\\\cuSIx+Dx48f9\\\\\\\\f37sVcAUIaMLY68vLyEhIS7775bp9PNnTtXCPHiiy\\\\\\\\ecccd2dnZXl7V1tbWdIW2trauri4JPQOAz8lYQS9evDglJeXDDz\\\\\\\\sHvH391+3bl1WVpaXV8XGxsbGxnoMfvbZZ3V1df3SJQAoRtK9bqNHjx49enT308WLFzc3NxcXF6enp8tpAAA0x2fnQVdWVnpfQQPATc5nAT116tTW1lZfVQcA9XFgPwAoigP7AUBRHNgPAIriwH4AUBQH9gOAojiwHwAUxYH9AKAo3xzYDwC4Jp\\\\\\\\9oAoAwDsCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CifBDQjY2NDodDfl0A0BYZAT179uy2tjYhxPHjx+Pi4sLCwoKDg9PT08+cOSOhOgBolIyA3r59e2dnpxAiNzc3LS3N4XB8+eWXkyZNWrJkiYTqAKBRepnFDh48WFxcrNfrw8PD165dGx4eLrM6AGiLpD1om80mhIiIiDh9+rR7pKqqymAwyKkOAFokI6CTkpKSk5PNZvPJkyfd2xq7d+9OTk5euXKlhOoAoFEytjj27NkjhHA6ndXV1efOnRNCGI3GN954Y8aMGRKqA4BGyduDbm1tHTNmjPvx1KlThRDnzp0LDg6W1gAAaIuMLY7PPvts3LhxoaGhkZGR7777rnvQ6XSGhIRIqA4AGiVjBf3ggw\\\\\\\\ecccd+\\\\\\\\btO3jw4MKFC4cMGZKYmCihLgBomoyAPnz48Pbt2wMDA1NTU\\\\\\\\\\\\\\\\4xz8+8MADR44ckVAXADRNxhZHWFhYRUWF+3FWVtbYsWNXrFghoS4AaJqMFfSTTz6ZkZERFxf31ltvhYaGFhQUZGRkXHOXY\\\\\\\\PmzS+99JLH4Oeffx4VFdVvnQKAQmQE9Pz586dNm3bgwAGj0SiEsFgsZWVlRUVFH3\\\\\\\\8sZdXzZs3b968eR6DK1asqKur68deAUAZkm6zCw8Pz8rK6n5qMBjS0tLMZrOc6gCgRT47D7qysvLSyAYAePBZQE+dOrW1tdVX1QFAfVID2uVytbS0uFwumUUBQKNkBLTT6czPz4+JiTEajUFBQQEBAdHR0atXr25vb5dQHQA0SkZA5+TkVFRUbNiwwWazdXR01NfXFxYWWq3W3NxcCdUBQKNk3MWxY8eO2tpak8nkfmqxWBISEuLj4yMiIiRUBwCNkrGCHj58eHFxscdgaWnpoEGDJFQHAI2SsYIuKCjIzMxctWrV2LFjzWaz3W63Wq02m62oqEhCdQDQKBkBHR8fX1NTU1JSUl1d3dTUZLFYsrOzU1JS9HqpvxERALRFUkTq9fq0tDQ5tQDgm8FnP6gCAPCOgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioAFAUQQ0ACiKgAYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABQlNaBdLldLS4vL5ZJZFAA0SkZAO53O\\\\\\\\Pz8mJgYo9EYFBQUEBAQHR29evXq9vZ2CdUBQKNkBHROTk5FRcWGDRtsNltHR0d9fX1hYaHVas3NzZVQHQA0Si+hxo4dO2pra00mk\\\\\\\\upxWJJSEiIj4+PiIiQUB0ANErGCnr48OHFxcUeg6WlpYMGDZJQHQA0SsYKuqCgIDMzc9WqVWPHjjWbzXa73Wq12my2oqIiCdUBQKNkBHR8fHxNTU1JSUl1dXVTU5PFYsnOzk5JSdHrZVQHAI2SFJF6vT4uLi4tLe3SwXPnzgUHB8tpAAA0R8Ye9GeffTZu3LjQ0NDIyMh3333XPeh0OkNCQiRUBwCNkrGCfvDBB++44459+\\\\\\\\YdPHhw4cKFQ4YMSUxMlFAXADRNRkAfPnx4+\\\\\\\\btgYGBqampf\\\\\\\\zjHx944IEjR45IqAsAmiYjoMPCwioqKm677TYhRFZW1qZNm1asWPHMM894f9XWrVs3bdrkMXjkyJGRI0f2U58AoBQZAf3kk09mZGTExcW99dZboaGhBQUFGRkZ19zlmDVr1vTp0z0G33nnHYfD0W+dAoBCZAT0\\\\\\\\Pnzp02bduDAAaPRKISwWCxlZWVFRUUff\\\\\\\\yxl1cZDAaLxeIxaDabnU5nP\\\\\\\\YKAMqQdJtdeHh4VlZW91ODwZCWlmY2m+VUBwAt8tl50JWVlZdGNgDAg88CeurUqa2trb6qDgDq48B+AFAUB\\\\\\\\YDgKI4sB8AFMWB\\\\\\\\QCgKA7sBwBFcWA\\\\\\\\ACiKA\\\\\\\\sBQFE6bd30Vlxc\\\\\\\\B\\\\\\\\\\\\\\\\8R9hYWG+bsSXrFbr+fPn\\\\\\\\f39Lx3s7Ozs7OwMCAjwuLi1tXXAgAEegxcuXBg4cKDHYFtbW0BAgJ\\\\\\\\fZbteFy9edLlcBoPh0kGXy9XW1tbzaY1Go06nu3Swo6NDCOExbVdXV3t7e\\\\\\\\f3KrxP29raajKZPKZtb2\\\\\\\\38\\\\\\\\Pz+Ie\\\\\\\\q6uro6PDfcxAt87OTofDYTabPWa4ai2n06nX6\\\\\\\\v8E+50Og0Gw5Wf8K6uLo9pVf6Ejxo1aujQoeImVltbu2vXrltuuaVfZndBax5\\\\\\\\\\\\\\\\PE9e\\\\\\\\Z4DBYXF\\\\\\\\\\\\\\\\nf\\\\\\\\6nx6DD4bjjjjuunCElJeXKwWXLlh0+fNhj8M0333zhhRc8Buvq6u6+++4eTnvfffdVV1d7DL7yyiuvvfaax2BVVdXixYt7OO3cuXMbGxs9Bp955pmioiKPwfLy8kceeaSH086cOdP9b9Kl8vPzS0pKPAZ37ty5Zs0aj8HW1taMjIwe1lq+fPmhQ4c8Bt9+++3nn3\\\\\\\\eY\\\\\\\\DMmTMLFizo4bSLFi06efKkx+Crr7765z\\\\\\\\\\\\\\\\2WbsMEoAAAa7SURBVGPQarXm5OT0cNp58+Y1NDR4DP73f\\\\\\\\\\\\\\\\3li1brrwYfcVnP0kIAPCOgAYARRHQAKAoAhoAFEVAA4CiCGjt8fPz87g3Swjh7+\\\\\\\\vcR\\\\\\\\Y110phLjqHehM6x70uJPMPcOV0161lk6nu3Lw62pp6zPT82nRhzR2HzSEEA6HY8CAAR5fLZ2dnU6n88rbV1taWq78zTVXHbTb7d\\\\\\\\61reuvH+2s7Pzyltlez7tVQedTqdOp7vyJmK73R4YGHjD07a2thoMBo98cblcFy5c+Na3vnXD036DP+G9nPaqn3D0IQIaABTFFgcAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAENAIoioLXk448\\\\\\\\njRp0pAhQ+677z6n09mv83z66afBwcF9OO2WLVtiYmJCQkLmzJlTX19\\\\\\\\vT3PmjXLarVeOb558+bRo0eHhISkpqZWVVX11bSnT59OS0uzWCyJiYmnT5++3mn7qr3rmucG3jLv0\\\\\\\\byLUMf8PF51Oixjo6OYcOGvfvuuxcuXMjKynr88cf7b56LFy\\\\\\\\Gx8ebTKa+mrahoWHAgAFFRUVNTU3z589ftGhRz2cuLy\\\\\\\\\\\\\\\\5S9\\\\\\\\KYSoqqry+KO6urqgoKB\\\\\\\\\\\\\\\\OMfLS0tv\\\\\\\\jFL8aOHdsn07pcrvHjx2\\\\\\\\atMnpdP7617++5557ej5tX7V3vfPcwFvmfdrevGXoKwS0Zvztb3+bMGGC+3FZWVlMTEz\\\\\\\\zfPkk08uXLjwur7avU9bXl4eHh7ufvz222\\\\\\\\Hx8f3fOannnoqNzd3wIABVybpu+++O2PGDPfj5uZmnU7X1NTU+2n37ds3efJk9+OOjo4rf0FJD\\\\\\\\Wmveud5wbeMu\\\\\\\\T9uYtQ18hoDVj\\\\\\\\fr13b\\\\\\\\3qLGx0WAwdHV19cc8lZWV48aN++KLL67rq937tHa7fciQIZs2baqtrZ09e\\\\\\\\Yvf\\\\\\\\nL6207PDz8yiS12+1nz551P961a1dERESfTPunP\\\\\\\\3pzjvvXLhw4ahRo2bPnn3DAd379no4z429Zd6n7f1bht4joDXjqaee+tnPfuZ+7P4doOfPn+\\\\\\\\zeTo7O2+77bY9e\\\\\\\\acOXPmur7ar9neCy+8IIQwmUxhYWH\\\\\\\\+te\\\\\\\\rrftqyZpty1btgwdOnTz5s19Mu3TTz8thHjnnXfOnz\\\\\\\\\\\\\\\\yCOPTJky5Xqn7av2ejLPDb9l12yvl28Zeo9jqDTDYrHY7Xb345aWFr1ef+XBb72fZ926dZMnT05KSrLZbH047d69e9euXVtVVTVq1Kjnnnvu9ttvP3To0A00f6WmpqacnJxjx45t3rw5MTGxT+YMDg6ePHny3LlzhRDLli37\\\\\\\\e9\\\\\\\\39TUZLFYfNiel3lu+C3zPm3\\\\\\\\vWXoOe7i0IxRo0Z1329gtVpHjhx55cnFvZ\\\\\\\\n0KFDGzduNJvNERERbW1tZrN5\\\\\\\\\\\\\\\\79vZ92165d6enpo0ePDggIyM3NPXr0aENDww0076GjoyMjI2PIkCFHjx7tq3QWQtx6662dnZ3ux+5zkG\\\\\\\\sRM2+as\\\\\\\\7PDf8lnmftp\\\\\\\\eMlwfXy\\\\\\\\h0VMdHR233HJLSUnJxYsXf\\\\\\\\zjH+fn5\\\\\\\\ftPP\\\\\\\\4xz8u\\\\\\\\R7R9f5\\\\\\\\2fu07733XlhY2OHDhx0Ox29\\\\\\\\+9vIyMjrbdtjL8I97VtvvTV58uS2S\\\\\\\\TJtO3t7UOGDNm5c2dXV9djjz2WnJx8vdO69b497\\\\\\\\P08i3zPm3v3zL0HgGtJR999NHEiRNHjBhx77333vBX+9fNYzKZ\\\\\\\\vrXv3ZfcwMbmt6nfe6550aOHBkSEpKSklJRUXG9PXskqXvaRx991GPB0dzc3PtpXS7XgQMHJk6cOHjw4IyMjNOnT19vt269b8\\\\\\\\7PL18y645bS\\\\\\\\fMvQeB\\\\\\\\YDgKLYgwYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoCgCGgAURUADgKIIaABQFAGNm8uGDRtSU1OFEF1dXZMnT37vvfd83RHwtXQul8vXPQDyuFyupKSkpUuXNjU1ffDBB2+\\\\\\\\\\\\\\\\bavOwK+FgGNm86xY8fuvPNOnU5XVlY2fPhwX7cDfC29rxsAZBs\\\\\\\\fnxUVNTgwYNJZyiOPWjcdPbu3VtfX19WVnb06FFf9wJ4wxYHbi7t7e2TJk16+eWXT5w48eqrr5aWlvq6I+BrsYLGzeXpp5+Oj4+fNm3avffe297e\\\\\\\\tprr\\\\\\\\m6I+BrsYIGAEWxggYARRHQAKAoAhoAFEVAA4CiCGgAUBQBDQCKIqABQFEENAAoioAGAEUR0ACgKAIaABRFQAOAoghoAFAUAQ0AiiKgAUBRBDQAKIqABgBFEdAAoKj\\\\\\\\B+iLZbmPBHYfAAAAAElFTkSuQmCC\\n\\txlim=c(a-1, b+1), \\n\\tmain=\"Uniform, X~U[0,3]\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=(a+b)/2, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(... - ..., ... + ... ), lty=2)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Uniforme Verteilung\\na <- 0\\nb <- 3\\nx <- seq(a, b, 0.1)\\nplot(x, dunif(x, min=a, max=b), type=\"s\", lwd=5, xlab=\"x\", ylab=\"f(x)\", xaxt=\"n\",\\n\\txlim=c(a-1, b+1), main=\"Uniform, X~U[0,3]\", col=\"blue\")\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=(a+b)/2, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c((a+b)/2-sqrt((b-a)^2/12), (a+b)/2+sqrt((b-a)^2/12)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Plot the boxplot of all continuous variables.\\n\\nNow access the 73-rd line in the 'iris' dataset and compare those values with the boxplot. Does the\\n73-rd iris flower have relatively long or short sepals, relatively wide or narrow ones?\\n\\nTips: The first four variables from the dataset 'iris' can be accessed by $iris[, 1 : 4]$.\\n\\nAfter you have created the boxplot, in the same code chunk you can use the function $points()$ to\\ndraw some additional points. With the argument $pch = 17$ these points are displayed as triangles.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- iris[73,]\\nboxplot(n, main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, 5:8, pch=17)\\n\\nsol <- list(Length = \"gross\", # falsche Antwort hier löschen!\\n            Width = \"schmal\" # falsche Antwort hier löschen!\\n) \\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- 73\\nboxplot(iris[,1:4], main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, iris[n,1:4], pch=17)\\n\\nsol <- list(Length = \"gross\", Width = \"schmal\")\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The sum of two independent normally distributed random variables is another normally distributed random variable. We will visualize this with some normally distributed samples. To this end, generate two samples, each with size $3000$, of the form\\n\\n* $X\\\\sim N(65, 30)$,\\n\\n* $Y\\\\sim N(35, 11)$,\\n\\nwhere (unlike in R!) the second parameter we list is the variance, i.e. $N(\\\\mu, \\\\sigma^2)$.\\nAdd these two samples to generate a single sample $V$. To check if $V$ is also normally distributed, use a quantile-quantile-plot and a histogram. Don't forget to write down what you conclude!\\n\\nTip: Do you still remember the functions $hist()$, $qqnorm()$, and $qqline()$?\\n\\n\", 'answer': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var)\\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X+Y\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n#Histogramm\\nhist(x, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"As the distribution of points in the QQ-plot is roughly linear, it is highly likely that V is indeed normally distributed.\"\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"The sample V=X+Y seems to still follow a theoretical\\n  normal distribution. The points are overall distributed along the line\\n  of the theoretical quantiles. We also note that the expectations add up,\\n  i.e. E[V] = E[X] + E[Y]. (In fact the variances also add up, but this is\\n  not so obvious from the plot.)\"\\n\\t\\ndev.off()\\n\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nPlot the probability function of $X$.\\n\\nTips: First replace the \\'NA\\' with the calculated value (Exercise 2). Use $plot(...)$ with $type=\"h\"$ to get a suitable plot.\\n', 'answer': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\nplot(x, p, type=\"h\", lwd=3, ylab=\"P[X = x]\", main=\"Wahrscheinlichkeitsfunktion\")\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\nplot(x, p, type=\"h\", lwd=3, ylab=\"P[X = x]\", main=\"Wahrscheinlichkeitsfunktion\")\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Which are the 'ht' for shoe sizes in the range $[5,6.5]$ (corresponding to EU shoe sizes 36-39)? And how many are there?\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\nht <- dat$ht\\nsize <- dat$size\\nsize_565 <- ht[size>=5 & size <= 6.5]\\n\\nsol <- list(ht = size_565, anzahl = length(size_565))\\nsol', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsize <- dat$size\\nht <- dat$ht\\nsize_565 <- ht[size>=5 & size<=6.5]\\nsol <- list(ht = size_565, anzahl = length(size_565))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nCompute the conditional probability $P[A|B]$ directly as follows: Start by making a data frame of all the rows which satisfy the condition B, and save this as $b$. Then within this reduced sample space, compute the probability $P[A]$.\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[ dat$size >= 8, ]\\nprob_A_given_B <- nrow( dat[dat$ht >= 170, ] ) / nrow( b[b$ht >= 170, ] ) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )\\nsol', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[ dat$size >= 8, ]\\nprob_A_given_B <- nrow( b[b$ht >= 170 , ] ) / nrow(b) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Load the familiar 'iris' dataset and plot the petal width versus sepal width. Label the x-axis with 'Breite Kelchblatt [mm]' and the y-axis with 'Breite Blütenblatt [mm]', and give your plot the title 'Breite der Irisblumenblätter'.\\n\\nWhat do you observe?\\n\\nTips: Here we are trying to create a real scatterplot, not the graph of a continuous function, and so we should use $type=p$. Use the argument $pch=16$ to get some nice points. Note that a plot of 'A versus B' should have A plotted along the vertical axis and B along the horizontal axis.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\nplot(\\n\\tiris$Sepal.Width, \\n\\tiris$Petal.Width, \\n\\txlab=\"Breite Kelchblatt [mm]\", \\n\\tylab=\"Breite Blütenblatt [mm]\", \\n\\tmain=\"Breite der Irisblumenblätter\", \\n\\tpch=16\\n)\\n\\ntext_response <- \"the scatterplot shows how petal width and sepal width vary among iris flowers\"\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n    ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", pch=16)\\n\\ntext_response <- \"The iris flowers seem to be divided into two groups. In both groups the sepals\\n    are wider than the petals, but in the lower group this tendency is even more pronounced.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Like a calculator, R can compute values of all the usual functions - although only numerically!\\n\\nCreate a variable 'n' with the value $42$ and compute $\\\\sin(90)$ and $\\\\sin($n$\\\\cdot\\\\pi)$. What do you observe?\\n\\n\", 'answer': 'n <-  42\\n\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*pi)\\n\\ntext_response <- \"sin_90 gives the correct output while sin_npi does not.\" \\n\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n', 'rubrics': [], 'modelSolution': 'n <- 42\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*pi)\\ntext_response <- \"We observe that R works with radians and not with degrees; also, that the result is a numerical approximation (although a very good one!). Since 42 is an integer, the sine of 42*pi should actually be exactly 0.\"\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Plot the histograms of the average wingspan for the sample sizes 5, 20 and 100 dragons from this population. As before, the (exceptionally brave) scientist will measure 100 groups of each size.\\n\\n\\n', 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\nD_1 <- rnorm(50000, mean = 5, sd = sqrt (2))\\nD_2 <- rnorm(50000, mean = 14, sd = sqrt (10))\\ndragons <- c( D_1, D_2)\\n\\n# Bereite Objekte vor\\nmesse5 <- numeric(length = 100)\\nmesse20 <- numeric(length = 100)\\nmesse100 <- numeric(length = 100)\\nxLim <- c(0, 25)\\ncolHist <- \"seagreen\"\\ncolDensity <- \"red\"\\nxLab <- \"Flügelspannweite [m]\"\\n\\n# Erzeuge Stichproben\\nfor (i in 1:100){\\n  messe5[i] <- mean (sample (x=dragons, size = 5))\\n  messe20[i] <- mean (sample (x=dragons, size = 20))\\n  messe100[i] <- mean (sample (x=dragons, size = 100))\\n}\\n\\npar(mfrow=c(3,1))  # drei Plots aufeinander gestapelt\\nhist(messe5, main=\"5 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe5, bw=2), lwd=2, col=colDensity)\\n\\nhist(messe20, main=\"20 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe20, bw=1), lwd=2, col=colDensity)\\n\\nhist(messe100, main=\"100 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe100, bw=0.5), lwd=2, col=colDensity)\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\nD_1 <- rnorm(50000, mean=5, sd=sqrt(2))\\nD_2 <- rnorm(50000, mean=14, sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\n# Bereite Objekte vor\\nmesse5 <- numeric(100)\\nmesse20 <- numeric(100)\\nmesse100 <- numeric(100)\\nxLim <- c(0, 25)\\ncolHist <- \"seagreen\"\\ncolDensity <- \"red\"\\nxLab <- \"Flügelspannweite [m]\"\\n\\n# Erzeuge Stichproben\\nfor (i in 1:100){\\n  messe5[i] <- mean(sample(dragons, 5))\\n  messe20[i] <- mean(sample(dragons, 20))\\n  messe100[i] <- mean(sample(dragons, 100))\\n}\\npar(mfrow=c(3,1))  # drei Plots aufeinander gestapelt\\nhist(messe5, main=\"5 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe5, bw=2), lwd=2, col=colDensity)\\n\\nhist(messe20, main=\"20 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe20, bw=1), lwd=2, col=colDensity)\\n\\nhist(messe100, main=\"100 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe100, bw=0.5), lwd=2, col=colDensity)\\n\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nNow compute the conditional probability $P[A|B]$ indirectly, with the help of the formula for conditional probability. Does the result match that of Exercise 2?\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170 , ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <-  nrow(dat[dat$size >= 8,])/ nrow(dat)\\nprob_A_and_B <- nrow(dat[dat$ht >= 170 & dat$size >= 8, ]) / nrow(dat)\\n\\nprob_A_given_B <- prob_A_and_B / prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n    Resultat = \"stimmt überein\"  # falsche Antwort hier löschen\\n    )\\n\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nprob_A <- nrow(dat[ dat$ht >= 170, ]) / nrow(dat)   # \"günstig\"/\"total\"\\nprob_B <- nrow(dat[ dat$size >= 8, ]) / nrow(dat)\\nprob_A_and_B <- nrow(dat[ dat$ht >=170 & dat$size >= 8, ]) / nrow(dat)\\n\\nprob_A_given_B <- prob_A_and_B / prob_B\\n\\nsol <- list( pAgivenB = prob_A_given_B, \\n    Resultat = \"stimmt überein\"\\n    )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Plot the density function of this continuous distribution:\\n    \\n* Normal distribution, $X\\\\sim N(0,3)$,\\n\\nEx.: the distribution of length variations in some machined parts, with standard deviation $\\\\sqrt{3}$.\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(\\n\\tx, \\n\\tdnorm(x, mean=mu, sd=sqrt(sigma2)), \\n\\ttype=\"l\", \\n\\tlwd=5, \\n\\tylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", \\n\\tcol=\"blue\"\\n)\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu - sqrt(sigma2), mu + sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Normalverteilung\\nx <- seq(-7, 7, 0.1)\\nmu <- 0\\nsigma2 <- 3\\nplot(x, dnorm(x, mean=mu, sd=sqrt(sigma2)), type=\"l\", lwd=5, ylab=\"f(x)\", \\n\\tmain=\"Normal, X~N(0, 3)\", col=\"blue\")\\naxis(1, at=-10:10,labels=-10:10)\\nabline(h=0, lty=3)\\nabline(v=mu, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(mu-sqrt(sigma2), mu+sqrt(sigma2)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In this exercise we will use various samples generated from random variables. If you calculate statistical key figures in R from these samples, you will get the sample variance $s^2$ instead of the theoretical variance $V[X]$ of the distribution, and the sample mean $\\\\overline{x}$ instead of the theoretical mean $E[X]$. The corresponding functions are $var()$ resp. $mean()$.\\n\\nGenerate two samples of size $n_X=400$ and $n_Y=400$ from normally distributed random variables $X\\\\sim\\\\mathcal{N}(\\\\mu, 9)$ and $Y\\\\sim\\\\mathcal{N}(\\\\mu/3, 4)$. Use $\\\\mu=57$.\\n\\nNow compute mean$(aX+bY)$ for $a=-4$ and $b=3$ and compare your result with $a\\\\cdot$mean$(X)+b\\\\cdot$mean$(Y)$. \\n\\nTip: Recall that normally distributed random samples can be generated using $rnorm()$.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400,mu,3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mu/3, 2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X+b*Y)\\nmean_x_y <- a*mean(X)+b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu, sd=3) # rnorm braucht SD, nicht Varianz!\\nY <- rnorm(400, mean=mu/3, sd=2)\\na <- -4\\nb <- 3\\n\\nmean_xy <- mean(a*X + b*Y)\\nmean_x_y <- a*mean(X) + b*mean(Y)\\n\\nsol <- list(mean_xy = mean_xy, mean_x_y = mean_x_y)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Show the first column with name 'ht' of the data frame 'dat'. \\nCalculate the sum of all the elements of 'ht'. This is the total height of all 403 students in the dataset.\\n\\nTips: There are two ways to access a column. We can use the indices directly, by simply leaving the first entry inside the square brackets before the comma empty, e.g. $dat[,2]$. The empty row specifier means that all rows are considered.\\n\\nAlternatively we can use the name of the column and the operator '\\\\$', e.g. 'dat\\\\$size'.\\n\\nUse the function $sum()$ to calculate the sum.\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nht <- dat$ht\\nsum_ht <- sum(dat$ht)\\n\\nsol <- list(Spalte_ht = ht, Summe_ht = sum_ht)\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nht <- dat$ht\\nsum_ht <- sum(dat$ht)\\nsol <- list(Spalte_ht = ht, Summe_ht = sum_ht)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Start with the code of the previous task. Now let's accentuate the 43rd iris flower by marking it differently on your scatterplot. Use the color 'magenta', give the point a square shape (the argument $pch=15$), and draw it in a slightly larger size than the others (the argument $cex=1.5$), in order to make this point stand out. Add this marking to the legend as well, with the label '43-te'.\\n\\nTip: As before, use the function $points()$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\tdata(iris)\\n\\n\\tn <- 43\\n\\tplot(\\n\\t\\tiris$Sepal.Width, \\n\\t\\tiris$Petal.Width, \\n\\t\\txlab=\"Breite Kelchblatt [mm]\",\\n\\t\\tylab=\"Breite Blütenblatt [mm]\",\\n\\t\\tmain=\"Breite der Irisblumenblätter\", \\n\\t\\tcol=iris$Species, \\n\\t\\tpch=16\\n\\t)\\n\\tpoints(\\n\\t\\tiris$Sepal.Width[n], \\n\\t\\tiris$Petal.Width[n], \\n\\t\\tcol= \"magenta\", \\n\\t\\tcex= 1.5, \\n\\t\\tpch= 15\\n\\t)\\n\\tlegend(\"topright\", legend=c(levels(iris$Species), \"43-te\"), \\n     col=c(1:3, \"magenta\"), pch=c(16,16,16,15 ))\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\nn <- 43\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n     ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", \\n     col=iris$Species, pch=16)\\npoints(iris$Sepal.Width[n], iris$Petal.Width[n], col=\"magenta\", cex=1.5, pch=15)\\nlegend(\"topright\", legend=c(levels(iris$Species), \"43-te\"), \\n     col=c(1:3, \"magenta\"), pch=c(16,16,16,15))\\ndev.off()', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Plot the probability function of this discrete distribution:\\n\\n* Poisson distribution, $X\\\\sim Po(3)$\\n\\nEx.: Number of telephone calls received in an hour (with rate 3).\\n\\n', 'answer': 'png(file = \"solution.png\")\\n\\n## Poissonverteilung\\nx <- 0:20\\nlambda <- 3\\nplot(\\n\\tx, \\n\\tdpois(x, lambda) , \\n\\ttype=\"h\", \\n\\tlwd=5, \\n\\tylab=\"P[X=x]\",\\n\\tmain=\"Poisson, X~Po(3)\", \\n\\tcol=\"green4\"\\n)\\nabline(h=0, lty=3)\\nabline(v=lambda, lwd=2) # Erwartungswert\\n\\t\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(lambda - sqrt(3), lambda + sqrt(3)), lty=2)\\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Poissonverteilung\\nx <- 0:20\\nlambda <- 3\\nplot(x, dpois(x, lambda=lambda), type=\"h\", lwd=5, ylab=\"P[X=x]\",\\n\\tmain=\"Poisson, X~Po(3)\", col=\"green4\")\\nabline(h=0, lty=3)\\nabline(v=lambda, lwd=2) # Erwartungswert\\n\\n# Erwartungswert +/- Standardabweichung: \\nabline(v=c(lambda-sqrt(lambda), lambda+sqrt(lambda)), lty=2)\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Which are the 'ht' for shoe sizes in the range $[5,6.5]$ (corresponding to EU shoe sizes 36-39)? And how many are there?\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\nht <- dat$ht\\nsize <- dat$size\\nsize_565 <- ht[size>=5 & size<=6.5]\\n\\nsol <- list(ht = size_565, anzahl = length(size_565))\\nsol', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsize <- dat$size\\nht <- dat$ht\\nsize_565 <- ht[size>=5 & size<=6.5]\\nsol <- list(ht = size_565, anzahl = length(size_565))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Again, we consider the 'shoe' dataset and the two events\\n\\n$A:$ ``The person's height is $\\\\geq 170$ cm''\\n\\n$B:$ ``The person's shoe size is $\\\\geq 8$''\\n\\nCompute the conditional probability $P[A|B]$ directly as follows: Start by making a data frame of all the rows which satisfy the condition B, and save this as $b$. Then within this reduced sample space, compute the probability $P[A]$.\\n\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[dat$size >= 8, ]\\nprob_A_given_B <- nrow(b[b$ht >= 170, ]) / nrow(dat) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nb <- dat[ dat$size >= 8, ]\\nprob_A_given_B <- nrow( b[b$ht >= 170 , ] ) / nrow(b) # \"günstig\"/\"total\"\\n\\nsol <- list( pAgivenB = prob_A_given_B )\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Take the sample of size $n=100\\\\,000$ from Task 3 and transform it to make 3 new samples: \\n  1. add $6$ to all values\\n  2. subtract $10$ from all values\\n  3. multiply all values by $2$\\n  \\nPlot the three resulting histograms of these transformed samples, and comment on the results.\\n\\nFix the same bin width 1 in all histograms, using the argument $breaks = seq(min(...)-1, max(...)+1, 1)$.\\n\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\nx1e5 <- rnorm(100000, mean = mu, sd = sigma)\\n\\nhist(x1e5+6, freq=FALSE, ylim = c(0,0.2), breaks=seq(min(x1e5+6)-1, max(x1e5+6)+1),1 )\\nhist(x1e5-10, freq=FALSE, ylim = c(0,0.2), breaks=seq(min(x1e5-10)-1, max(x1e5-10)+1),1 )\\nhist(x1e5*2, freq=FALSE, ylim = c(0,0.2), breaks=seq(min(x1e5*2)-1, max(x1e5*2)+1),1 )\\n\\ntext_response <- \"Durch die Addition/Subtraktion/Multiplikation verschiebt sich der Mittelwert.\" \\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\n\\nhist(x1e5+6, freq=FALSE, ylim = c(0,0.2), breaks = seq(min(x1e5+6)-1, max(x1e5+6)+1, 1) )\\nhist(x1e5-10, freq=FALSE, ylim = c(0,0.2), breaks = seq(min(x1e5-10)-1, max(x1e5-10)+1, 1) )\\nhist(x1e5*2, freq=FALSE, ylim = c(0,0.2), breaks = seq(min(x1e5*2)-1, max(x1e5*2)+1, 1) )\\n\\ntext_response <- \"Addition and subtraction shift the histogram to the right \\n    and left, respectively, but its shape remains unchanged. Multiplication \\n    shifts the histogram by a factor of 2, but also stretches it wider by the \\n    same factor. As a result the histogram becomes flatter as well.\" \\n\\t\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Load the familiar 'iris' dataset and plot the petal width versus sepal width. Label the x-axis with 'Breite Kelchblatt [mm]' and the y-axis with 'Breite Blütenblatt [mm]', and give your plot the title 'Breite der Irisblumenblätter'.\\n\\nWhat do you observe?\\n\\nTips: Here we are trying to create a real scatterplot, not the graph of a continuous function, and so we should use $type=p$. Use the argument $pch=16$ to get some nice points. Note that a plot of 'A versus B' should have A plotted along the vertical axis and B along the horizontal axis.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\nplot(\\n  iris$Sepal.Width, \\n  iris$Petal.Width, \\n  xlab= \"Breite Kelchblatt [mm]\", \\n  ylab= \"Breite Blütenblatt [mm]\", \\n  main= \"Breite der Irisblumenblätter\", \\n  pch= 16\\n)\\n\\ntext_response <- \"the scatterplot showshow petal width and sepal widh vary among iris flowers\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n    ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", pch=16)\\n\\ntext_response <- \"The iris flowers seem to be divided into two groups. In both groups the sepals\\n    are wider than the petals, but in the lower group this tendency is even more pronounced.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"The sum of two independent normally distributed random variables is another normally distributed random variable. We will visualize this with some normally distributed samples. To this end, generate two samples, each with size $3000$, of the form\\n\\n* $X\\\\sim N(65, 30)$,\\n\\n* $Y\\\\sim N(35, 11)$,\\n\\nwhere (unlike in R!) the second parameter we list is the variance, i.e. $N(\\\\mu, \\\\sigma^2)$.\\nAdd these two samples to generate a single sample $V$. To check if $V$ is also normally distributed, use a quantile-quantile-plot and a histogram. Don't forget to write down what you conclude!\\n\\nTip: Do you still remember the functions $hist()$, $qqnorm()$, and $qqline()$?\\n\\n\", 'answer': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nn <- 3000\\nX <- rnorm(n, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(n, mean=35, sd=sqrt(11))\\nV <- X+Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"Die addierte Stichprobe V nähert sich einer Normalverteilung an, im Quantil-Quantil Plot zeigt die Verteilung eine relativ gerade Linie. Zusätzlich dazu zeigt das Hstogram eine der Normalverteilung ähnliche Kurve an, der Unterschied zu der üblichen Normalverteilung ist jedoch gering und wenn man eine Kurve ziehen würde sind sie sich sehr ähnlich. Insgesamt kann man also sagen dass die Summe der beiden Zufallsgrössen (V) immernoch normal verteilt ist. \"\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nset.seed(10) #um reproduzierbar zu arbeiten\\npar(mfrow=c(1,2)) # 2 Plots nebeneinander\\n\\nX <- rnorm(3000, mean=65, sd=sqrt(30)) # sd = sqrt(Var) \\nY <- rnorm(3000, mean=35, sd=sqrt(11))\\nV <- X + Y\\n\\n#Quantil-Quantil-Plot\\nqqnorm(V, pch=16, col=\"orange\")\\nqqline(V, lwd=2)\\n\\n#Histogramm\\nhist(V, prob=TRUE, col=\"orange\")\\n\\ntext_response <- \"The sample V=X+Y seems to still follow a theoretical\\n  normal distribution. The points are overall distributed along the line\\n  of the theoretical quantiles. We also note that the expectations add up,\\n  i.e. E[V] = E[X] + E[Y]. (In fact the variances also add up, but this is\\n  not so obvious from the plot.)\"\\n\\t\\ndev.off()\\n\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'In the plot of the distribution function $F_X(x)$, mark the values of the quantiles where 95%, 97.5%, and 99% of the probability is reached.\\n\\nTips: Use $qnorm(...)$ to get quantiles of a normal distribution. Again, use the function $abline(v=...)$ to add a vertical line to an existing plot. Did you know by giving a vector instead of a single value, you can add multiple lines at the same time?\\n', 'answer': 'png(file = \"solution.png\")\\nmu <- 40\\nsigma <- 2\\nx <- seq(mu-4*sigma, mu+4*sigma, 0.1) # gibt eine gute Spannweite\\np <- c( 0.95, 0.975, 0.99 )\\n\\nplot(x, dnorm(x, mean=mu, sd=sigma) type=\"l\", lwd=3, ylab=\"F(x)\", \\n     main=\"Verteilungsfunktion F(x)\")\\nabline(v = mu, col=\"tomato\", lwd=3)\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nmu <- 40\\nsigma <- 2\\nx <- seq(mu-4*sigma, mu+4*sigma, 0.1) # gibt eine gute Spannweite\\np <- c( 0.95, 0.975, 0.99 )\\n\\nplot(x, pnorm(x, mean = mu, sd = sigma), type=\"l\", lwd=3, ylab=\"F(x)\", \\n     main=\"Verteilungsfunktion F(x)\")\\nabline(v = qnorm( p, mean = mu, sd = sigma), col=\"tomato\", lwd=3)\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Practice assigning a value, or multiple values, to $objects$ in R. \\nCreate a variable '$z$' with value 5 and a vector '$s$' containing the integers -2 to 5. \\nMultiply '$z$' with '$s$' and check the result.\\nAccess the '$z$'-th entry of '$s$'.\\n\\nHint: Sequences of numbers can be created with a '$:$', for example, '$1:4$' results in a vector $(1, 2, 3, 4)$. Alternatively the function '$seq()$' may be used, see the help for details.\\n\", 'answer': 'z <- 5\\ns <- -2:5 \\nmlt <- z * s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\n\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)\\nprint(sol)', 'rubrics': [], 'modelSolution': 'z <- 5\\ns <- -2:5 # oder: s <- seq(-2,5)\\nmlt <- z*s # z wird mit jedem Eintrag von s multipliziert\\neintr <- s[z]\\nsol <- list(Multiplikation = mlt, Eintrag = eintr)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Show the first column with name 'ht' of the data frame 'dat'. \\nCalculate the sum of all the elements of 'ht'. This is the total height of all 403 students in the dataset.\\n\\nTips: There are two ways to access a column. We can use the indices directly, by simply leaving the first entry inside the square brackets before the comma empty, e.g. $dat[,2]$. The empty row specifier means that all rows are considered.\\n\\nAlternatively we can use the name of the column and the operator '\\\\$', e.g. 'dat\\\\$size'.\\n\\nUse the function $sum()$ to calculate the sum.\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nht <- dat$ht\\nsum_ht <- sum(ht)\\n\\nsol <- list(Spalte_ht = ht, Summe_ht = sum_ht)\\n', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nht <- dat$ht\\nsum_ht <- sum(dat$ht)\\nsol <- list(Spalte_ht = ht, Summe_ht = sum_ht)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\nsol', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\n\\nWhat is the value of $a$? Compute it here in R.\\n\\nTip: go to R Studio and do $?sum$ to read the online help about $sum(...)$.\\n', 'answer': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1-sum(p, na.rm = T) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\n(sol <- list(Wert = a))\\n\", 'rubrics': [], 'modelSolution': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1 - sum(p, na.rm=TRUE) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\nsol <- list(Wert = a)\\n\", 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Start with the code of the previous task. Now let\\'s color the points of the scatterplot according to the variable $species$. Color the species \\'setosa\\' with the color code 1, \\'versicolor\\' with color code 2, and \\'virginica\\' with the color code 3. In the upper right corner of the graph, introduce a legend with the same order of species. Comment on the resulting plot.\\n \\nTips: You can also just assign a factor to the argument $col=$, e.g. with \\'col=iris\\\\$Species\\'. Then R will simply assign color codes 1, 2, 3, $\\\\dots$ to the factor levels.\\n\\nUse the function $legend()$ to give your plot a suitable legend:\\n$legend(\"topright\", legend=..., col=..., pch=16)$\\n\\nTake care that the colors and species in the legend match those in the plot!\\n', 'answer': 'png(file = \"solution.png\")\\ndata(\"iris\")\\nplot(\\n\\tiris$Sepal.Width, \\n\\tiris$Petal.Width, \\n\\txlab=\\'Breite Kelchblatt [mm]\\',\\n\\tylab=\\'Breite Blütenblatt [mm]\\', \\n\\tmain=\\'Breite der Irisblumenblätter\\', \\n\\tcol=as.numeric(iris$Species), \\n\\tpch=16\\n)\\nlegend(\"topright\", legend=levels(iris$Species), col=1:3, pch=16)\\n\\ntext_response <- \"...\"\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(\"iris\")\\nplot(iris$Sepal.Width, iris$Petal.Width, xlab=\"Breite Kelchblatt [mm]\", \\n     ylab=\"Breite Blütenblatt [mm]\", main=\"Breite der Irisblumenblätter\", \\n     col=iris$Species, pch=16)\\nlegend(\"topright\", legend=levels(iris$Species), col=1:3, pch=16)\\ntext_response <- \"The flowers of I. setosa have wide sepals and narrow petals. The other group\\n     consists of the two species versicolor and virginica; these are similar but there is a tendency\\n     for I. versicolor to have narrower petals.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Like a calculator, R can compute values of all the usual functions - although only numerically!\\n\\nCreate a variable 'n' with the value $42$ and compute $\\\\sin(90)$ and $\\\\sin($n$\\\\cdot\\\\pi)$. What do you observe?\\n\\n\", 'answer': 'n <-  42\\n\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*(pi))\\n\\ntext_response <- \"When computing sin(90), the result is:\" \\n\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n\\n', 'rubrics': [], 'modelSolution': 'n <- 42\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*pi)\\ntext_response <- \"We observe that R works with radians and not with degrees; also, that the result is a numerical approximation (although a very good one!). Since 42 is an integer, the sine of 42*pi should actually be exactly 0.\"\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Create some random samples of sizes $n=\\\\{10, 1000, 100\\\\,000\\\\}$ from a random variable $X\\\\sim \\\\mathcal{N}(60, 9)$ and plot each sample in a histogram. As you do, reduce the bin width successively, from $2$ to $1$ to $0.5$. What do you observe?\\n\\n\\nTip: To make a histogram with a fixed bin width, use the function $hist()$ with the argument $breaks=...$. You will need to create a vector of the desired breakpoints between bins, e.g. from $\\\\mu - 6 \\\\sigma$ to $\\\\mu + 6\\\\sigma$ in steps of the desired bin width:\\n\\n$hist(..., freq=FALSE, breaks = seq(..., ..., ...) )$\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"Die Verteilung ähnelt immer mehr einer Normalverteilung, desto mehr Stichproben hinzugefügt werden und je kleiner die Klassenbreite ist\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"The larger the sample, the more closely the histogram resembles\\n      the density function f_X(x) from Task 1.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the video ``Creature-Cast: the Central Limit Theorem'' on YouTube \\n( [https://www.youtube.com/watch?v=jvoxEYmQHNM](https://www.youtube.com/watch?v=jvoxEYmQHNM) ).\\n\\nWe will reproduce both examples from this video and plot the corresponding density functions for different sample sizes. Please note that in the lecture we looked at the sum of i.i.d. random variables and saw how this sum approaches a normally distributed variable for increasing $n$. The same is true for the arithmetic mean $\\\\overline{X}$ - after all, to find the mean you first consider a sum and then divide by $n$.\\n\\nPlot the histogram of the weight distribution of the rabbits, with reasonable labels for the data. Add a density function to your histogram - please do this for all the histograms in this worksheet!\\n\\nTip: \\nFollow these steps:\\n\\n- Generate a sample from the population of all rabbits in R: \\n\\n$set.seed(24)$\\n\\n$rabbits <- rnorm(100000, mean=5.25, sd=1.625)$\\n\\nIn this way, you create an object called 'rabbits' with the weights in kg of 100,000 rabbits (we assume the weights to be normally distributed). The command $set.seed()$ ensures that we all get the same data set.\\n \\n- In order to better see the shape of the histogram, it's customary to add the graph of a density estimation to the plot. This can be done in R without much additional effort:\\n\\n$hist(???, freq=FALSE)$\\n\\n$lines(density(???, bw=1/3), col=..., lwd=...)$\\n\\nHere we use $bw=1/3$ for a nice-looking curve. You can read more about the meaning of this argument in the online help in RStudio, just type $?density$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(100000, mean=5.25, sd=1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density(rabbits,bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n\\n# Anmerkung:\\n# Wir merken, dass die angenommene Normalverteilung nicht ganz realistisch ist, \\n# denn einige wenige Kaninchen müssten negative Gewichte haben. Um eine physikalisch\\n# sinnvollere Verteilung zu erzeugen, könnten wir zum Beispiel den Befehl \\n# \\'rabbits[rabbits<1] <- 1\\' verwenden - alle Kaninchen, die laut Normalverteilung \\n# weniger als 1kg haben sollen, werden auf 1kg aufgerundet. Die daraus resultierende \\n# Verteilung wäre zwar nicht mehr normalverteilt - aber dafür bestimmt etwas \\n# realistischer! Der Aufgabenstellung zufolge werden wir hier doch bei einer \\n# Normalverteilung bleiben.\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(100000, mean=5.25, sd=1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density(rabbits, bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Vergleichen Sie die Histogramme der vier stetigen Variablen miteinander. Plotten Sie die Histogramme; verwenden Sie überall den gleichen Abschnitt der $x$-Achse. Kommentieren Sie das Resultat und vergleichen Sie es mit dem Boxplot.\\n\\nTipps:\\nMit R Markdown können Sie mehrere Plots in einem Codeabschnitt generieren. Verwenden Sie die Hilfe für die Funktion $hist()$ und das Argument $xlim$;\\n\\n$hist(..., xlim ...)$.\\n', 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\n\\nhist(iris$Sepal.Length, main=\"Sepal.Length\", xlab=\"Sepal.Length\", xlim=c(0, 8))\\nhist(iris$Sepal.Width, main=\"Sepal.Width\", xlab=\"Sepal.Width\", xlim=c(0, 8))\\nhist(iris$Petal.Length, main=\"Petal.Length\", xlab=\"Petal.Length\", xlim=c(0, 8))\\nhist(iris$Petal.Width, main=\"Petal.Width\", xlab=\"Petal.Width\", xlim=c(0, 8))\\n\\ntext_response <- \"The boxplot and the histograms are consistent.\"\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\npar(mfrow=c(2,2), mar = c(4, 4, 0.1, 0.1)) #Plots in Zweierreihe; Seitenränder klein\\nhist(iris[,1], main=\"\", xlab=\"Variable 1\", xlim=c(0, 8))\\nhist(iris[,2], main=\"\", xlab=\"Variable 2\", xlim=c(0, 8))\\nhist(iris[,3], main=\"\", xlab=\"Variable 3\", xlim=c(0, 8))\\nhist(iris[,4], main=\"\", xlab=\"Variable 4\", xlim=c(0, 8))\\n\\ntext_response <- \"Variables 1 and 2 (sepal length and sepal width) each have a unimodal distribution (they form a single \\'heap\\' so to speak). Variables 3 and 4 are bimodal! This difference was not obvious from the boxplots.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the R videos related to this exercise. The links can be found on the course web page.\\n\\nR allows us to compute quantities such as mean, median, standard deviation etc. easily. The corresponding functions are:\\n\\nmean()   $~$ = $~$ Mean;\\n\\nmedian() $~$ = $~$ Median;\\n\\nsd()     $~$ = $~$ Standard deviation;\\n\\nvar()    $~$ = $~$ Variance;\\n\\nrange()  $~$ = $~$ Range of values (i.e., from minimum to maximum);\\n\\nmin()    $~$ = $~$ Minimum;\\n\\nmax()    $~$ = $~$ Maximum;\\n\\n\\nExample: We illustrate the use of some of these functions with the dataset 'women' containing average heights and weights (in inches and pounds respectively) for American women between 30 and 39.\\nThis dataset is already available in R and can be used directly. Switch to R Studio and try out a few of the functions above, e.g. 'range(women\\\\$height)' or 'mean(women\\\\$height)'.\\n\\nVisualization of data by a boxplot or histogram can be done with the functions $boxplot()$ und $hist()$. Read the short section on boxplots in the textbook, at the end of (2.2.3.4).\\n\\nThe dataset 'iris' is available in R: load it with the function $data()$. More information about the dataset is available in the R help via the command $?iris$.\\n\\nGet an overview of the dataset with the functions $summary()$, $str()$ and $head()$. The fifth column contains the values of a nominal variable, the other variables are continuous. In R, nominal and ordinal variables are called 'factor' while continuous variables are called 'numeric' (or simply $num$).\\n\\n\\nCompute both the mean and the median of petal length.\\n\", 'answer': 'data(iris)\\n\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\n\\nmean_iris <- mean(iris$Petal.Length)\\nmedian_iris <- median(iris$Petal.Length)\\n\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'rubrics': [], 'modelSolution': 'data(iris)\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\nmean_iris <- mean(iris$Petal.Length)\\nmedian_iris <- median(iris$Petal.Length)\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Create some random samples of sizes $n=\\\\{10, 1000, 100\\\\,000\\\\}$ from a random variable $X\\\\sim \\\\mathcal{N}(60, 9)$ and plot each sample in a histogram. As you do, reduce the bin width successively, from $2$ to $1$ to $0.5$. What do you observe?\\n\\n\\nTip: To make a histogram with a fixed bin width, use the function $hist()$ with the argument $breaks=...$. You will need to create a vector of the desired breakpoints between bins, e.g. from $\\\\mu - 6 \\\\sigma$ to $\\\\mu + 6\\\\sigma$ in steps of the desired bin width:\\n\\n$hist(..., freq=FALSE, breaks = seq(..., ..., ...) )$\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean = mu, sd = sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(10, mean = mu, sd = sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean = mu, sd = sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"Die Verteilung nähert sich an eine Normalverteilung an je mehr Stichproben hinzugefügt werden und je kleiner die Klassenbreite ist.\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"The larger the sample, the more closely the histogram resembles\\n      the density function f_X(x) from Task 1.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Check the statement from lemma 5.4 a) $V[aX+b]=a^2 \\\\cdot V[X]$ for the values obtained in part 1.\\n', 'answer': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400,mean=mu,sd=sqrt(9)) # rnorm braucht SD, nicht Varianz!\\na <- -4\\nb <- 3\\n\\nv1 <- var(a*X+b)\\nv2 <- a^2*var(X)\\n\\nsol <- list(linke_Seite_der_Gleichung = v1, rechte_Seite_der_Gleichung = v2)\\nsol', 'rubrics': [], 'modelSolution': 'set.seed(10) # damit wir reproduzierbar arbeiten\\n\\nmu <- 57\\nX <- rnorm(400, mean=mu, sd=3) # rnorm braucht SD, nicht Varianz!\\na <- -4\\nb <- 3\\n\\nv1 <- var(a*X+b)\\nv2 <- a^2*var(X)\\n\\nsol <- list(linke_Seite_der_Gleichung = v1, rechte_Seite_der_Gleichung = v2)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Which are the 'ht' for shoe sizes in the range $[5,6.5]$ (corresponding to EU shoe sizes 36-39)? And how many are there?\\n\", 'answer': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\",header=TRUE)\\n\\nht <- dat[,1]\\nsize <- dat[,3]\\nsize_565 <- ht[size >= 5 & size <= 6.5]\\n\\nsol <- list(ht = size_565, anzahl = length(size_565))\\nprint (sol)', 'rubrics': [], 'modelSolution': 'dat <- read.table(\"http://stat.ethz.ch/Teaching/Datasets/shoe.dat\", header=TRUE)\\nsize <- dat$size\\nht <- dat$ht\\nsize_565 <- ht[size>=5 & size<=6.5]\\nsol <- list(ht = size_565, anzahl = length(size_565))', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"What are the names of the three categories of the variable 'Species'?\\nUse the function $summary()$.\\n\", 'answer': 'data(iris)\\nsummary(iris$Species)\\ntext_response <- \"The three categories of the variable \\'Species\\' are setosa, versicolor and virginica.\"', 'rubrics': [], 'modelSolution': 'data(iris)\\nsummary(iris$Species)\\ntext_response <- \"setosa, versicolor, virginica\"', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\n\\nWhat is the value of $a$? Compute it here in R.\\n\\nTip: go to R Studio and do $?sum$ to read the online help about $sum(...)$.\\n', 'answer': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1-sum(p, NA, na.rm=TRUE) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\nsol <- list(Wert = a)\\n\", 'rubrics': [], 'modelSolution': \"p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05) # NA steht für 'not available'\\na <- 1 - sum(p, na.rm=TRUE) #na.rm entfernt alle NA, sonst wäre die Summe gleich NA\\nsol <- list(Wert = a)\\n\", 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the R videos related to this exercise. The links can be found on the course web page.\\n\\nR allows us to compute quantities such as mean, median, standard deviation etc. easily. The corresponding functions are:\\n\\nmean()   $~$ = $~$ Mean;\\n\\nmedian() $~$ = $~$ Median;\\n\\nsd()     $~$ = $~$ Standard deviation;\\n\\nvar()    $~$ = $~$ Variance;\\n\\nrange()  $~$ = $~$ Range of values (i.e., from minimum to maximum);\\n\\nmin()    $~$ = $~$ Minimum;\\n\\nmax()    $~$ = $~$ Maximum;\\n\\n\\nExample: We illustrate the use of some of these functions with the dataset 'women' containing average heights and weights (in inches and pounds respectively) for American women between 30 and 39.\\nThis dataset is already available in R and can be used directly. Switch to R Studio and try out a few of the functions above, e.g. 'range(women\\\\$height)' or 'mean(women\\\\$height)'.\\n\\nVisualization of data by a boxplot or histogram can be done with the functions $boxplot()$ und $hist()$. Read the short section on boxplots in the textbook, at the end of (2.2.3.4).\\n\\nThe dataset 'iris' is available in R: load it with the function $data()$. More information about the dataset is available in the R help via the command $?iris$.\\n\\nGet an overview of the dataset with the functions $summary()$, $str()$ and $head()$. The fifth column contains the values of a nominal variable, the other variables are continuous. In R, nominal and ordinal variables are called 'factor' while continuous variables are called 'numeric' (or simply $num$).\\n\\n\\nCompute both the mean and the median of petal length.\\n\", 'answer': 'data(iris)\\n\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\n\\nmean_iris <- mean(iris$Petal.Lenght)\\nmedian_iris <- median(iris$Petal.Lenght)\\n\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'rubrics': [], 'modelSolution': 'data(iris)\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\nmean_iris <- mean(iris$Petal.Length)\\nmedian_iris <- median(iris$Petal.Length)\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nPlot the probability function of $X$.\\n\\nTips: First replace the \\'NA\\' with the calculated value (Exercise 2). Use $plot(...)$ with $type=\"h\"$ to get a suitable plot.\\n', 'answer': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\nplot(p, x, type=\"h\", lwd=3, ylab=\"P[X = x]\", main=\"Wahrscheinlichkeitsfunktion\")\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\nplot(x, p, type=\"h\", lwd=3, ylab=\"P[X = x]\", main=\"Wahrscheinlichkeitsfunktion\")\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Plot the histograms of the average wingspan for the sample sizes 5, 20 and 100 dragons from this population. As before, the (exceptionally brave) scientist will measure 100 groups of each size.\\n\\n\\n', 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\nD_1 <- rnorm(50000, mean=5, sd=sqrt(2))\\nD_2 <- rnorm(50000, mean=14, sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\n# Bereite Objekte vor\\nmesse5 <- numeric(length=100)\\nmesse20 <- numeric(length=100)\\nmesse100 <- numeric(length=100)\\nxLim <- c(0, 25)\\ncolHist <- \"seagreen\"\\ncolDensity <- \"red\"\\nxLab <- \"Flügelspannweite [m]\"\\n\\n# Erzeuge Stichproben\\nfor (i in dragons){\\n  messe5[i] <- mean(sample(x=dragons, size=5))\\n  messe20[i] <- mean(sample(x=dragons, size=20))\\n  messe100[i] <- mean(sample(x=dragons, size=100))\\n}\\n\\npar(mfrow=c(3,1))  # drei Plots aufeinander gestapelt\\nhist(messe5, main=\"5 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe5, bw=2), lwd=2, col=colDensity)\\n\\nhist(messe20, main=\"20 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe20, bw=1), lwd=2, col=colDensity)\\n\\nhist(messe100, main=\"100 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe100, bw=0.5), lwd=2, col=colDensity)\\n\\ndev.off()\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\nD_1 <- rnorm(50000, mean=5, sd=sqrt(2))\\nD_2 <- rnorm(50000, mean=14, sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\n# Bereite Objekte vor\\nmesse5 <- numeric(100)\\nmesse20 <- numeric(100)\\nmesse100 <- numeric(100)\\nxLim <- c(0, 25)\\ncolHist <- \"seagreen\"\\ncolDensity <- \"red\"\\nxLab <- \"Flügelspannweite [m]\"\\n\\n# Erzeuge Stichproben\\nfor (i in 1:100){\\n  messe5[i] <- mean(sample(dragons, 5))\\n  messe20[i] <- mean(sample(dragons, 20))\\n  messe100[i] <- mean(sample(dragons, 100))\\n}\\npar(mfrow=c(3,1))  # drei Plots aufeinander gestapelt\\nhist(messe5, main=\"5 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe5, bw=2), lwd=2, col=colDensity)\\n\\nhist(messe20, main=\"20 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe20, bw=1), lwd=2, col=colDensity)\\n\\nhist(messe100, main=\"100 Drachen\", col=colHist, xlim=xLim, freq=FALSE, xlab=xLab)\\nlines(density(messe100, bw=0.5), lwd=2, col=colDensity)\\n\\ndev.off()\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Now let's turn to the example with the dragons.\\n\\nThis example shows that even when we start with really distributions (uniform distribution in the lecture, or bimodal in this exercise), thanks to the CLT a normal distribution emerges in the end.\\n\\nWe generate a bimodal population of the different dragons according to the following: create a random vector $D_1$ of length 50,000 with $D_1\\\\sim N(5,2)$-distribution, which describes the wingspan of the dragon subpopulation 'Draconis breves pinnae', and another random vector $D_2\\\\sim N(14, 10)$ with the same length, which describes the subpopulation 'D. lata quadrupes'. \\nWe combine the two vectors into a single longer one with the function $c()$.\\n\\nPlot the bimodal population of dragon wingspans. Label your plot as shown and once again add an estimated density function.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\t\\nD_1 <- rnorm(50000,mean=5,sd=sqrt(2))\\nD_2 <- rnorm(50000,mean=14,sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\t\\nhist(\\n\\tdragons, \\n\\tmain=\"Flügelspannweite\", \\n\\tcol=\"lightgreen\",\\n\\txlab=\"Flügelspannweite [m]\", \\n\\tfreq=FALSE\\n)\\nlines(density(dragons, bw=2), col=\"red\", lwd=2)\\n\\ndev.off()', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\n\\t\\nD_1 <- rnorm(50000, mean=5, sd=sqrt(2))\\nD_2 <- rnorm(50000, mean=14, sd=sqrt(10))\\ndragons <- c(D_1, D_2)\\n\\t\\nhist(\\n\\tdragons, \\n\\tmain=\"Flügelspannweite\", \\n\\tcol=\"lightgreen\",\\n\\txlab=\"Flügelspannweite [m]\", \\n\\tfreq=FALSE\\n)\\nlines(density(dragons, bw=2), col=\"red\", lwd=2)\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Plot the boxplot of all continuous variables.\\n\\nNow access the 73-rd line in the 'iris' dataset and compare those values with the boxplot. Does the\\n73-rd iris flower have relatively long or short sepals, relatively wide or narrow ones?\\n\\nTips: The first four variables from the dataset 'iris' can be accessed by $iris[, 1 : 4]$.\\n\\nAfter you have created the boxplot, in the same code chunk you can use the function $points()$ to\\ndraw some additional points. With the argument $pch = 17$ these points are displayed as triangles.\\n\", 'answer': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- iris[,1:4]\\nboxplot(n, main=\"Boxplot des Iris-Datensatzes\")\\n\\npoints(1:4, iris[73,1:4] , pch=17)\\n\\nsol <- list(Length = \"gross\", # falsche Antwort hier löschen!\\n            Width = \"breit\" # falsche Antwort hier löschen!\\n)\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\ndata(iris)\\n\\nn <- 73\\nboxplot(iris[,1:4], main=\"Boxplot des Iris-Datensatzes\")\\npoints(1:4, iris[n,1:4], pch=17)\\n\\nsol <- list(Length = \"gross\", Width = \"schmal\")\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the video ``Creature-Cast: the Central Limit Theorem'' on YouTube \\n( [https://www.youtube.com/watch?v=jvoxEYmQHNM](https://www.youtube.com/watch?v=jvoxEYmQHNM) ).\\n\\nWe will reproduce both examples from this video and plot the corresponding density functions for different sample sizes. Please note that in the lecture we looked at the sum of i.i.d. random variables and saw how this sum approaches a normally distributed variable for increasing $n$. The same is true for the arithmetic mean $\\\\overline{X}$ - after all, to find the mean you first consider a sum and then divide by $n$.\\n\\nPlot the histogram of the weight distribution of the rabbits, with reasonable labels for the data. Add a density function to your histogram - please do this for all the histograms in this worksheet!\\n\\nTip: \\nFollow these steps:\\n\\n- Generate a sample from the population of all rabbits in R: \\n\\n$set.seed(24)$\\n\\n$rabbits <- rnorm(100000, mean=5.25, sd=1.625)$\\n\\nIn this way, you create an object called 'rabbits' with the weights in kg of 100,000 rabbits (we assume the weights to be normally distributed). The command $set.seed()$ ensures that we all get the same data set.\\n \\n- In order to better see the shape of the histogram, it's customary to add the graph of a density estimation to the plot. This can be done in R without much additional effort:\\n\\n$hist(???, freq=FALSE)$\\n\\n$lines(density(???, bw=1/3), col=..., lwd=...)$\\n\\nHere we use $bw=1/3$ for a nice-looking curve. You can read more about the meaning of this argument in the online help in RStudio, just type $?density$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(1000, mean=5.25, sd=1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density( rabbits, bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n\\n# Anmerkung:\\n# Wir merken, dass die angenommene Normalverteilung nicht ganz realistisch ist, \\n# denn einige wenige Kaninchen müssten negative Gewichte haben. Um eine physikalisch\\n# sinnvollere Verteilung zu erzeugen, könnten wir zum Beispiel den Befehl \\n# \\'rabbits[rabbits<1] <- 1\\' verwenden - alle Kaninchen, die laut Normalverteilung \\n# weniger als 1kg haben sollen, werden auf 1kg aufgerundet. Die daraus resultierende \\n# Verteilung wäre zwar nicht mehr normalverteilt - aber dafür bestimmt etwas \\n# realistischer! Der Aufgabenstellung zufolge werden wir hier doch bei einer \\n# Normalverteilung bleiben.\\n\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\nset.seed(24)\\t\\nrabbits <- rnorm(100000, mean=5.25, sd=1.625)\\n\\t\\nhist(\\n\\trabbits, \\n\\txlab=\"Gewicht [kg]\", \\n\\tcol=\"lightblue\", \\n\\tfreq=FALSE,\\n\\tmain=\"Kaninchen Gewicht\"\\n)\\nlines(density(rabbits, bw=1/3), col=\"red\", lwd=2)  # benutzen Sie bei density() bw=1/3\\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nPlot the cumulative distribution function of $X$. Since cumulative distribution functions are defined from $-\\\\infty$ to $\\\\infty$, please indicate this by making a plot which shows 2 units to the left and right of the relevant domain.\\n\\nTips: Here you will need the functions $cumsum(...)$, $stepfun(...)$, $plot(...)$, and $points(...)$; take the opening example (Exercise 1) as a starting point. For $plot(...)$ use the argument $pch=16$ for solid points and $verticals=FALSE$ for a plot without vertical lines at the jumps; the argument $pch=1$ to the command $points(...)$ will give empty points.\\n', 'answer': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- stepfun(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- stepfun(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Create some random samples of sizes $n=\\\\{10, 1000, 100\\\\,000\\\\}$ from a random variable $X\\\\sim \\\\mathcal{N}(60, 9)$ and plot each sample in a histogram. As you do, reduce the bin width successively, from $2$ to $1$ to $0.5$. What do you observe?\\n\\n\\nTip: To make a histogram with a fixed bin width, use the function $hist()$ with the argument $breaks=...$. You will need to create a vector of the desired breakpoints between bins, e.g. from $\\\\mu - 6 \\\\sigma$ to $\\\\mu + 6\\\\sigma$ in steps of the desired bin width:\\n\\n$hist(..., freq=FALSE, breaks = seq(..., ..., ...) )$\\n\\n', 'answer': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean = mu, sd = sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t\\nx1000 <- rnorm(1000, mean = mu, sd = sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean = mu, sd = sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"Wie erwartet, nähert sich die Verteilung einer Normalverteilung,\\nje mehr Stichproben hinzugefügt werden und je kleiner die Klassenbreite ist.\"\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\npar(mfrow = c(3,1)) #drei Graphen aufeinander gestapelt\\nset.seed(10) #um reproduzierbar zu arbeiten\\n\\nmu <- 60\\nsigma <- 3\\n\\t\\nx10 <- rnorm(10, mean=mu, sd=sigma)\\nhist(x10, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,2))\\n\\t\\t\\t# Mittelwert +- 6 * Standardabweichung\\n\\t\\nx1000 <- rnorm(1000, mean=mu, sd=sigma)\\nhist(x1000, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,1))\\n\\t\\nx1e5 <- rnorm(100000, mean=mu, sd=sigma)\\nhist(x1e5, freq=FALSE, breaks=seq(mu-6*sigma,mu+6*sigma,0.5))\\n\\ntext_response <- \"The larger the sample, the more closely the histogram resembles\\n      the density function f_X(x) from Task 1.\"\\ndev.off()\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'We\\'ve gotten to know the plot functions $boxplot()$ and $hist()$ in earlier exercises. The generic function to display data as well as functions graphically is $plot()$. It creates a scatterplot of two vectors, which represent the x- and y-coordinates respectively of the points to plot.\\n\\nA plot is only informative if the axes are labeled accordingly! This can be done with the arguments $xlab$ and $ylab$. It\\'s also often helpful to add a title; you can do this by using the argument $main$.\\n\\nThe way a function is represented can be determined with the argument $type$. Often, the data are plotted with points ($type=\"p\"$) or with lines ($type=\"l\"$). You can find a complete list of values for $type$ with the command $?plot$; some examples are also there.\\nYou can also use color in your plots by directly setting the argument $col$, e.g. $col=\"red\"$. You can find a list of all possible values with $?colors$.\\n\\nThere are many other arguments which modify the way plots are displayed. You can get an overview over all these arguments with $?par$ or with $help.search(\"par\")$. \\n\\nHere is an example on the right: have some fun with this code, play around with all the options. Change the colors, line types, title, add some axis descriptions...  Or are these two curves a bit blocky-looking to you? Then take a larger number of points, i.e. in line 2 reduce the step length to get a smoother approximation.\\n\\nWhen you\\'re through, choose \"Reset\" at the far right (to restore the original code) and then simply do \"Submit\".\\n', 'answer': 'png(file = \"solution.png\")\\nx <- seq(0, 1.5, 0.3)  # x-Werte zwischen 0 und 1.5 (in Schritten der Länge 0.3)\\ny <- x^2 # Zugehörige y-Werte für die Quadratfunktion\\n# Plotte x gegen y als gepunktete (lty=\"dotted\") Linie (type=\"l\")\\nplot(x, y, lty=\"dotted\", type=\"l\",main=\"Zwei Potenzfunktionen\") \\n# Füge Wurzelfunktion als schokoladefarbene gestrichelte (\"dashed\") Kurve hinzu\\nz<-sqrt(x)\\nlines(x,z,lty=\"dashed\",col=\"chocolate3\")\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\nx <- seq(0, 1.5, 0.3)  # x-Werte zwischen 0 und 1.5 (in Schritten der Länge 0.3)\\ny <- x^2 # Zugehörige y-Werte für die Quadratfunktion\\n# Plotte x gegen y als gepunktete (lty=\"dotted\") Linie (type=\"l\")\\nplot(x, y, lty=\"dotted\", type=\"l\",main=\"Zwei Potenzfunktionen\") \\n# Füge Wurzelfunktion als schokoladefarbene gestrichelte (\"dashed\") Kurve hinzu\\nz<-sqrt(x)\\nlines(x,z,lty=\"dashed\",col=\"chocolate3\")\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Watch the R videos related to this exercise. The links can be found on the course web page.\\n\\nR allows us to compute quantities such as mean, median, standard deviation etc. easily. The corresponding functions are:\\n\\nmean()   $~$ = $~$ Mean;\\n\\nmedian() $~$ = $~$ Median;\\n\\nsd()     $~$ = $~$ Standard deviation;\\n\\nvar()    $~$ = $~$ Variance;\\n\\nrange()  $~$ = $~$ Range of values (i.e., from minimum to maximum);\\n\\nmin()    $~$ = $~$ Minimum;\\n\\nmax()    $~$ = $~$ Maximum;\\n\\n\\nExample: We illustrate the use of some of these functions with the dataset 'women' containing average heights and weights (in inches and pounds respectively) for American women between 30 and 39.\\nThis dataset is already available in R and can be used directly. Switch to R Studio and try out a few of the functions above, e.g. 'range(women\\\\$height)' or 'mean(women\\\\$height)'.\\n\\nVisualization of data by a boxplot or histogram can be done with the functions $boxplot()$ und $hist()$. Read the short section on boxplots in the textbook, at the end of (2.2.3.4).\\n\\nThe dataset 'iris' is available in R: load it with the function $data()$. More information about the dataset is available in the R help via the command $?iris$.\\n\\nGet an overview of the dataset with the functions $summary()$, $str()$ and $head()$. The fifth column contains the values of a nominal variable, the other variables are continuous. In R, nominal and ordinal variables are called 'factor' while continuous variables are called 'numeric' (or simply $num$).\\n\\n\\nCompute both the mean and the median of petal length.\\n\", 'answer': 'data(iris)\\n\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\n\\nmean_iris <- mean (iris$Petal.Length)\\nmedian_iris <- median(iris$Petal.Length)\\n\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'rubrics': [], 'modelSolution': 'data(iris)\\nsummary(iris)\\nstr(iris)\\nhead(iris)\\nmean_iris <- mean(iris$Petal.Length)\\nmedian_iris <- median(iris$Petal.Length)\\nsol <- list(Mittelwert = mean_iris, Median = median_iris)', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nPlot the cumulative distribution function of $X$. Since cumulative distribution functions are defined from $-\\\\infty$ to $\\\\infty$, please indicate this by making a plot which shows 2 units to the left and right of the relevant domain.\\n\\nTips: Here you will need the functions $cumsum(...)$, $stepfun(...)$, $plot(...)$, and $points(...)$; take the opening example (Exercise 1) as a starting point. For $plot(...)$ use the argument $pch=16$ for solid points and $verticals=FALSE$ for a plot without vertical lines at the jumps; the argument $pch=1$ to the command $points(...)$ will give empty points.\\n', 'answer': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- stepfun(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\np <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\npsum <- c(0, cumsum(p)) # Vektor der kumulativen Wahrscheinlichkeiten + Startwert 0\\nverteilungsfunktion <- stepfun(x, psum) # definiere eine Treppenfunktion\\nplot(\\n\\tverteilungsfunktion, \\n\\tverticals=FALSE, \\n\\tpch=16, \\n\\txlim=c(-5,6), \\n\\tylab=\"P[ X <= x ]\", \\n\\tmain=\"Verteilungsfunktion\"\\n) # plotte die Striche inkl. gefüllte Punkte\\npoints(x, psum[-length(psum)], pch = 1) # zeichne auch die leeren Punkte ein\\ngrid(nx=0, ny=NULL, col=\"grey\") # Gitter zur besseren Lesbarkeit der y-Werte\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"Like a calculator, R can compute values of all the usual functions - although only numerically!\\n\\nCreate a variable 'n' with the value $42$ and compute $\\\\sin(90)$ and $\\\\sin($n$\\\\cdot\\\\pi)$. What do you observe?\\n\\n\", 'answer': 'n <-  42\\n\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*pi)\\n\\ntext_response <- \"Die Zahlen wurden in Bogenmass angegeben. Ausserdem ist der Wert von sin(42 * π) theoretisch null, da es sich um einen Winkel handelt, der mehr als einer vollen Umdrehung entspricht. Wegen der begrenzten Genauigkeit von numerischen Berechnungen in R gibt es einen sehr kleinen Wert, der nahe genug bei null liegt, um als null betrachtet zu werden.\" \\n\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n', 'rubrics': [], 'modelSolution': 'n <- 42\\nsin_90 <- sin(90)\\nsin_npi <- sin(n*pi)\\ntext_response <- \"We observe that R works with radians and not with degrees; also, that the result is a numerical approximation (although a very good one!). Since 42 is an integer, the sine of 42*pi should actually be exactly 0.\"\\nsol <- list(sin_90 = sin_90, sin_npi = sin_npi)\\n', 'maxPoints': 2.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'A discrete random variable $X$ is given by the following table (probability function):\\n\\n| x\\t| &nbsp; | p\\t|\\n| :---:\\t| :---:\\t | :---\\t|\\n| -2\\t| &nbsp; | 0.25\\t|\\n| -1\\t| &nbsp; | 0.19\\t|\\n| 0\\t| &nbsp; | 0.108\\t|\\n| 1\\t| &nbsp; | 0.21\\t|\\n| 2\\t| &nbsp; | $a$\\t|\\n| 3\\t| &nbsp; | 0.10\\t|\\n| 4\\t| &nbsp; | 0.05\\t|\\n\\nCompute the probability $P[-1 < X \\\\leq 2]$.\\n\\nTip: Use the vector $x_i$ and the corresponding logical conditions in order to access the correct entries of $p_i$:\\n\\n$p[\\\\,... \\\\;\\\\&\\\\; ...\\\\,]$\\n\\n', 'answer': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 0.092 # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[x>-1 & x<=2])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\nsol', 'rubrics': [], 'modelSolution': 'p <- c(0.25, 0.19, 0.108, 0.21, NA, 0.10, 0.05)\\np[5] <- 1 - sum(p, na.rm=TRUE) # das NA durch den berechneten Wert ersetzen\\nx <- c(-2, -1, 0, 1, 2, 3, 4)\\n\\nw <- sum(p[ x>-1 & x<=2 ])\\n\\nsol <- list(Wahrscheinlichkeit = w)\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Check if the standard deviation of the sepal width equals the square root of the variance.\\n', 'answer': 'data(iris)\\n\\nstandardabw <- sd(iris$Sepal.Width)\\nwurz_var <- sqrt(var(iris$Sepal.Width))\\n\\nsol <- list(Standardabweichung = standardabw, \\n    Wurzel_der_Varianz = wurz_var, \\n    Werte_sind = \"identisch\")\\nsol', 'rubrics': [], 'modelSolution': 'data(iris)\\nstandardabw <- sd(iris$Sepal.Width)\\nwurz_var <- sqrt(var(iris$Sepal.Width))\\nsol <- list(Standardabweichung = standardabw, Wurzel_der_Varianz = wurz_var, Werte_sind = \"identisch\")', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Heidi and Peter are curious how many buttercups grow on the alp. They take 10 samples by marking out 10 different 1m$^2$ areas of land, and counting the buttercups in each one:\\n\\n580, 331, 493, 525, 420, 522, 468, 594, 347, 586.\\n\\nAssume that the number of buttercups per square meter is normally distributed (i.e. we are using a continuous distribution to model a discrete one) and that the samples are independent of each other.\\n\\nCompute a 99\\\\% confidence interval for the expectation $\\\\mu$. Give the estimated variance as well.\\n', 'answer': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nxquer <- sum(counts)/n\\nsigma <- sqrt(varianz)\\nvarianz <- var(counts)\\n\\nt <- qt(0.99, df=n-1)\\nCI <- c(xquer - t*sigma/sqrt(n), xquer + t*sigma/sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\nprint(sol)\\n', 'rubrics': [], 'modelSolution': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nxquer <- mean(counts)\\nsigma <- sd(counts)\\nvarianz <- sigma^2\\n\\nt <- qt(0.995,n-1)\\nCI <- c(xquer - t*sigma/sqrt(n), xquer + t*sigma/sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Heidi and Peter are curious how many buttercups grow on the alp. They take 10 samples by marking out 10 different 1m$^2$ areas of land, and counting the buttercups in each one:\\n\\n580, 331, 493, 525, 420, 522, 468, 594, 347, 586.\\n\\nAssume that the number of buttercups per square meter is normally distributed (i.e. we are using a continuous distribution to model a discrete one) and that the samples are independent of each other.\\n\\nCompute a 99\\\\% confidence interval for the expectation $\\\\mu$. Give the estimated variance as well.\\n', 'answer': 'counts <- c(580,331,493,525,420,522,468,594,347,586)\\nn <- 10\\n\\nxquer <- mean(counts)\\nvarianz <- var(counts)\\nsigma <- sd(counts)\\nt <- qt(0.995, df=n-1)\\nCI <- c(xquer - t*sigma/sqrt(n), xquer + t*sigma/sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\n\\n', 'rubrics': [], 'modelSolution': 'counts <- c(580, 331, 493, 525, 420, 522, 468, 594, 347, 586)\\nn <- length(counts)\\n\\nxquer <- mean(counts)\\nsigma <- sd(counts)\\nvarianz <- sigma^2\\n\\nt <- qt(0.995,n-1)\\nCI <- c(xquer - t*sigma/sqrt(n), xquer + t*sigma/sqrt(n))\\n\\nsol <- list(Varianz = varianz, CI = CI)\\n\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': \"In this collection of exercises we use R to examine some important distributions. With the command $?Distributions$ you can get an overview of the distributions which are included in the R package 'stats'. It includes all the distributions discussed in the lecture; binomial (incl. Bernoulli), $\\\\chi^2$-, exponential distribution, etc.\\nIn the first four tasks we will take a closer look at a few of these distributions (see also the lecture notes, pp.100-112).\\n\\nTip: Always pay attention to the parameters! In particular the normal and geometric distributions are parametrised differently in R than in the lecture.\\n\\n\\nPlot the probability function of the following discrete distribution:\\n\\n* Geometric distribution, $X\\\\sim Ge(\\\\frac{1}{3})$,\\n\\nEx.: Number of attempts until the first success, with success probability $p=\\\\frac{1}{3}$; \\n    \\nTip: This distribution is defined differently in R: namely as the number of $\\\\it failures$ $\\\\it before$ the first success. So you will need to shift the graph: instead of $(x, \\\\texttt{dgeom(x, ...)})$ you should plot the points $(x+1, \\\\texttt{dgeom(x, ...)})$.\\n\\n\", 'answer': 'png(file = \"solution.png\")\\n\\n## Geometrische Verteilung\\nx <- 0:10 # Anzahl Misserfolge (nicht Versuche)\\np <- 1/3\\ny <- x <- 0:10\\np <- 1/3\\ny <- (dgeom(x, p))\\nplot(\\n\\tx+1, # x+1 sodass wir die Anzahl Versuche plotten\\n\\ty, \\n\\ttype=\"h\", \\n\\tlwd=5, \\n\\txlab=\"Anzahl Versuche\", \\n\\tylab=\"P[X=x]\",\\n\\tmain=\"Geometrisch, X~Ge(1/3)\", \\n\\tcol=\"green4\"\\n\\t)\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=1/p, lwd=2) # Erwartungswert (Anzahl Versuche)\\n\\n# Erwartungswert +/- Standardabweichung (auch Anzahl Versuche):\\nabline(v=c(1/p - sqrt(6), 1/p + sqrt(6)) , lty=2) \\n\\ndev.off()\\n', 'rubrics': [], 'modelSolution': 'png(file = \"solution.png\")\\n\\n## Geometrische Verteilung\\nx <- 0:10 # Anzahl Misserfolge (nicht Versuche)\\np <- 1/3\\ny <- dgeom(x, prob=p)\\nplot(x+1, y, type=\"h\", lwd=5, xlab=\"Anzahl Versuche\", ylab=\"P[X=x]\", \\n\\tmain=\"Geometrisch, X~Ge(1/3)\", col=\"green4\")\\n# x+1 sodass wir die Anzahl Versuche plotten\\naxis(1, at=x, labels=x)\\nabline(h=0, lty=3)\\nabline(v=1/p, lwd=2) # Erwartungswert (Anzahl Versuche)\\n\\n# Erwartungswert +/- Standardabweichung (auch Anzahl Versuche):\\nabline(v=c(1/p-sqrt((1-p)/p^2), 1/p+sqrt((1-p)/p^2)), lty=2) \\n\\ndev.off()\\n', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "{'question': 'Determine the range of the second variable in the dataset ’iris’. Check if the two values\\ncorrespond to the minimum and maximum.\\n', 'answer': 'data(iris)\\n\\nwerteber <- range(iris$Sepal.Width)\\nminimum <- min(iris$Sepal.Width)\\nmaximum <- max(iris$Sepal.Width)\\n\\nsol <- list(Wertebereich = werteber, \\n    Minimum = minimum, \\n    Maximum = maximum, \\n    Werte = \"stimmen überein\" # falsche Antwort hier löschen!\\n    )\\n', 'rubrics': [], 'modelSolution': 'data(iris)\\nwerteber <- range(iris[,2])\\nminimum <- min(iris[,2])\\nmaximum <- max(iris[,2])\\nsol <- list(Wertebereich = werteber, Minimum = minimum, Maximum = maximum, Werte = \"stimmen überein\")', 'maxPoints': 1.0, 'minPoints': 0.0, 'pointStep': 0.5, 'temperature': 0, 'llmType': 'gpt', 'chainOfThought': False, 'votingCount': 1}\n",
      "Maths Set: Average Accuracy with added solutions: 71.00%\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### With Solutions and Voting\n",
    "Here we add voting, meaning we evaluate the submissions multiple times and take the average of the points assigned by the LLM. This happens in the backend."
   ],
   "id": "e278fc42e2dd9e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T11:26:41.498140Z",
     "start_time": "2025-01-05T11:24:36.602845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_threads = 2 # Due to rate limits and voting making more calls, we reduce the number of threads\n",
    "stat_tracker_voting, stat_accuracy_voting, stat_logs_voting = parallel_evaluate(evaluation_data_stat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True, voting=3)\n",
    "print(f\"Statistics Set: Average Accuracy with added solutions and voting: {stat_accuracy_voting:.2%}\")\n"
   ],
   "id": "c4e9663c86ef484c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating batch...\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n",
      "Evaluating batch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b34f117d19b4173975c94bc7ae0ff6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0f7cff5d69a49c5a4f4ef6e6a4a226e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1903489f84f64106bb7ed58766b6e69b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evaluating submissions:   0%|          | 0/25 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72b8e20132834d96a434f2cae0ff2042"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating submission 9: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 8: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 10: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 9: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 9: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 10: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 11: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 11: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 12: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 12: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 13: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 14: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 15: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 11: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 12: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 17: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 12: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 15: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 13: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 14: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 14: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 16: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 15: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 16: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 17: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 18: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 15: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 19: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 16: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 17: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 17: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 18: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 18: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 20: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 21: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 21: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Error evaluating submission 20: 500 Server Error: Internal Server Error for url: http://localhost:4000/evaluate\n",
      "Statistics Set: Average Accuracy with added solutions and voting: 73.02%\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mat_tracker_voting, mat_accuracy_voting, mat_logs_voting = parallel_evaluate(evaluation_data_mat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True, voting=3)\n",
    "print(f\"Maths Set: Average Accuracy with added solutions: {mat_accuracy_voting:.2%}\")"
   ],
   "id": "64e71ef141043a94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### With Solutions, Voting and CoT",
   "id": "18a9dd4a94174582"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stat_tracker_cot, stat_accuracy_cot, stat_logs_cot = parallel_evaluate(evaluation_data_stat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True, voting=3, cot=True)\n",
    "print(f\"Statistics Set: Average Accuracy with solutions, voting and CoT: {stat_accuracy_cot:.2%}\")"
   ],
   "id": "cc2a9a5e37f5ac82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mat_tracker_cot, mat_accuracy_cot, mat_logs_cot = parallel_evaluate(evaluation_data_mat_rand, func=evaluate, num_threads=num_threads, batch_size=batch_size, solution=True, voting=3, cot=True)\n",
    "print(f\"Maths Set: Average Accuracy with solutions, voting and CoT: {mat_accuracy_cot:.2%}\")"
   ],
   "id": "e2f0b543f1ed0b97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Clean and save the results",
   "id": "6d9774aad70a74b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helpers.get_metrics import get_average_accuracy\n",
    "\n",
    "# Clean data and recalculate the average accuracies in case of any missing data\n",
    "average_mat_no_solution_accuracy, _ = get_average_accuracy(mat_tracker_no_solutions)\n",
    "print(f\"Average Accuracy Statistics cleaned: {average_mat_no_solution_accuracy:.2%}\")\n",
    "\n",
    "average_stat_no_solution_accuracy, _ = get_average_accuracy(stat_tracker_no_solutions)\n",
    "print(f\"Average Accuracy Statistics without solution cleaned: {average_stat_no_solution_accuracy:.2%}\")\n",
    "\n",
    "average_stat_accuracy, _ = get_average_accuracy(stat_tracker)\n",
    "print(f\"Average Accuracy Statistics with solution cleaned: {average_stat_accuracy:.2%}\")\n",
    "\n",
    "average_mat_accuracy, _ = get_average_accuracy(mat_tracker)\n",
    "print(f\"Average Accuracy Maths with solution cleaned: {average_mat_accuracy:.2%}\")\n",
    "\n",
    "average_stat_accuracy_voting, _ = get_average_accuracy(stat_tracker_voting)\n",
    "print(f\"Average Accuracy Statistics with solution and voting cleaned: {average_stat_accuracy_voting:.2%}\")\n",
    "\n",
    "average_mat_accuracy_voting, _ = get_average_accuracy(mat_tracker_voting)\n",
    "print(f\"Average Accuracy Maths with solution and voting cleaned: {average_mat_accuracy_voting:.2%}\")\n",
    "\n",
    "average_stat_accuracy_cot, _ = get_average_accuracy(stat_tracker_cot)\n",
    "print(f\"Average Accuracy Statistics with solution, voting and CoT cleaned: {average_stat_accuracy_cot:.2%}\")\n",
    "\n",
    "average_mat_accuracy_cot, _ = get_average_accuracy(mat_tracker_cot)\n",
    "print(f\"Average Accuracy Maths with solution, voting and CoT cleaned: {average_mat_accuracy_cot:.2%}\")\n"
   ],
   "id": "f2acc55ce487e59f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helpers.save_results import save_evaluation_result_with_versioning\n",
    "\n",
    "save_evaluation_result_with_versioning(stat_tracker_no_solutions, 'stat_evaluation_no_solutions_result.csv', 'results')\n",
    "save_evaluation_result_with_versioning(mat_tracker_no_solutions, 'mat_evaluation_no_solutions_result.csv', 'results')\n",
    "\n",
    "save_evaluation_result_with_versioning(stat_tracker, 'stat_evaluation_result.csv', 'results')\n",
    "save_evaluation_result_with_versioning(mat_tracker, 'mat_evaluation_result.csv', 'results')\n",
    "\n",
    "save_evaluation_result_with_versioning(stat_tracker_voting, 'stat_evaluation_voting_result.csv', 'results')\n",
    "save_evaluation_result_with_versioning(mat_tracker_voting, 'mat_evaluation_voting_result.csv', 'results')\n",
    "\n",
    "save_evaluation_result_with_versioning(stat_tracker_voting, 'stat_evaluation_voting_cot_result.csv', 'results')\n",
    "save_evaluation_result_with_versioning(mat_tracker_voting, 'mat_evaluation_voting_cot_result.csv', 'results')\n",
    "\n"
   ],
   "id": "9221778a79aebfb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
